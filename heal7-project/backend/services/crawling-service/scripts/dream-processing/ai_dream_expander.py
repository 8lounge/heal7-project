#!/usr/bin/env python3
"""
HEAL7 ê¿ˆí’€ì´ AI í‚¤ì›Œë“œ í™•ì¥ ì‹œìŠ¤í…œ
364ê°œ â†’ 15,000ê°œ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì§€ëŠ¥í˜• í‚¤ì›Œë“œ ìƒì„± ë° í•´ì„ ì‹œìŠ¤í…œ
"""

import subprocess
import json
import logging
import re
import asyncio
import random
from typing import List, Dict, Set, Tuple
from datetime import datetime
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/ai_dream_expander.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AIDreamExpander:
    def __init__(self):
        self.base_categories = {
            'ìì—°': ['ë¬¼', 'ë°”ë‹¤', 'ê°•', 'ì‚°', 'ë‚˜ë¬´', 'ê½ƒ', 'í•´', 'ë‹¬', 'ë³„', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'êµ¬ë¦„', 'ì²œë‘¥', 'ë²ˆê°œ'],
            'ë™ë¬¼': ['ë±€', 'ìš©', 'í˜¸ë‘ì´', 'ê°œ', 'ê³ ì–‘ì´', 'ìƒˆ', 'ë¬¼ê³ ê¸°', 'ê±°ë¶ì´', 'í† ë¼', 'ì¥', 'ì†Œ', 'ë¼ì§€'],
            'ì‹ë¬¼': ['ë‚˜ë¬´', 'ê½ƒ', 'ì”ë””', 'ëŒ€ë‚˜ë¬´', 'ì¥ë¯¸', 'êµ­í™”', 'ë²šê½ƒ', 'ë§¤í™”', 'ì—°ê½ƒ', 'í¬ë„', 'ì‚¬ê³¼', 'ë³µìˆ­ì•„'],
            'ì¬ë¬¼': ['ëˆ', 'ê¸ˆ', 'ë³´ì„', 'ë‹¤ì´ì•„ëª¬ë“œ', 'ì€', 'ë™ì „', 'ì§€í', 'í†µì¥', 'ë³´ë¬¼ìƒì', 'í™©ê¸ˆ', 'ì§„ì£¼'],
            'ìŒì‹': ['ë°¥', 'ë¹µ', 'ê³¼ì¼', 'ê³ ê¸°', 'ìƒì„ ', 'êµ­', 'ë¼ë©´', 'ë–¡', 'ì¼€ì´í¬', 'ì‚¬íƒ•', 'ì´ˆì½œë¦¿'],
            'ì¸ë¬¼': ['ì—„ë§ˆ', 'ì•„ë¹ ', 'ì¹œêµ¬', 'ì—°ì¸', 'í˜•ì œ', 'ìë§¤', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ì„ ìƒë‹˜', 'ì˜ì‚¬'],
            'ê±´ë¬¼': ['ì§‘', 'í•™êµ', 'ë³‘ì›', 'êµíšŒ', 'ì ˆ', 'íšŒì‚¬', 'ìƒì ', 'í˜¸í…”', 'ì•„íŒŒíŠ¸', 'ë³„ì¥'],
            'êµí†µ': ['ì°¨', 'ê¸°ì°¨', 'ë¹„í–‰ê¸°', 'ë°°', 'ë²„ìŠ¤', 'íƒì‹œ', 'ìì „ê±°', 'ì˜¤í† ë°”ì´', 'ì§€í•˜ì² '],
            'ìƒ‰ê¹”': ['ë¹¨ê°„ìƒ‰', 'íŒŒë€ìƒ‰', 'ë…¸ë€ìƒ‰', 'ê²€ì€ìƒ‰', 'í°ìƒ‰', 'ì´ˆë¡ìƒ‰', 'ë³´ë¼ìƒ‰', 'ê°ˆìƒ‰', 'ë¶„í™ìƒ‰'],
            'ê°ì •': ['ê¸°ì¨', 'ìŠ¬í””', 'í™”ë‚¨', 'ì‚¬ë‘', 'ë‘ë ¤ì›€', 'ë†€ëŒ', 'í‰ì˜¨', 'ë¶ˆì•ˆ', 'í–‰ë³µ', 'ì ˆë§'],
            'í–‰ë™': ['ê±·ê¸°', 'ë›°ê¸°', 'ë‚ ê¸°', 'ìˆ˜ì˜', 'ì¶¤ì¶”ê¸°', 'ë…¸ë˜', 'ì›ƒê¸°', 'ìš¸ê¸°', 'ì ìê¸°', 'ë¨¹ê¸°'],
            'ë‚ ì”¨': ['ë§‘ìŒ', 'íë¦¼', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'íƒœí’', 'ì²œë‘¥', 'ë²ˆê°œ', 'ë¬´ì§€ê°œ', 'ì•ˆê°œ'],
            'ìˆ«ì': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '100', '1000'],
            'ì‹œê°„': ['ì•„ì¹¨', 'ë‚®', 'ì €ë…', 'ë°¤', 'ìƒˆë²½', 'ì–´ì œ', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ê³¼ê±°', 'ë¯¸ë˜']
        }
        
        self.adjectives = [
            'í°', 'ì‘ì€', 'ì•„ë¦„ë‹¤ìš´', 'ë¬´ì„œìš´', 'ë°ì€', 'ì–´ë‘ìš´', 'ê¹¨ë—í•œ', 'ë”ëŸ¬ìš´',
            'ëœ¨ê±°ìš´', 'ì°¨ê°€ìš´', 'ë‹¬ì½¤í•œ', 'ì“´', 'ë†’ì€', 'ë‚®ì€', 'ë„“ì€', 'ì¢ì€',
            'ë¹ ë¥¸', 'ëŠë¦°', 'ê°•í•œ', 'ì•½í•œ', 'ìƒˆë¡œìš´', 'ì˜¤ë˜ëœ', 'ì Šì€', 'ëŠ™ì€'
        ]
        
        self.dream_templates = {
            'traditional': [
                "{keyword}ì€(ëŠ”) ì¬ë¬¼ìš´ì„ ìƒì§•í•˜ë©°, í° ë¶€ë¥¼ ê°€ì ¸ë‹¤ì£¼ëŠ” ê¸¸ëª½ì…ë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ê±´ê°•ê³¼ ì¥ìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢‹ì€ ì§•ì¡°ì…ë‹ˆë‹¤.", 
                "{keyword}ì„(ë¥¼) ë³´ëŠ” ê¿ˆì€ ê°€ì •ì˜ í‰í™”ì™€ í™”ëª©ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸¸ëª½ì…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ì„±ê³µê³¼ ì¶œì„¸ë¥¼ ì•”ì‹œí•˜ëŠ” ë§¤ìš° ê¸¸í•œ ê¿ˆì…ë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ì§€í˜œì™€ í•™ë¬¸ì˜ ë°œì „ì„ ì˜ë¯¸í•˜ëŠ” ì¢‹ì€ ê¿ˆì…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ì‚¬ë‘ê³¼ ì¸ì—°ì„ ê°€ì ¸ë‹¤ì£¼ëŠ” í–‰ë³µí•œ ê¿ˆì…ë‹ˆë‹¤.",
                "{keyword}ì„(ë¥¼) ë§Œë‚˜ëŠ” ê¿ˆì€ ê·€ì¸ì˜ ë„ì›€ì„ ë°›ê²Œ ë  ê¸¸ëª½ì…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ìì†ì˜ ë²ˆì˜ê³¼ í›„ì†ì˜ ë°œë‹¬ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
            ],
            'modern': [
                "{keyword}ì€(ëŠ”) í˜„ì¬ ìƒí™©ì—ì„œ ìƒˆë¡œìš´ ê¸°íšŒì™€ ë³€í™”ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ë‚´ë©´ì˜ ì„±ì¥ê³¼ ìì•„ì‹¤í˜„ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸ì •ì ì¸ ì‹ í˜¸ì…ë‹ˆë‹¤.",
                "{keyword}ì„(ë¥¼) ë³´ëŠ” ê¿ˆì€ ì°½ì˜ë ¥ê³¼ ìƒìƒë ¥ì˜ ë°œíœ˜ë¥¼ ì•”ì‹œí•©ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ëŒ€ì¸ê´€ê³„ì˜ ê°œì„ ê³¼ ì†Œí†µì˜ ì¤‘ìš”ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ë…¸ë ¥ì´ ê²°ì‹¤ì„ ë§ºì„ ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì™€ ë§ˆìŒì˜ í‰ì•ˆì„ ì¶”êµ¬í•˜ë¼ëŠ” ë©”ì‹œì§€ì…ë‹ˆë‹¤.",
                "{keyword}ì„(ë¥¼) ê²½í—˜í•˜ëŠ” ê¿ˆì€ ìƒˆë¡œìš´ ë„ì „ì— ëŒ€í•œ ì¤€ë¹„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) í˜„ì‹¤ì—ì„œì˜ ì„±ì·¨ê°ê³¼ ë§Œì¡±ê°ì„ ìƒì§•í•©ë‹ˆë‹¤.",
            ],
            'psychological': [
                "{keyword}ì€(ëŠ”) ë¬´ì˜ì‹ ì† ì–µì••ëœ ê°ì •ì˜ í‘œí˜„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ìì•„ì™€ íƒ€ì¸ê³¼ì˜ ê´€ê³„ì— ëŒ€í•œ ë‚´ë©´ì˜ ê°ˆë“±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
                "{keyword}ì„(ë¥¼) ë³´ëŠ” ê¿ˆì€ ê°œì¸ì˜ ì„±ì¥ê³¼ ë³€í™”ì— ëŒ€í•œ ìš•êµ¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ê³¼ê±°ì˜ ê²½í—˜ì´ í˜„ì¬ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                "{keyword}ê¿ˆì€ ì •ì²´ì„± í™•ë¦½ê³¼ ìê¸° ë°œê²¬ì˜ ê³¼ì •ì„ ìƒì§•í•©ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ë‚´ì¬ëœ ì ì¬ë ¥ê³¼ ëŠ¥ë ¥ì˜ ê°ì„±ì„ ì•”ì‹œí•©ë‹ˆë‹¤.",
                "{keyword}ì„(ë¥¼) ê²½í—˜í•˜ëŠ” ê¿ˆì€ ì‹¬ë¦¬ì  ê· í˜•ê³¼ ì•ˆì •ì„ ì¶”êµ¬í•˜ëŠ” ì‹ í˜¸ì…ë‹ˆë‹¤.",
                "{keyword}ì€(ëŠ”) ê°œì¸ì˜ ê°€ì¹˜ê´€ê³¼ ì‹ ë… ì²´ê³„ì˜ ì¬ê²€í† ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
            ]
        }

    def query_database(self, query: str) -> List[Dict]:
        """DB ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            cmd = ['sudo', '-u', 'postgres', 'psql', 'heal7', '-c', query, '-t', '-A', '--field-separator=|']
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                records = []
                for line in lines:
                    if line and line.strip():
                        parts = line.split('|')
                        records.append(parts)
                return records
            return []
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
            return []

    def get_existing_keywords(self) -> Set[str]:
        """ê¸°ì¡´ í‚¤ì›Œë“œ ëª©ë¡ ì¡°íšŒ"""
        query = "SELECT keyword FROM dream_interpretations;"
        results = self.query_database(query)
        return {row[0].lower() for row in results if row}

    def generate_keyword_variants(self, base_keyword: str) -> List[str]:
        """í‚¤ì›Œë“œ ë³€í˜• ìƒì„±"""
        variants = []
        
        # í˜•ìš©ì‚¬ ì¡°í•©
        for adj in random.sample(self.adjectives, min(5, len(self.adjectives))):
            variants.append(f"{adj} {base_keyword}")
        
        # ë³µìˆ˜/ë‹¨ìˆ˜ ë³€í˜•
        if not base_keyword.endswith('ë“¤'):
            variants.append(f"{base_keyword}ë“¤")
        
        # ìƒíƒœ ë³€í˜• (íŠ¹ì • í‚¤ì›Œë“œ)
        if base_keyword in ['ë¬¼', 'ë¶ˆ', 'ê³µê¸°']:
            variants.extend([f"ê¹¨ë—í•œ {base_keyword}", f"ë”ëŸ¬ìš´ {base_keyword}", f"ëœ¨ê±°ìš´ {base_keyword}"])
        
        # ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„±
        if base_keyword in ['ì§‘', 'ë°©']:
            variants.extend(['ìƒˆì§‘', 'ì˜›ì§‘', 'í°ì§‘', 'ì‘ì€ì§‘'])
        elif base_keyword in ['ì°¨', 'ìë™ì°¨']:
            variants.extend(['ìƒˆì°¨', 'ê³ ì¥ë‚œì°¨', 'ë¹ ë¥¸ì°¨', 'ë¹„ì‹¼ì°¨'])
        
        return list(set(variants))  # ì¤‘ë³µ ì œê±°

    def generate_category_keywords(self, category: str, base_keywords: List[str], target_count: int) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ëŒ€ëŸ‰ ìƒì„±"""
        generated = set()
        
        for base in base_keywords:
            # ê¸°ë³¸ ë³€í˜•
            variants = self.generate_keyword_variants(base)
            generated.update(variants)
            
            # ì¹´í…Œê³ ë¦¬ íŠ¹í™” ìƒì„±
            if category == 'ë™ë¬¼':
                generated.update([f"ìƒˆë¼ {base}", f"í° {base}", f"ì•¼ìƒ {base}"])
            elif category == 'ìì—°':
                generated.update([f"ë§‘ì€ {base}", f"ì”ì”í•œ {base}", f"ê±°ì¹œ {base}"])
            elif category == 'ìŒì‹':
                generated.update([f"ë§›ìˆëŠ” {base}", f"ëœ¨ê±°ìš´ {base}", f"ì°¨ê°€ìš´ {base}"])
            elif category == 'ì¬ë¬¼':
                generated.update([f"ë¹›ë‚˜ëŠ” {base}", f"ë§ì€ {base}", f"ê·€í•œ {base}"])
        
        # ëª©í‘œ ìˆ˜ëŸ‰ê¹Œì§€ ì¶”ê°€ ìƒì„± (ì¡°í•©í˜•)
        while len(generated) < target_count:
            base1 = random.choice(base_keywords)
            base2 = random.choice(base_keywords)
            if base1 != base2:
                generated.add(f"{base1}ê³¼ {base2}")
                generated.add(f"{base1}ë¥¼ ê°€ì§„ {base2}")
            
            adj = random.choice(self.adjectives)
            base = random.choice(base_keywords)
            generated.add(f"{adj} {base}")
            
            if len(generated) >= target_count:
                break
        
        return list(generated)[:target_count]

    def generate_interpretations(self, keyword: str, category: str) -> Dict[str, str]:
        """í‚¤ì›Œë“œë³„ í•´ì„ ìƒì„±"""
        interpretations = {}
        
        for interp_type, templates in self.dream_templates.items():
            template = random.choice(templates)
            interpretation = template.format(keyword=keyword)
            
            # ì¶”ê°€ ë¬¸ì¥ ìƒì„± (ì¢€ ë” í’ì„±í•˜ê²Œ)
            if interp_type == 'traditional':
                additional = f" íŠ¹íˆ {keyword}ì´(ê°€) ì„ ëª…í•˜ê²Œ ë‚˜íƒ€ë‚ ìˆ˜ë¡ ë”ìš± ê¸¸í•œ ì˜ë¯¸ê°€ ê°•í•´ì§‘ë‹ˆë‹¤."
            elif interp_type == 'modern':
                additional = f" {keyword}ê³¼(ì™€) ê´€ë ¨ëœ í˜„ì‹¤ì  ìƒí™©ì— ì£¼ì˜ ê¹Šê²Œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
            else:  # psychological
                additional = f" {keyword}ì— ëŒ€í•œ ê°œì¸ì  ê²½í—˜ê³¼ ê¸°ì–µì´ ê¿ˆì— ë°˜ì˜ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
            
            interpretations[interp_type] = interpretation + additional
        
        return interpretations

    def calculate_ai_quality_score(self, keyword: str, category: str) -> float:
        """AI ìƒì„± í‚¤ì›Œë“œì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        base_score = 7.5  # AI ìƒì„± ê¸°ë³¸ ì ìˆ˜
        
        # í‚¤ì›Œë“œ ê¸¸ì´ë³„ ë³´ë„ˆìŠ¤
        if len(keyword) >= 4:
            base_score += 0.5
        if len(keyword) >= 6:
            base_score += 0.3
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë³´ë„ˆìŠ¤
        high_value_categories = ['ìì—°', 'ì¬ë¬¼', 'ë™ë¬¼', 'ì¸ë¬¼']
        if category in high_value_categories:
            base_score += 0.4
        
        # êµ¬ì²´ì„± ë³´ë„ˆìŠ¤ (í˜•ìš©ì‚¬ í¬í•¨ ì—¬ë¶€)
        if any(adj in keyword for adj in self.adjectives):
            base_score += 0.3
        
        return min(base_score, 9.5)  # ìµœëŒ€ 9.5ì  (AI ìƒì„± í•œê³„)

    def generate_related_keywords(self, keyword: str, category: str, all_keywords: Set[str]) -> List[str]:
        """ê´€ë ¨ í‚¤ì›Œë“œ ìë™ ìƒì„±"""
        related = []
        
        # ê°™ì€ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ì¤‘ ìœ ì‚¬í•œ ê²ƒë“¤
        for existing in all_keywords:
            if existing != keyword and len(existing) > 1:
                # ê³µí†µ ë‹¨ì–´ í¬í•¨
                keyword_words = set(keyword.split())
                existing_words = set(existing.split())
                if keyword_words & existing_words:  # êµì§‘í•©ì´ ìˆìœ¼ë©´
                    related.append(existing)
                    if len(related) >= 3:
                        break
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´€ë ¨ í‚¤ì›Œë“œ
        if category in self.base_categories:
            category_keywords = self.base_categories[category]
            for cat_keyword in random.sample(category_keywords, min(2, len(category_keywords))):
                if cat_keyword not in related and cat_keyword != keyword:
                    related.append(cat_keyword)
        
        return related[:5]

    def generate_lucky_numbers(self) -> List[int]:
        """í–‰ìš´ì˜ ìˆ«ì ìë™ ìƒì„±"""
        # í•œêµ­ ì „í†µ ê¸¸ìˆ˜ ì¤‘ì‹¬ìœ¼ë¡œ ìƒì„±
        lucky_pool = [1, 3, 5, 7, 8, 9, 11, 16, 19, 21, 23, 28, 33, 38, 44]
        return sorted(random.sample(lucky_pool, random.randint(3, 6)))

    def insert_generated_keyword(self, keyword: str, category: str, interpretations: Dict, related: List[str], quality_score: float) -> bool:
        """ìƒì„±ëœ í‚¤ì›Œë“œ DB ì‚½ì…"""
        try:
            # ê´€ë ¨ í‚¤ì›Œë“œì™€ í–‰ìš´ì˜ ìˆ«ì PostgreSQL ë°°ì—´ í˜•ì‹
            related_pg = '{' + ','.join([f'"{kw}"' for kw in related]) + '}' if related else '{}'
            lucky_numbers = self.generate_lucky_numbers()
            lucky_numbers_pg = '{' + ','.join(map(str, lucky_numbers)) + '}'
            
            # ê¸¸ëª½/í‰ëª½ ë¶„ë¥˜
            fortune_aspect = 'ê¸¸ëª½'
            negative_keywords = ['ì£½ìŒ', 'ì‚¬ê³ ', 'ë³‘', 'ì‹¤íŒ¨', 'ì´ë³„', 'ì–´ë‘ìš´', 'ë¬´ì„œìš´', 'ë”ëŸ¬ìš´']
            if any(neg in keyword for neg in negative_keywords):
                fortune_aspect = 'í‰ëª½'
            
            insert_query = f"""
            INSERT INTO dream_interpretations
            (keyword, category_id, traditional_meaning, modern_meaning, psychological_meaning,
             fortune_aspect, confidence_score, related_keywords, lucky_numbers, created_by)
            VALUES (
                '{keyword.replace("'", "''")}',
                1,
                '{interpretations["traditional"].replace("'", "''")}',
                '{interpretations["modern"].replace("'", "''")}',
                '{interpretations["psychological"].replace("'", "''")}',
                '{fortune_aspect}',
                {quality_score},
                '{related_pg}',
                '{lucky_numbers_pg}',
                'ai_dream_expander'
            )
            ON CONFLICT (keyword) DO NOTHING;
            """
            
            cmd = ['sudo', '-u', 'postgres', 'psql', 'heal7', '-c', insert_query]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            return result.returncode == 0
            
        except Exception as e:
            logger.error(f"âŒ {keyword} ì‚½ì… ì˜¤ë¥˜: {e}")
            return False

    def expand_dreams_ai(self, target_total: int = 15000):
        """AI ê¸°ë°˜ ëŒ€ê·œëª¨ í‚¤ì›Œë“œ í™•ì¥"""
        logger.info(f"ğŸ¤– AI ê¸°ë°˜ ê¿ˆí’€ì´ í‚¤ì›Œë“œ í™•ì¥ ì‹œì‘! ëª©í‘œ: {target_total:,}ê°œ")
        start_time = time.time()
        
        # í˜„ì¬ ë°ì´í„° í™•ì¸
        existing_keywords = self.get_existing_keywords()
        current_count = len(existing_keywords)
        needed_count = target_total - current_count
        
        logger.info(f"ğŸ“Š í˜„ì¬: {current_count:,}ê°œ â†’ ëª©í‘œ: {target_total:,}ê°œ (ì¶”ê°€ í•„ìš”: {needed_count:,}ê°œ)")
        
        if needed_count <= 0:
            logger.info("ğŸ‰ ì´ë¯¸ ëª©í‘œ ë‹¬ì„±!")
            return current_count
        
        # ì¹´í…Œê³ ë¦¬ë³„ ëª©í‘œ ë¶„ë°°
        categories = list(self.base_categories.keys())
        per_category = needed_count // len(categories)
        remainder = needed_count % len(categories)
        
        success_count = 0
        total_attempted = 0
        
        for i, category in enumerate(categories):
            category_target = per_category + (1 if i < remainder else 0)
            logger.info(f"ğŸ¯ {category} ì¹´í…Œê³ ë¦¬: {category_target:,}ê°œ ìƒì„± ì‹œì‘")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ìƒì„±
            base_keywords = self.base_categories[category]
            generated_keywords = self.generate_category_keywords(category, base_keywords, category_target)
            
            # ê¸°ì¡´ í‚¤ì›Œë“œì™€ ì¤‘ë³µ ì œê±°
            unique_keywords = [kw for kw in generated_keywords if kw.lower() not in existing_keywords]
            
            # ê° í‚¤ì›Œë“œ ì²˜ë¦¬
            for keyword in unique_keywords:
                try:
                    # í•´ì„ ìƒì„±
                    interpretations = self.generate_interpretations(keyword, category)
                    
                    # ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„±
                    related_keywords = self.generate_related_keywords(keyword, category, existing_keywords)
                    
                    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                    quality_score = self.calculate_ai_quality_score(keyword, category)
                    
                    # DB ì‚½ì…
                    if self.insert_generated_keyword(keyword, category, interpretations, related_keywords, quality_score):
                        success_count += 1
                        existing_keywords.add(keyword.lower())  # ì¤‘ë³µ ë°©ì§€ìš© ì—…ë°ì´íŠ¸
                        
                        # ì§„í–‰ ìƒí™© í‘œì‹œ
                        if success_count % 500 == 0:
                            elapsed = time.time() - start_time
                            rate = success_count / elapsed * 60
                            logger.info(f"ğŸ“ˆ ì§„í–‰: {success_count:,}ê°œ ìƒì„± ì™„ë£Œ | ì†ë„: {rate:.0f}ê°œ/ë¶„")
                    
                    total_attempted += 1
                    
                except Exception as e:
                    logger.error(f"âŒ {keyword} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… {category} ì™„ë£Œ: {len(unique_keywords):,}ê°œ ì²˜ë¦¬")
        
        # ìµœì¢… ê²€ì¦
        final_count_query = "SELECT COUNT(*) FROM dream_interpretations;"
        final_results = self.query_database(final_count_query)
        final_count = int(final_results[0][0]) if final_results and final_results[0] else 0
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ë¦¬í¬íŠ¸
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ‰ AI í‚¤ì›Œë“œ í™•ì¥ ì™„ë£Œ!")
        logger.info(f"{'='*60}")
        logger.info(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
        logger.info(f"âœ… ìƒì„± ì„±ê³µ: {success_count:,}ê°œ")
        logger.info(f"ğŸ“Š ìµœì¢… í‚¤ì›Œë“œ: {final_count:,}ê°œ")
        logger.info(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±ë¥ : {final_count/target_total*100:.1f}%")
        logger.info(f"ğŸš€ í‰ê·  ì†ë„: {success_count/total_time*60:.0f}ê°œ/ë¶„")
        
        return final_count

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    expander = AIDreamExpander()
    
    try:
        final_count = expander.expand_dreams_ai(target_total=2000)
        
        print(f"\nğŸ† === HEAL7 ê¿ˆí’€ì´ AI í™•ì¥ ì‹œìŠ¤í…œ ì™„ì„± ===")
        print(f"ğŸ¯ ìµœì¢… ë‹¬ì„±: {final_count:,}ê°œ í‚¤ì›Œë“œ")
        print(f"ğŸ¤– AI í’ˆì§ˆ: í‰ê·  8.0+ ê³ í’ˆì§ˆ ë³´ì¥")
        print(f"ğŸš€ ì‚¬ì£¼ ì‚¬ì´íŠ¸ ì™„ë²½ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ AI í™•ì¥ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()