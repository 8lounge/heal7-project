"""
Paperwork AI Integration API Gateway
ì •ë¶€ í¬í„¸ ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œê³¼ Paperwork AI ì—°ë™ ê²Œì´íŠ¸ì›¨ì´

Author: Paperwork AI Team
Version: 2.0.0
Date: 2025-08-23
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib
import hmac

import aiohttp
from pydantic import BaseModel, validator
import backoff

logger = logging.getLogger(__name__)

class DataType(Enum):
    PROGRAM = "program"
    TEMPLATE = "template" 
    PATTERN = "pattern"
    ANALYSIS = "analysis"
    NOTIFICATION = "notification"

class SyncStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRY = "retry"

@dataclass
class SyncData:
    """ë™ê¸°í™”í•  ë°ì´í„° êµ¬ì¡°"""
    data_type: DataType
    data_id: str
    institution_id: str
    content: Dict
    metadata: Dict
    priority: int = 1  # 1=ë†’ìŒ, 2=ë³´í†µ, 3=ë‚®ìŒ
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()

class PaperworkConnector:
    """Paperwork AI ì—°ë™ ì»¤ë„¥í„°"""
    
    def __init__(self, base_url: str, api_key: str, secret_key: str = None):
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.secret_key = secret_key
        
        # API ì—”ë“œí¬ì¸íŠ¸
        self.endpoints = {
            'sync': '/api/government-portal/sync',
            'templates': '/api/government-portal/templates',
            'programs': '/api/government-portal/programs',
            'patterns': '/api/government-portal/patterns',
            'health': '/api/government-portal/health',
            'webhook': '/api/government-portal/webhook'
        }
        
        # HTTP ì„¸ì…˜
        self.session = None
        self.headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'GovernmentPortalScraper/2.0',
            'Authorization': f'Bearer {api_key}'
        }
        
        # ë™ê¸°í™” í
        self.sync_queue: List[SyncData] = []
        self.max_queue_size = 1000
        self.batch_size = 50  # í•œ ë²ˆì— ì „ì†¡í•  ìµœëŒ€ í•­ëª© ìˆ˜
        
        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = 3
        self.retry_delay = 5  # ì´ˆ
        
        # í†µê³„
        self.stats = {
            'total_syncs': 0,
            'successful_syncs': 0,
            'failed_syncs': 0,
            'queue_size': 0,
            'last_sync_time': None,
            'connection_errors': 0
        }
        
        logger.info(f"ğŸ“¡ Paperwork AI Connector ì´ˆê¸°í™”: {base_url}")
    
    async def initialize(self):
        """ì»¤ë„¥í„° ì´ˆê¸°í™”"""
        if not self.session:
            timeout = aiohttp.ClientTimeout(total=30, connect=10)
            connector = aiohttp.TCPConnector(limit=10)
            
            self.session = aiohttp.ClientSession(
                headers=self.headers,
                timeout=timeout,
                connector=connector
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.test_connection()
            
            logger.info("âœ… Paperwork AI ì»¤ë„¥í„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def close(self):
        """ì»¤ë„¥í„° ì •ë¦¬"""
        if self.session:
            await self.session.close()
            self.session = None
            logger.info("ğŸ”’ Paperwork AI ì»¤ë„¥í„° ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
    
    async def test_connection(self) -> bool:
        """Paperwork AI ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            url = f"{self.base_url}{self.endpoints['health']}"
            
            async with self.session.get(url) as response:
                if response.status == 200:
                    result = await response.json()
                    logger.info("âœ… Paperwork AI ì—°ê²° ì„±ê³µ")
                    return True
                else:
                    logger.warning(f"âš ï¸ Paperwork AI ì—°ê²° ì´ìƒ: HTTP {response.status}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ Paperwork AI ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            self.stats['connection_errors'] += 1
            return False
    
    def add_to_sync_queue(self, sync_data: SyncData):
        """ë™ê¸°í™” íì— ë°ì´í„° ì¶”ê°€"""
        if len(self.sync_queue) >= self.max_queue_size:
            # ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
            removed = self.sync_queue.pop(0)
            logger.warning(f"âš ï¸ í ì˜¤ë²„í”Œë¡œìš°, í•­ëª© ì œê±°: {removed.data_id}")
        
        self.sync_queue.append(sync_data)
        self.stats['queue_size'] = len(self.sync_queue)
        
        logger.debug(f"ğŸ“¥ ë™ê¸°í™” í ì¶”ê°€: {sync_data.data_type.value}/{sync_data.data_id}")
    
    async def sync_programs(self, programs: List[Dict], institution_id: str) -> Dict:
        """ì§€ì›ì‚¬ì—… í”„ë¡œê·¸ë¨ ë™ê¸°í™”"""
        logger.info(f"ğŸ“Š í”„ë¡œê·¸ë¨ ë™ê¸°í™” ì‹œì‘: {len(programs)}ê°œ ({institution_id})")
        
        # ìš°ì„ ìˆœìœ„ë³„ ë¶„ë¥˜
        priority_programs = self.classify_by_priority(programs)
        
        sync_results = {
            'total_programs': len(programs),
            'successful_syncs': 0,
            'failed_syncs': 0,
            'sync_details': []
        }
        
        # ìš°ì„ ìˆœìœ„ë³„ ë™ê¸°í™”
        for priority, program_list in priority_programs.items():
            batch_results = await self.sync_program_batch(program_list, institution_id, priority)
            
            sync_results['successful_syncs'] += batch_results['successful']
            sync_results['failed_syncs'] += batch_results['failed']
            sync_results['sync_details'].extend(batch_results['details'])
        
        logger.info(f"âœ… í”„ë¡œê·¸ë¨ ë™ê¸°í™” ì™„ë£Œ: {sync_results['successful_syncs']}/{len(programs)} ì„±ê³µ")
        return sync_results
    
    def classify_by_priority(self, programs: List[Dict]) -> Dict[int, List[Dict]]:
        """í”„ë¡œê·¸ë¨ ìš°ì„ ìˆœìœ„ ë¶„ë¥˜"""
        priority_programs = {1: [], 2: [], 3: []}
        
        for program in programs:
            # ìš°ì„ ìˆœìœ„ ê²°ì • ë¡œì§
            priority = self.determine_program_priority(program)
            priority_programs[priority].append(program)
        
        return priority_programs
    
    def determine_program_priority(self, program: Dict) -> int:
        """í”„ë¡œê·¸ë¨ ìš°ì„ ìˆœìœ„ ê²°ì •"""
        # 1ìˆœìœ„: ìƒˆë¡œìš´ í”„ë¡œê·¸ë¨ì´ê±°ë‚˜ ì¤‘ìš”í•œ ë³€ê²½ì‚¬í•­
        if program.get('is_new', False):
            return 1
        
        # ë§ˆê° ì„ë°•í•œ í”„ë¡œê·¸ë¨
        period = program.get('application_period', '')
        if 'ë§ˆê°' in period or 'ì¢…ë£Œ' in period or 'ì„ë°•' in period:
            return 1
        
        # ì£¼ìš” ê¸°ê´€ì˜ í”„ë¡œê·¸ë¨
        agency = program.get('agency', '')
        major_agencies = ['ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€', 'ì¤‘ì†Œê¸°ì—…ì§„í¥ê³µë‹¨', 'NIPA', 'ê¸°ìˆ ë³´ì¦ê¸°ê¸ˆ']
        if any(major in agency for major in major_agencies):
            return 1
        
        # 2ìˆœìœ„: ì¼ë°˜ì ì¸ ì—…ë°ì´íŠ¸
        if program.get('hash_value') != program.get('previous_hash'):
            return 2
        
        # 3ìˆœìœ„: ë³€ê²½ì‚¬í•­ ì—†ìŒ
        return 3
    
    async def sync_program_batch(self, programs: List[Dict], institution_id: str, priority: int) -> Dict:
        """í”„ë¡œê·¸ë¨ ë°°ì¹˜ ë™ê¸°í™”"""
        if not programs:
            return {'successful': 0, 'failed': 0, 'details': []}
        
        url = f"{self.base_url}{self.endpoints['programs']}"
        
        sync_payload = {
            'institution_id': institution_id,
            'programs': programs,
            'priority': priority,
            'sync_timestamp': datetime.now().isoformat(),
            'batch_info': {
                'total_count': len(programs),
                'batch_priority': priority,
                'scraper_version': '2.0.0'
            }
        }
        
        # ì„œëª… ìƒì„± (ë³´ì•ˆ)
        if self.secret_key:
            sync_payload['signature'] = self.generate_signature(sync_payload)
        
        return await self.send_batch_data(url, sync_payload)
    
    async def sync_templates(self, templates: List[Dict], institution_id: str) -> Dict:
        """í…œí”Œë¦¿ ë™ê¸°í™”"""
        logger.info(f"ğŸ“‹ í…œí”Œë¦¿ ë™ê¸°í™” ì‹œì‘: {len(templates)}ê°œ ({institution_id})")
        
        url = f"{self.base_url}{self.endpoints['templates']}"
        
        sync_payload = {
            'institution_id': institution_id,
            'templates': templates,
            'sync_timestamp': datetime.now().isoformat(),
            'template_metadata': {
                'total_count': len(templates),
                'generation_method': 'ai_auto',
                'quality_threshold': 8.0
            }
        }
        
        if self.secret_key:
            sync_payload['signature'] = self.generate_signature(sync_payload)
        
        result = await self.send_batch_data(url, sync_payload)
        
        logger.info(f"âœ… í…œí”Œë¦¿ ë™ê¸°í™” ì™„ë£Œ: {result['successful']}/{len(templates)} ì„±ê³µ")
        return result
    
    async def sync_patterns(self, patterns: Dict, institution_id: str) -> Dict:
        """íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë™ê¸°í™”"""
        logger.info(f"ğŸ§  íŒ¨í„´ ë™ê¸°í™” ì‹œì‘: {institution_id}")
        
        url = f"{self.base_url}{self.endpoints['patterns']}"
        
        sync_payload = {
            'institution_id': institution_id,
            'patterns': patterns,
            'sync_timestamp': datetime.now().isoformat(),
            'analysis_metadata': {
                'pattern_count': len(patterns),
                'confidence_scores': self.extract_confidence_scores(patterns),
                'analyzer_version': '2.0.0'
            }
        }
        
        if self.secret_key:
            sync_payload['signature'] = self.generate_signature(sync_payload)
        
        result = await self.send_batch_data(url, sync_payload)
        
        logger.info(f"âœ… íŒ¨í„´ ë™ê¸°í™” ì™„ë£Œ")
        return result
    
    @backoff.on_exception(
        backoff.expo,
        (aiohttp.ClientError, asyncio.TimeoutError),
        max_tries=3,
        max_time=60
    )
    async def send_batch_data(self, url: str, payload: Dict) -> Dict:
        """ë°°ì¹˜ ë°ì´í„° ì „ì†¡ (ì¬ì‹œë„ í¬í•¨)"""
        if not self.session:
            await self.initialize()
        
        try:
            self.stats['total_syncs'] += 1
            
            async with self.session.post(url, json=payload) as response:
                response_data = await response.json()
                
                if response.status == 200:
                    self.stats['successful_syncs'] += 1
                    self.stats['last_sync_time'] = datetime.now()
                    
                    return {
                        'successful': response_data.get('processed_count', 0),
                        'failed': response_data.get('failed_count', 0),
                        'details': response_data.get('details', []),
                        'response_data': response_data
                    }
                else:
                    self.stats['failed_syncs'] += 1
                    error_msg = f"HTTP {response.status}: {response_data.get('message', 'Unknown error')}"
                    
                    logger.error(f"âŒ ë°°ì¹˜ ì „ì†¡ ì‹¤íŒ¨: {error_msg}")
                    raise aiohttp.ClientResponseError(
                        request_info=response.request_info,
                        history=response.history,
                        status=response.status,
                        message=error_msg
                    )
                    
        except Exception as e:
            self.stats['failed_syncs'] += 1
            logger.error(f"âŒ ë°°ì¹˜ ì „ì†¡ ì˜ˆì™¸: {str(e)}")
            raise
    
    def generate_signature(self, payload: Dict) -> str:
        """ìš”ì²­ ì„œëª… ìƒì„± (ë³´ì•ˆ)"""
        if not self.secret_key:
            return ""
        
        # í˜ì´ë¡œë“œë¥¼ ì •ë ¬ëœ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        payload_str = json.dumps(payload, sort_keys=True, separators=(',', ':'))
        
        # HMAC-SHA256 ì„œëª… ìƒì„±
        signature = hmac.new(
            self.secret_key.encode('utf-8'),
            payload_str.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        
        return signature
    
    def extract_confidence_scores(self, patterns: Dict) -> Dict:
        """íŒ¨í„´ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ"""
        scores = {}
        
        for pattern_type, pattern_data in patterns.items():
            if isinstance(pattern_data, dict) and 'confidence_score' in pattern_data:
                scores[pattern_type] = pattern_data['confidence_score']
        
        return scores
    
    async def send_notification(self, notification_type: str, message: str, metadata: Dict = None) -> bool:
        """ì•Œë¦¼ ì „ì†¡"""
        try:
            url = f"{self.base_url}{self.endpoints['webhook']}"
            
            notification_payload = {
                'type': notification_type,
                'message': message,
                'metadata': metadata or {},
                'timestamp': datetime.now().isoformat(),
                'source': 'government_portal_scraper'
            }
            
            if self.secret_key:
                notification_payload['signature'] = self.generate_signature(notification_payload)
            
            if not self.session:
                await self.initialize()
            
            async with self.session.post(url, json=notification_payload) as response:
                if response.status == 200:
                    logger.info(f"ğŸ“¡ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {notification_type}")
                    return True
                else:
                    logger.warning(f"âš ï¸ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: HTTP {response.status}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ ì•Œë¦¼ ì „ì†¡ ì˜ˆì™¸: {str(e)}")
            return False
    
    async def process_sync_queue(self):
        """ë™ê¸°í™” í ì²˜ë¦¬"""
        if not self.sync_queue:
            return
        
        logger.info(f"ğŸ”„ ë™ê¸°í™” í ì²˜ë¦¬ ì‹œì‘: {len(self.sync_queue)}ê°œ í•­ëª©")
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        self.sync_queue.sort(key=lambda x: (x.priority, x.created_at))
        
        # ë°°ì¹˜ë³„ ì²˜ë¦¬
        while self.sync_queue:
            batch = self.sync_queue[:self.batch_size]
            self.sync_queue = self.sync_queue[self.batch_size:]
            
            await self.process_sync_batch(batch)
            
            # ë°°ì¹˜ê°„ ë”œë ˆì´
            await asyncio.sleep(1)
        
        self.stats['queue_size'] = 0
        logger.info("âœ… ë™ê¸°í™” í ì²˜ë¦¬ ì™„ë£Œ")
    
    async def process_sync_batch(self, batch: List[SyncData]):
        """ë™ê¸°í™” ë°°ì¹˜ ì²˜ë¦¬"""
        grouped_data = self.group_sync_data_by_type(batch)
        
        for data_type, items in grouped_data.items():
            try:
                if data_type == DataType.PROGRAM:
                    await self.sync_programs_from_queue(items)
                elif data_type == DataType.TEMPLATE:
                    await self.sync_templates_from_queue(items)
                elif data_type == DataType.PATTERN:
                    await self.sync_patterns_from_queue(items)
                elif data_type == DataType.NOTIFICATION:
                    await self.send_notifications_from_queue(items)
                    
            except Exception as e:
                logger.error(f"âŒ {data_type.value} ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def group_sync_data_by_type(self, batch: List[SyncData]) -> Dict[DataType, List[SyncData]]:
        """ë™ê¸°í™” ë°ì´í„°ë¥¼ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”"""
        grouped = {}
        
        for item in batch:
            if item.data_type not in grouped:
                grouped[item.data_type] = []
            grouped[item.data_type].append(item)
        
        return grouped
    
    async def sync_programs_from_queue(self, items: List[SyncData]):
        """íì˜ í”„ë¡œê·¸ë¨ ë°ì´í„° ë™ê¸°í™”"""
        programs_by_institution = {}
        
        for item in items:
            institution = item.institution_id
            if institution not in programs_by_institution:
                programs_by_institution[institution] = []
            programs_by_institution[institution].append(item.content)
        
        for institution, programs in programs_by_institution.items():
            await self.sync_programs(programs, institution)
    
    async def sync_templates_from_queue(self, items: List[SyncData]):
        """íì˜ í…œí”Œë¦¿ ë°ì´í„° ë™ê¸°í™”"""
        templates_by_institution = {}
        
        for item in items:
            institution = item.institution_id
            if institution not in templates_by_institution:
                templates_by_institution[institution] = []
            templates_by_institution[institution].append(item.content)
        
        for institution, templates in templates_by_institution.items():
            await self.sync_templates(templates, institution)
    
    async def sync_patterns_from_queue(self, items: List[SyncData]):
        """íì˜ íŒ¨í„´ ë°ì´í„° ë™ê¸°í™”"""
        for item in items:
            await self.sync_patterns(item.content, item.institution_id)
    
    async def send_notifications_from_queue(self, items: List[SyncData]):
        """íì˜ ì•Œë¦¼ ì „ì†¡"""
        for item in items:
            await self.send_notification(
                notification_type=item.metadata.get('type', 'info'),
                message=item.content.get('message', ''),
                metadata=item.metadata
            )
    
    def get_stats(self) -> Dict:
        """ì»¤ë„¥í„° í†µê³„ ì¡°íšŒ"""
        return {
            **self.stats,
            'success_rate': (self.stats['successful_syncs'] / max(1, self.stats['total_syncs'])) * 100,
            'queue_size': len(self.sync_queue),
            'is_connected': bool(self.session),
            'last_connection_test': datetime.now().isoformat()
        }
    
    async def health_check(self) -> Dict:
        """ì»¤ë„¥í„° ìƒíƒœ í™•ì¸"""
        health_status = {
            'connector_status': 'healthy',
            'paperwork_connection': False,
            'queue_health': 'normal',
            'stats': self.get_stats(),
            'last_check': datetime.now().isoformat()
        }
        
        # Paperwork AI ì—°ê²° í™•ì¸
        health_status['paperwork_connection'] = await self.test_connection()
        
        # í ê±´ê°•ë„ í™•ì¸
        queue_size = len(self.sync_queue)
        if queue_size > self.max_queue_size * 0.8:
            health_status['queue_health'] = 'warning'
        elif queue_size >= self.max_queue_size:
            health_status['queue_health'] = 'critical'
        
        # ì „ì²´ ìƒíƒœ íŒì •
        if not health_status['paperwork_connection'] or health_status['queue_health'] == 'critical':
            health_status['connector_status'] = 'unhealthy'
        elif health_status['queue_health'] == 'warning':
            health_status['connector_status'] = 'warning'
        
        return health_status