#!/usr/bin/env python3
"""
HEAL7 ìµœì‹  AI ëª¨ë¸ ì—°ë™ ì²´í¬ ë° í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ (2025)
ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ë“¤: Gemini 2.0 Flash, GPT-4o, Claude 3.5 Sonnet, Perplexity, ë„¤ì´ë²„ Clova X
"""

import asyncio
import aiohttp
import json
import os
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv('/home/ubuntu/project/backend/api/.env.ai')

class AIModelConnector2025:
    """2025ë…„ ìµœì‹  AI ëª¨ë¸ë“¤ì˜ ì—°ë™ ìƒíƒœ ì²´í¬"""
    
    def __init__(self):
        self.models = {
            "gemini-2.0-flash": {
                "name": "Gemini 2.0 Flash",
                "provider": "Google",
                "endpoint": "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent",
                "api_key_env": "GOOGLE_API_KEY",
                "is_free": True,
                "cost_per_1k_tokens": 0.0,
                "features": ["text", "vision", "code", "multimodal"],
                "max_tokens": 32768,
                "speed": "very_fast",
                "status": "unknown"
            },
            "gpt-4o": {
                "name": "GPT-4o",
                "provider": "OpenAI", 
                "endpoint": "https://api.openai.com/v1/chat/completions",
                "api_key_env": "OPENAI_API_KEY",
                "is_free": False,
                "cost_per_1k_tokens": 0.015,  # input cost
                "features": ["text", "vision", "code", "multimodal"],
                "max_tokens": 128000,
                "speed": "fast",
                "status": "unknown"
            },
            "gpt-4o-mini": {
                "name": "GPT-4o Mini", 
                "provider": "OpenAI",
                "endpoint": "https://api.openai.com/v1/chat/completions",
                "api_key_env": "OPENAI_API_KEY",
                "is_free": False,
                "cost_per_1k_tokens": 0.00015,  # very cheap!
                "features": ["text", "vision", "code"],
                "max_tokens": 128000,
                "speed": "very_fast",
                "status": "unknown"
            },
            "claude-3.5-sonnet": {
                "name": "Claude 3.5 Sonnet",
                "provider": "Anthropic",
                "endpoint": "https://api.anthropic.com/v1/messages",
                "api_key_env": "ANTHROPIC_API_KEY", 
                "is_free": False,
                "cost_per_1k_tokens": 0.003,
                "features": ["text", "code", "analysis", "safety"],
                "max_tokens": 200000,
                "speed": "medium",
                "status": "unknown"
            },
            "perplexity-sonar": {
                "name": "Perplexity Sonar",
                "provider": "Perplexity AI",
                "endpoint": "https://api.perplexity.ai/chat/completions",
                "api_key_env": "PERPLEXITY_API_KEY",
                "is_free": False,
                "cost_per_1k_tokens": 0.005,
                "features": ["realtime_search", "citations", "web_access"],
                "max_tokens": 4096,
                "speed": "medium",
                "status": "unknown"
            },
            "clova-x": {
                "name": "ë„¤ì´ë²„ Clova X",
                "provider": "Naver",
                "endpoint": "https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003",
                "api_key_env": "CLOVAX_API_KEY",
                "is_free": False,
                "cost_per_1k_tokens": 0.002,  # ì¶”ì •
                "features": ["korean", "text", "conversation"],
                "max_tokens": 4096,
                "speed": "fast",
                "status": "unknown"
            }
        }
        
        self.test_results = {}
    
    async def check_api_keys(self) -> Dict[str, Any]:
        """API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸"""
        key_status = {}
        
        for model_id, config in self.models.items():
            api_key = os.getenv(config["api_key_env"])
            
            if api_key and len(api_key) > 10:
                key_status[model_id] = {
                    "available": True,
                    "key_preview": f"{api_key[:10]}...{api_key[-4:]}",
                    "key_length": len(api_key)
                }
                print(f"âœ… {config['name']}: API í‚¤ ì„¤ì •ë¨ ({api_key[:10]}...)")
            else:
                key_status[model_id] = {
                    "available": False,
                    "key_preview": None,
                    "key_length": 0
                }
                print(f"âŒ {config['name']}: API í‚¤ ëˆ„ë½")
        
        return key_status
    
    async def test_gemini_2_flash(self) -> Dict[str, Any]:
        """Gemini 2.0 Flash í…ŒìŠ¤íŠ¸"""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        url = f"{self.models['gemini-2.0-flash']['endpoint']}?key={api_key}"
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": "ì•ˆë…•í•˜ì„¸ìš”! Gemini 2.0 Flash í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”."
                }]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 100
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                async with session.post(url, json=payload, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    elapsed_time = time.time() - start_time
                    
                    if response.status == 200:
                        data = await response.json()
                        content = data["candidates"][0]["content"]["parts"][0]["text"]
                        
                        return {
                            "success": True,
                            "response": content,
                            "response_time": elapsed_time,
                            "model_version": "gemini-2.0-flash-exp"
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": elapsed_time
                        }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def test_gpt_4o(self, model_name: str = "gpt-4o") -> Dict[str, Any]:
        """GPT-4o / GPT-4o-mini í…ŒìŠ¤íŠ¸"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": f"ì•ˆë…•í•˜ì„¸ìš”! {model_name} í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”."}
            ],
            "max_tokens": 100,
            "temperature": 0.7
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                async with session.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    elapsed_time = time.time() - start_time
                    
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"]
                        
                        return {
                            "success": True,
                            "response": content,
                            "response_time": elapsed_time,
                            "tokens_used": data["usage"]["total_tokens"],
                            "model_version": data["model"]
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": elapsed_time
                        }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def test_claude_35_sonnet(self) -> Dict[str, Any]:
        """Claude 3.5 Sonnet í…ŒìŠ¤íŠ¸"""
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        headers = {
            "x-api-key": api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }
        
        payload = {
            "model": "claude-3-5-sonnet-20241022",  # ìµœì‹  ë²„ì „
            "max_tokens": 100,
            "messages": [
                {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! Claude 3.5 Sonnet í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê°„ë‹¨íˆ ì¸ì‚¬í•´ì£¼ì„¸ìš”."}
            ],
            "temperature": 0.7
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                async with session.post(
                    "https://api.anthropic.com/v1/messages",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    elapsed_time = time.time() - start_time
                    
                    if response.status == 200:
                        data = await response.json()
                        content = data["content"][0]["text"]
                        
                        return {
                            "success": True,
                            "response": content,
                            "response_time": elapsed_time,
                            "model_version": data["model"],
                            "tokens_used": data["usage"]["input_tokens"] + data["usage"]["output_tokens"]
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": elapsed_time
                        }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def test_perplexity_sonar(self) -> Dict[str, Any]:
        """Perplexity Sonar í…ŒìŠ¤íŠ¸"""
        api_key = os.getenv("PERPLEXITY_API_KEY")
        if not api_key:
            return {"success": False, "error": "API í‚¤ ì—†ìŒ"}
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "sonar",  # ìµœì‹  ì›¹ ê²€ìƒ‰ ëª¨ë¸
            "messages": [
                {"role": "user", "content": "2025ë…„ ìµœì‹  AI íŠ¸ë Œë“œë¥¼ ê°„ë‹¨íˆ ì•Œë ¤ì£¼ì„¸ìš”."}
            ],
            "max_tokens": 150,
            "temperature": 0.7
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                start_time = time.time()
                async with session.post(
                    "https://api.perplexity.ai/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as response:
                    elapsed_time = time.time() - start_time
                    
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"]
                        citations = data.get("citations", [])
                        
                        return {
                            "success": True,
                            "response": content,
                            "response_time": elapsed_time,
                            "citations": citations,
                            "has_realtime_data": True,
                            "model_version": data.get("model", "unknown")
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": elapsed_time
                        }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def test_clova_x(self) -> Dict[str, Any]:
        """ë„¤ì´ë²„ Clova X í…ŒìŠ¤íŠ¸ (ì¶”í›„ êµ¬í˜„)"""
        api_key = os.getenv("CLOVAX_API_KEY")
        if not api_key:
            return {
                "success": False, 
                "error": "API í‚¤ ì„¤ì • ì•ˆë¨ - ì¶”í›„ ë„¤ì´ë²„ í´ë¡œë°” ìŠ¤íŠœë””ì˜¤ì—ì„œ ë°œê¸‰ í•„ìš”",
                "note": "HyperCLOVA X APIëŠ” ë„¤ì´ë²„ í´ë¡œë°” ìŠ¤íŠœë””ì˜¤ì—ì„œ ì‹ ì²­ í›„ ì‚¬ìš© ê°€ëŠ¥"
            }
        
        # TODO: ë„¤ì´ë²„ Clova X API ì—°ë™ êµ¬í˜„
        return {
            "success": False,
            "error": "Clova X API ì—°ë™ ì½”ë“œ ë¯¸êµ¬í˜„ - ì¶”í›„ ê°œë°œ ì˜ˆì •",
            "todo": "ë„¤ì´ë²„ í´ë¡œë°” ìŠ¤íŠœë””ì˜¤ API ë¬¸ì„œ ì°¸ê³ í•˜ì—¬ êµ¬í˜„"
        }
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """ì „ì²´ AI ëª¨ë¸ ì¢…í•© í…ŒìŠ¤íŠ¸"""
        print("ğŸš€ HEAL7 ìµœì‹  AI ëª¨ë¸ ì—°ë™ í…ŒìŠ¤íŠ¸ (2025)")
        print("=" * 60)
        
        # 1. API í‚¤ í™•ì¸
        print("\n1ï¸âƒ£ API í‚¤ ì„¤ì • í™•ì¸")
        key_status = await self.check_api_keys()
        
        # 2. ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ëª¨ë¸ë³„ ì—°ê²° í…ŒìŠ¤íŠ¸")
        
        # Gemini 2.0 Flash í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª Gemini 2.0 Flash í…ŒìŠ¤íŠ¸...")
        gemini_result = await self.test_gemini_2_flash()
        self.test_results["gemini-2.0-flash"] = gemini_result
        
        if gemini_result["success"]:
            print(f"   âœ… ì„±ê³µ ({gemini_result['response_time']:.2f}ì´ˆ)")
            print(f"   ğŸ’¬ ì‘ë‹µ: {gemini_result['response'][:50]}...")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {gemini_result['error']}")
        
        # GPT-4o í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª GPT-4o í…ŒìŠ¤íŠ¸...")
        gpt4o_result = await self.test_gpt_4o("gpt-4o")
        self.test_results["gpt-4o"] = gpt4o_result
        
        if gpt4o_result["success"]:
            print(f"   âœ… ì„±ê³µ ({gpt4o_result['response_time']:.2f}ì´ˆ)")
            print(f"   ğŸ’¬ ì‘ë‹µ: {gpt4o_result['response'][:50]}...")
            print(f"   ğŸ”¢ í† í°: {gpt4o_result['tokens_used']}")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {gpt4o_result['error']}")
        
        # GPT-4o Mini í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª GPT-4o Mini í…ŒìŠ¤íŠ¸...")
        gpt4o_mini_result = await self.test_gpt_4o("gpt-4o-mini")
        self.test_results["gpt-4o-mini"] = gpt4o_mini_result
        
        if gpt4o_mini_result["success"]:
            print(f"   âœ… ì„±ê³µ ({gpt4o_mini_result['response_time']:.2f}ì´ˆ)")
            print(f"   ğŸ’¬ ì‘ë‹µ: {gpt4o_mini_result['response'][:50]}...")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {gpt4o_mini_result['error']}")
        
        # Claude 3.5 Sonnet í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª Claude 3.5 Sonnet í…ŒìŠ¤íŠ¸...")
        claude_result = await self.test_claude_35_sonnet()
        self.test_results["claude-3.5-sonnet"] = claude_result
        
        if claude_result["success"]:
            print(f"   âœ… ì„±ê³µ ({claude_result['response_time']:.2f}ì´ˆ)")
            print(f"   ğŸ’¬ ì‘ë‹µ: {claude_result['response'][:50]}...")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {claude_result['error']}")
        
        # Perplexity í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª Perplexity Sonar í…ŒìŠ¤íŠ¸...")
        perplexity_result = await self.test_perplexity_sonar()
        self.test_results["perplexity-sonar"] = perplexity_result
        
        if perplexity_result["success"]:
            print(f"   âœ… ì„±ê³µ ({perplexity_result['response_time']:.2f}ì´ˆ)")
            print(f"   ğŸ’¬ ì‘ë‹µ: {perplexity_result['response'][:50]}...")
            print(f"   ğŸ”— ì‹¤ì‹œê°„ ë°ì´í„°: {perplexity_result['has_realtime_data']}")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {perplexity_result['error']}")
        
        # Clova X í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª ë„¤ì´ë²„ Clova X í…ŒìŠ¤íŠ¸...")
        clova_result = await self.test_clova_x()
        self.test_results["clova-x"] = clova_result
        
        if clova_result["success"]:
            print(f"   âœ… ì„±ê³µ")
        else:
            print(f"   â­ï¸ ìŠ¤í‚µ: {clova_result['error']}")
        
        # 3. ê²°ê³¼ ìš”ì•½
        print(f"\n3ï¸âƒ£ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.print_summary()
        
        # 4. ê¶Œì¥ì‚¬í•­
        print(f"\n4ï¸âƒ£ ê¶Œì¥ì‚¬í•­")
        recommendations = self.generate_recommendations()
        for rec in recommendations:
            print(f"ğŸ’¡ {rec}")
        
        # 5. ë¦¬í¬íŠ¸ ì €ì¥
        report = {
            "timestamp": datetime.now().isoformat(),
            "api_key_status": key_status,
            "test_results": self.test_results,
            "recommendations": recommendations,
            "summary": self.get_summary_stats()
        }
        
        report_path = f"/home/ubuntu/logs/ai_model_test_2025_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        
        return report
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"{'ëª¨ë¸':<20} {'ìƒíƒœ':<8} {'ì‘ë‹µì‹œê°„':<10} {'íŠ¹ì§•'}")
        print("-" * 60)
        
        for model_id, result in self.test_results.items():
            model_name = self.models[model_id]["name"]
            
            if result["success"]:
                status = "âœ… ì •ìƒ"
                response_time = f"{result.get('response_time', 0):.2f}ì´ˆ"
                
                # íŠ¹ì§• í‘œì‹œ
                features = []
                if model_id == "gemini-2.0-flash":
                    features.append("ë¬´ë£Œ")
                if model_id == "gpt-4o-mini":
                    features.append("ì €ë¹„ìš©")
                if model_id == "perplexity-sonar" and result.get("has_realtime_data"):
                    features.append("ì‹¤ì‹œê°„")
                if model_id == "claude-3.5-sonnet":
                    features.append("ì •í™•ì„±")
                
                feature_str = ", ".join(features) if features else "ì¼ë°˜"
            else:
                status = "âŒ ì‹¤íŒ¨"
                response_time = "N/A"
                feature_str = "ì˜¤ë¥˜"
            
            print(f"{model_name:<20} {status:<8} {response_time:<10} {feature_str}")
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """ìš”ì•½ í†µê³„"""
        total_models = len(self.test_results)
        successful_models = sum(1 for result in self.test_results.values() if result["success"])
        
        avg_response_time = 0
        if successful_models > 0:
            total_time = sum(result.get("response_time", 0) for result in self.test_results.values() if result["success"])
            avg_response_time = total_time / successful_models
        
        return {
            "total_models": total_models,
            "successful_models": successful_models,
            "success_rate": (successful_models / total_models) * 100,
            "avg_response_time": avg_response_time
        }
    
    def generate_recommendations(self) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        successful_models = [model_id for model_id, result in self.test_results.items() if result["success"]]
        
        if not successful_models:
            recommendations.append("â— ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            return recommendations
        
        # Gemini 2.0 Flash ìš°ì„  ê¶Œì¥
        if "gemini-2.0-flash" in successful_models:
            recommendations.append("ğŸ†“ Gemini 2.0 FlashëŠ” ë¬´ë£Œì´ë¯€ë¡œ 1ìˆœìœ„ë¡œ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:
            recommendations.append("ğŸ’° Gemini 2.0 Flash API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ë¬´ë£Œë¡œ AI ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ë¹„ìš© íš¨ìœ¨ì„±
        if "gpt-4o-mini" in successful_models:
            recommendations.append("ğŸ’° GPT-4o MiniëŠ” ë§¤ìš° ì €ë ´í•˜ë¯€ë¡œ ëŒ€ìš©ëŸ‰ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.")
        
        # ì‹¤ì‹œê°„ ë°ì´í„°
        if "perplexity-sonar" in successful_models:
            recommendations.append("ğŸ” PerplexityëŠ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ ë¦¬ì„œì¹˜ ì‘ì—…ì— ìµœì ì…ë‹ˆë‹¤.")
        
        # í´ë°± ìˆœì„œ ê¶Œì¥
        if len(successful_models) >= 2:
            # ë¬´ë£Œ ëª¨ë¸ ìš°ì„ , ê·¸ ë‹¤ìŒ ì €ë¹„ìš© ëª¨ë¸ ìˆœìœ¼ë¡œ ì •ë ¬
            priority_order = []
            
            if "gemini-2.0-flash" in successful_models:
                priority_order.append("gemini-2.0-flash")
            if "gpt-4o-mini" in successful_models:
                priority_order.append("gpt-4o-mini")
            if "claude-3.5-sonnet" in successful_models:
                priority_order.append("claude-3.5-sonnet")
            if "gpt-4o" in successful_models:
                priority_order.append("gpt-4o")
            if "perplexity-sonar" in successful_models:
                priority_order.append("perplexity-sonar")
            
            model_names = [self.models[mid]["name"] for mid in priority_order]
            recommendations.append(f"ğŸ”„ ê¶Œì¥ í´ë°± ìˆœì„œ: {' â†’ '.join(model_names)}")
        
        # Clova X ì¶”í›„ ì—°ë™
        if "clova-x" not in successful_models:
            recommendations.append("ğŸ‡°ğŸ‡· ë„¤ì´ë²„ Clova X ì—°ë™ ì‹œ í•œêµ­ì–´ ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return recommendations

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    connector = AIModelConnector2025()
    await connector.run_comprehensive_test()

if __name__ == "__main__":
    asyncio.run(main())