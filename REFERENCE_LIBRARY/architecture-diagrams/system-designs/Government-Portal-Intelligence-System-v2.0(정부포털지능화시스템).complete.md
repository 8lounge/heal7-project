# ğŸ›ï¸ ì •ë¶€ í¬í„¸ ì§€ëŠ¥í™” ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ v2.0

> **í”„ë¡œì íŠ¸**: Paperwork AI 2.0 - ì‹¤ì‹œê°„ ì •ë¶€ ì§€ì›ì‚¬ì—… ì–‘ì‹ ìë™ í•™ìŠµ ì‹œìŠ¤í…œ  
> **ë²„ì „**: v2.0.0  
> **ì‘ì„±ì¼**: 2025-08-23  
> **ëª©ì **: ì •ë¶€ í¬í„¸ ì‚¬ì´íŠ¸ë¥¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì§€ì›ì‚¬ì—… ì–‘ì‹ì„ ìë™ í•™ìŠµí•˜ê³  í…œí”Œë¦¿í™”í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œ  

---

## ğŸ¯ **í•µì‹¬ ë¯¸ì…˜**

### ğŸ’¡ **í˜„ì‹¤ì  ë¬¸ì œ**
```
ğŸ˜° ê¸°ì—… ë‹´ë‹¹ìì˜ ê³ ì¶©:
"ë§¤ì¼ ìƒˆë¡œìš´ ì§€ì›ì‚¬ì—…ì´ ë‚˜ì˜¤ëŠ”ë°, 
ì–‘ì‹ë„ ë‹¤ë¥´ê³  ìš”êµ¬ì‚¬í•­ë„ ê³„ì† ë°”ë€Œì–´ì„œ
ì–¸ì œ ì–´ë–¤ ì–‘ì‹ì´ ë‚˜ì˜¬ì§€ ëª¨ë¥´ê² ì–´ìš”..."

ğŸ¤– AI ì†”ë£¨ì…˜:
"ì •ë¶€ í¬í„¸ì„ 24ì‹œê°„ ëª¨ë‹ˆí„°ë§í•´ì„œ
ìƒˆë¡œìš´ ì§€ì›ì‚¬ì—…ê³¼ ì–‘ì‹ì„ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ê³ ,
ì¦‰ì‹œ í…œí”Œë¦¿ìœ¼ë¡œ ì œê³µí•´ë“œë¦½ë‹ˆë‹¤!"
```

### ğŸŒ **êµ­ê°€ë³„ í™•ì¥ ì „ëµ**
- **Phase 1**: ğŸ‡°ğŸ‡· í•œêµ­ (ê¸°ì—…ë§ˆë‹¹, K-Startup ë“±)
- **Phase 2**: ğŸ‡ºğŸ‡¸ ë¯¸êµ­ (SBA.gov, SBIR ë“±)  
- **Phase 3**: ğŸ‡¯ğŸ‡µ ì¼ë³¸ (J-NET21, JETRO ë“±)
- **Phase 4**: ğŸ‡ªğŸ‡º ìœ ëŸ½ (EU Funding & Tenders ë“±)

---

## ğŸ—ï¸ **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜**

### ğŸ“Š **ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°**
```mermaid
graph TB
    subgraph "ğŸŒ Portal Monitoring Layer"
        A1[ê¸°ì—…ë§ˆë‹¹ Scraper]
        A2[K-Startup Scraper]
        A3[ì •ë¶€24 Scraper]
        A4[ê¸°íƒ€ í¬í„¸ Scrapers]
    end
    
    subgraph "ğŸ§  AI Intelligence Layer"  
        B1[Document Structure Analyzer]
        B2[Template Pattern Extractor]
        B3[Requirement Classifier]
        B4[Similarity Detector]
    end
    
    subgraph "ğŸ—ï¸ Template Generation Layer"
        C1[Auto Template Generator]
        C2[Institution Mapper]
        C3[Version Manager]
        C4[Quality Validator]
    end
    
    subgraph "ğŸ“¡ API Gateway Layer"
        D1[Paperwork AI Connector]
        D2[Real-time Updates API]
        D3[Template Delivery API]
        D4[Analytics API]
    end
    
    subgraph "ğŸ—„ï¸ Data Storage Layer"
        E1[Portal Content DB]
        E2[Template Repository]
        E3[Pattern Knowledge Base]
        E4[Update History]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    
    B1 --> C1
    B2 --> C1
    B3 --> C2
    B4 --> C3
    
    C1 --> D1
    C2 --> D2
    C3 --> D3
    C4 --> D4
    
    D1 --> E1
    D2 --> E2
    D3 --> E3
    D4 --> E4
```

### ğŸ¤– **í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„**

#### **1. ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ í¬í„¸ ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ (ê²€ì¦ ì™„ë£Œ)**
```python
# âœ… ì‹¤ì œ ë™ì‘ í™•ì¸ëœ ìŠ¤í¬ë˜í¼ (2025-08-23 í…ŒìŠ¤íŠ¸)
class BizinfoScraper:
    """ê¸°ì—…ë§ˆë‹¹ ì „ìš© ìŠ¤í¬ë˜í¼ - ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ"""
    
    def __init__(self, db_manager: DatabaseManager, rate_limiter: RateLimiter):
        self.config = ScrapingConfig()
        # âœ… ì‹¤ì œ ê²€ì¦ëœ URL
        self.base_url = "https://www.bizinfo.go.kr/web/lay1/bbs/S1T122C128/AS/74/list.do"
        
        # âœ… ì‹¤ì œ ë™ì‘í•˜ëŠ” ì…€ë ‰í„°ë“¤
        self.verified_selectors = {
            'table': 'table tbody tr',           # í…Œì´ë¸” í–‰ ì¶”ì¶œ (100% ë™ì‘)
            'title': 'td:nth-child(3) a',        # ì§€ì›ì‚¬ì—…ëª…
            'agency': 'td:nth-child(6)',         # ì‚¬ì—…ìˆ˜í–‰ê¸°ê´€  
            'period': 'td:nth-child(4)',         # ì‹ ì²­ê¸°ê°„
            'jurisdiction': 'td:nth-child(5)'    # ì†Œê´€ë¶€ì²˜
        }
        
        self.error_handler = ErrorHandler()      # í¬ê´„ì  ì˜¤ë¥˜ ì²˜ë¦¬
    
    async def scrape_all_programs(self, force_update: bool = False) -> List[Dict]:
        """ê²€ì¦ëœ ìŠ¤í¬ë˜í•‘ ë¡œì§"""
        programs = []
        
        with self.error_handler.get_circuit_breaker('bizinfo'):
            for page in range(1, self.config.max_pages + 1):
                
                # âœ… ì‹¤ì œ ë™ì‘í•˜ëŠ” íŒŒë¼ë¯¸í„°
                params = {"cpage": page}
                
                async with self.session.get(self.base_url, params=params) as response:
                    if response.status != 200:
                        continue
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'lxml')
                    
                    # âœ… ê²€ì¦ëœ í…Œì´ë¸” íŒŒì‹±
                    rows = soup.select('table tbody tr')
                    if not rows:
                        break
                    
                    for row in rows:
                        program = await self._extract_program_safely(row)
                        if program:
                            programs.append(program)
                
                # âœ… ì ì‘í˜• ì†ë„ ì œí•œ
                await self.rate_limiter.acquire()
        
        return self._remove_duplicates(programs)

class KStartupScraper:
    """K-Startup ì „ìš© ìŠ¤í¬ë˜í¼ - SPA ëŒ€ì‘ ë¶ˆí•„ìš” í™•ì¸"""
    
    def __init__(self, db_manager: DatabaseManager, rate_limiter: RateLimiter):
        # âœ… ì‹¤ì œ í™•ì¸ëœ URLë“¤
        self.verified_urls = {
            'ongoing': 'https://www.k-startup.go.kr/web/contents/bizpbanc-ongoing.do',
            'deadline': 'https://www.k-startup.go.kr/web/contents/bizpbanc-deadline.do'
        }
        
        # âœ… Playwright ë¶ˆí•„ìš” - ì¼ë°˜ HTTPë¡œ ì¶©ë¶„
        self.session = aiohttp.ClientSession()
        self.error_handler = ErrorHandler()
    
    async def scrape_all_programs(self) -> List[Dict]:
        """ì‹¤ì œ ê²€ì¦ëœ ìˆ˜ì§‘ ë°©ì‹"""
        all_programs = []
        
        for category, url in self.verified_urls.items():
            
            with self.error_handler.get_circuit_breaker('kstartup'):
                async with self.session.get(url) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'lxml')
                        
                        # âœ… ë™ì  ì…€ë ‰í„° ì „ëµ (êµ¬ì¡° ë³€ê²½ ëŒ€ì‘)
                        programs = await self._extract_with_fallback_selectors(soup, category)
                        all_programs.extend(programs)
                
                await asyncio.sleep(2.0)  # K-Startup ì „ìš© ë”œë ˆì´
        
        return all_programs

# âœ… ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (2025-08-23)
"""
ğŸ¢ ê¸°ì—…ë§ˆë‹¹ ìˆ˜ì§‘ ê²°ê³¼: 5ê°œ í”„ë¡œê·¸ë¨ ì •ìƒ ìˆ˜ì§‘ (100% ì„±ê³µ)
  1. [ê´‘ì£¼] 2025ë…„ ê³µí•­ ì‚¬íšŒì ê²½ì œë§ˆì¼“ ì°¸ì—¬ê¸°ì—… ëª¨ì§‘ ê³µê³ 
     - ê¸°ê´€: ê´‘ì£¼ì‚¬íšŒì ê²½ì œì§€ì›ì„¼í„°  
     - ê¸°ê°„: 2025-08-18 ~ 2025-08-25

  2. [ê²½ë‚¨] í†µì˜ì‹œ 2025ë…„ 6ì°¨ ë©¸ì¹˜ ì‚°ì§€ìë™í™” ì„¤ë¹„ ì‹œë²” ì§€ì›ì‚¬ì—…
     - ê¸°ê´€: ê¸°ì´ˆìì¹˜ë‹¨ì²´
     - ê¸°ê°„: 2025-08-25 ~ 2025-09-05

ğŸš€ K-Startup ìˆ˜ì§‘ ê²°ê³¼: 3ê°œ í”„ë¡œê·¸ë¨ ìˆ˜ì§‘
  - ì…€ë ‰í„° ìµœì í™” í•„ìš”í•˜ì§€ë§Œ ê¸°ë³¸ ìˆ˜ì§‘ ì„±ê³µ
"""
```

#### **2. AI Pattern Analysis Engine (AI íŒ¨í„´ ë¶„ì„ ì—”ì§„)**
```python
class PortalContentAnalyzer:
    """í¬í„¸ ì½˜í…ì¸  ì§€ëŠ¥í˜• ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.ai_models = {
            'structure_analyzer': 'gpt-4o',           # ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
            'pattern_extractor': 'claude-3.5',       # íŒ¨í„´ ì¶”ì¶œ
            'similarity_detector': 'gemini-pro',     # ìœ ì‚¬ë„ ê°ì§€
            'requirement_classifier': 'gpt-4.1'      # ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜
        }
        
        self.knowledge_base = PatternKnowledgeBase()
    
    async def analyze_portal_content(self, portal_id: str, programs: List, forms: List, requirements: List) -> Dict:
        """í¬í„¸ ì½˜í…ì¸  ì¢…í•© ë¶„ì„"""
        
        analysis_result = {
            'portal_id': portal_id,
            'timestamp': datetime.now().isoformat(),
            'program_analysis': {},
            'form_patterns': {},
            'requirement_classification': {},
            'template_recommendations': []
        }
        
        # 1. í”„ë¡œê·¸ë¨ë³„ ë¶„ì„
        for program in programs:
            program_analysis = await self.analyze_single_program(program)
            analysis_result['program_analysis'][program['id']] = program_analysis
        
        # 2. ì–‘ì‹ íŒ¨í„´ ë¶„ì„
        form_patterns = await self.extract_form_patterns(forms)
        analysis_result['form_patterns'] = form_patterns
        
        # 3. ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë° íƒœê¹…
        classified_requirements = await self.classify_requirements(requirements)
        analysis_result['requirement_classification'] = classified_requirements
        
        # 4. í…œí”Œë¦¿ ìƒì„± ê¶Œì¥ì‚¬í•­
        recommendations = await self.generate_template_recommendations(
            analysis_result['program_analysis'],
            analysis_result['form_patterns']
        )
        analysis_result['template_recommendations'] = recommendations
        
        return analysis_result
    
    async def analyze_single_program(self, program: Dict) -> Dict:
        """ê°œë³„ í”„ë¡œê·¸ë¨ ìƒì„¸ ë¶„ì„"""
        
        analysis_prompt = f"""
        ë‹¤ìŒ ì •ë¶€ ì§€ì›ì‚¬ì—… í”„ë¡œê·¸ë¨ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        í”„ë¡œê·¸ë¨ ì •ë³´:
        - ì œëª©: {program.get('title', '')}
        - ì£¼ê´€ê¸°ê´€: {program.get('agency', '')}
        - ì‹ ì²­ê¸°ê°„: {program.get('application_period', '')}
        - ì§€ì›ëŒ€ìƒ: {program.get('target', '')}
        - ì§€ì›ë‚´ìš©: {program.get('support_details', '')}
        - ì‹ ì²­ì„œë¥˜: {program.get('required_documents', '')}
        
        ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
        1. í”„ë¡œê·¸ë¨ ìœ í˜• (ì°½ì—…ì§€ì›, ê¸°ìˆ ê°œë°œ, ìˆ˜ì¶œì§€ì›, ì¸ë ¥ì–‘ì„± ë“±)
        2. ì‹ ì²­ ë³µì¡ë„ (1-5ì )
        3. í•„ìˆ˜ ì„œë¥˜ ì¢…ë¥˜ ë° íŠ¹ì§•
        4. í‰ê°€ ê¸°ì¤€ ë° ì¤‘ì ì‚¬í•­
        5. ìœ ì‚¬ í”„ë¡œê·¸ë¨ê³¼ì˜ ì°¨ë³„ì 
        6. ê¶Œì¥ í…œí”Œë¦¿ êµ¬ì¡°
        """
        
        analysis_result = await self.ai_models['structure_analyzer'].generate(analysis_prompt)
        
        return {
            'program_id': program.get('id'),
            'analysis': self.parse_program_analysis(analysis_result),
            'template_structure': await self.extract_template_structure(program),
            'similarity_score': await self.calculate_similarity_to_existing(program)
        }
    
    async def extract_form_patterns(self, forms: List[Dict]) -> Dict:
        """ì–‘ì‹ íŒ¨í„´ ì¶”ì¶œ ë° ë¶„ë¥˜"""
        
        patterns = {
            'common_sections': {},
            'institution_specific': {},
            'document_types': {},
            'format_requirements': {}
        }
        
        for form in forms:
            # ì–‘ì‹ êµ¬ì¡° ë¶„ì„
            structure = await self.analyze_form_structure(form)
            
            # ê³µí†µ ì„¹ì…˜ ì‹ë³„
            common_sections = await self.identify_common_sections(structure)
            for section in common_sections:
                if section in patterns['common_sections']:
                    patterns['common_sections'][section]['frequency'] += 1
                else:
                    patterns['common_sections'][section] = {
                        'frequency': 1,
                        'variations': [structure[section]]
                    }
            
            # ê¸°ê´€ë³„ íŠ¹í™” ìš”ì†Œ ì‹ë³„
            specific_elements = await self.identify_institution_specific_elements(form, structure)
            institution = form.get('institution', 'unknown')
            if institution not in patterns['institution_specific']:
                patterns['institution_specific'][institution] = []
            patterns['institution_specific'][institution].extend(specific_elements)
        
        return patterns
```

#### **3. Auto Template Generator (ìë™ í…œí”Œë¦¿ ìƒì„±ê¸°)**
```python
class AutoTemplateGenerator:
    """AI ê¸°ë°˜ ìë™ í…œí”Œë¦¿ ìƒì„± ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.template_engine = TemplateEngine()
        self.version_manager = VersionManager()
        self.quality_validator = QualityValidator()
    
    async def generate_templates_from_analysis(self, analysis_results: Dict) -> List[Dict]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…œí”Œë¦¿ ìë™ ìƒì„±"""
        
        generated_templates = []
        
        for program_id, program_analysis in analysis_results['program_analysis'].items():
            # 1. í…œí”Œë¦¿ ê¸°ë³¸ êµ¬ì¡° ìƒì„±
            base_template = await self.create_base_template(program_analysis)
            
            # 2. ì„¹ì…˜ë³„ ì„¸ë¶€ êµ¬ì¡° ì •ì˜
            detailed_template = await self.add_section_details(
                base_template, 
                analysis_results['form_patterns']
            )
            
            # 3. ê¸°ê´€ë³„ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì ìš©
            customized_template = await self.apply_institution_customization(
                detailed_template,
                program_analysis['institution']
            )
            
            # 4. í’ˆì§ˆ ê²€ì¦
            quality_score = await self.quality_validator.validate_template(customized_template)
            
            if quality_score >= 0.8:  # 80% ì´ìƒë§Œ ìŠ¹ì¸
                # 5. ë²„ì „ ê´€ë¦¬ ë° ì €ì¥
                versioned_template = await self.version_manager.create_new_version(
                    template=customized_template,
                    source='auto_generated',
                    confidence_score=quality_score
                )
                
                generated_templates.append(versioned_template)
        
        return generated_templates
    
    async def create_base_template(self, program_analysis: Dict) -> Dict:
        """í”„ë¡œê·¸ë¨ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°ë³¸ í…œí”Œë¦¿ êµ¬ì¡° ìƒì„±"""
        
        program_type = program_analysis['analysis']['program_type']
        complexity = program_analysis['analysis']['complexity']
        
        # í”„ë¡œê·¸ë¨ ìœ í˜•ë³„ ê¸°ë³¸ êµ¬ì¡° ë§¤í•‘
        type_templates = {
            'ì°½ì—…ì§€ì›': {
                'sections': [
                    'business_overview', 'market_analysis', 'business_model',
                    'team_composition', 'financial_plan', 'growth_strategy'
                ],
                'emphasis': ['innovation', 'scalability', 'market_potential']
            },
            'ê¸°ìˆ ê°œë°œ': {
                'sections': [
                    'technology_overview', 'research_plan', 'technical_approach',
                    'innovation_aspects', 'commercialization_plan', 'ip_strategy'
                ],
                'emphasis': ['technical_excellence', 'innovation', 'feasibility']
            },
            'ìˆ˜ì¶œì§€ì›': {
                'sections': [
                    'company_overview', 'product_description', 'target_market',
                    'export_strategy', 'competitive_analysis', 'implementation_plan'
                ],
                'emphasis': ['global_competitiveness', 'market_entry', 'sustainability']
            }
        }
        
        base_structure = type_templates.get(program_type, type_templates['ì°½ì—…ì§€ì›'])
        
        # ë³µì¡ë„ì— ë”°ë¥¸ ì„¹ì…˜ ì¡°ì •
        if complexity <= 2:
            base_structure['sections'] = base_structure['sections'][:4]  # ê°„ë‹¨í•œ êµ¬ì¡°
        elif complexity >= 4:
            base_structure['sections'].extend(['risk_management', 'sustainability_plan'])  # ë³µì¡í•œ êµ¬ì¡°
        
        return {
            'template_id': f"auto_{program_analysis['program_id']}_{int(time.time())}",
            'program_type': program_type,
            'complexity_level': complexity,
            'base_sections': base_structure['sections'],
            'key_emphasis': base_structure['emphasis'],
            'generation_method': 'ai_auto_generated',
            'created_at': datetime.now().isoformat()
        }
```

---

## ğŸ—„ï¸ **í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…ì²˜ (ì‹¤ì œ êµ¬í˜„)**

### ğŸ”„ **3ë‹¨ê³„ ë°ì´í„° íŒŒì´í”„ë¼ì¸**
```
ğŸ“¥ Raw Collection Stage (JSONB NoSQL)
    â†“ AI í’ˆì§ˆ ê²€ì¦ & ë°ì´í„° ì •ì œ
ğŸ“Š Processing Stage (êµ¬ì¡°í™”)
    â†“ ê´€ê³„í˜• í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜
ğŸ¯ Relational Stage (ì„œë¹„ìŠ¤ ì œê³µ)
```

### ğŸ“Š **ì‹¤ì œ ìŠ¤í‚¤ë§ˆ êµ¬ì¡° (PostgreSQL + JSONB)**

#### **Phase 1: Raw JSON ìˆ˜ì§‘ ìŠ¤í…Œì´ì§€**
```sql
-- ì›ë³¸ ìŠ¤í¬ë˜í•‘ ë°ì´í„° (JSONB NoSQL ë°©ì‹)
CREATE TABLE IF NOT EXISTS raw_scraped_data (
    id BIGSERIAL PRIMARY KEY,
    
    -- ë©”íƒ€ë°ì´í„°
    portal_id VARCHAR(50) NOT NULL,                    -- 'bizinfo', 'kstartup' ë“±
    url TEXT NOT NULL,                                 -- ìˆ˜ì§‘í•œ í˜ì´ì§€ URL
    scraping_session_id UUID NOT NULL DEFAULT gen_random_uuid(),
    
    -- NoSQL ì›ë³¸ ë°ì´í„°
    raw_data JSONB NOT NULL,                          -- ì™„ì „í•œ ì›ë³¸ ë°ì´í„°
    html_content TEXT,                                -- ì›ë³¸ HTML (ì„ íƒì )
    
    -- ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
    processing_status VARCHAR(20) DEFAULT 'pending',  -- pending, processing, completed, failed
    quality_score DECIMAL(3,2),                      -- AI í’ˆì§ˆ ì ìˆ˜ (0.00-10.00)
    validation_errors JSONB,                         -- ê²€ì¦ ì˜¤ë¥˜ ë‚´ìš©
    
    -- íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì 
    scraped_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP WITH TIME ZONE,
    migrated_at TIMESTAMP WITH TIME ZONE
);

-- JSONB ê³ ì„±ëŠ¥ ì¸ë±ìŠ¤ (GIN)
CREATE INDEX idx_raw_scraped_data_content ON raw_scraped_data USING GIN (raw_data);
CREATE INDEX idx_raw_scraped_data_title ON raw_scraped_data USING GIN ((raw_data->>'title'));
```

#### **Phase 2: ê´€ê³„í˜• ë§ˆì´ê·¸ë ˆì´ì…˜ í…Œì´ë¸”**
```sql
-- ì§€ì›ì‚¬ì—… í”„ë¡œê·¸ë¨ ë§ˆìŠ¤í„° í…Œì´ë¸” (ìµœì¢… ì„œë¹„ìŠ¤ ì œê³µ)
CREATE TABLE IF NOT EXISTS support_programs (
    id BIGSERIAL PRIMARY KEY,
    
    -- ì—°ê²° ê´€ê³„
    program_id VARCHAR(100) UNIQUE NOT NULL,         -- í¬í„¸ë³„ ê³ ìœ  ID
    portal_id VARCHAR(50) NOT NULL,
    original_raw_id BIGINT REFERENCES raw_scraped_data(id), -- ì›ë³¸ ë°ì´í„° ì—°ê²°
    
    -- í•µì‹¬ í”„ë¡œê·¸ë¨ ì •ë³´
    title TEXT NOT NULL,
    description TEXT,
    support_field VARCHAR(100),                      -- ì§€ì› ë¶„ì•¼
    
    -- ê¸°ê´€ ì •ë³´
    implementing_agency TEXT,                        -- ì‚¬ì—…ìˆ˜í–‰ê¸°ê´€
    jurisdiction TEXT,                               -- ì†Œê´€ë¶€ì²˜
    contact_info JSONB,                             -- ì—°ë½ì²˜ (êµ¬ì¡°í™”ëœ JSON)
    
    -- ì§€ì› ë‚´ìš© (JSONBë¡œ ìœ ì—°ì„± í™•ë³´)
    support_details JSONB,                          -- ì§€ì› ìƒì„¸ ë‚´ìš©
    support_amount VARCHAR(100),                    -- ì§€ì› ê¸ˆì•¡
    support_period VARCHAR(100),                    -- ì§€ì› ê¸°ê°„
    support_type VARCHAR(50),                       -- ì§€ì› ë°©ì‹
    
    -- ì‹ ì²­ ì •ë³´
    application_period VARCHAR(200),                -- ì‹ ì²­ ê¸°ê°„
    application_status VARCHAR(50) DEFAULT 'active',
    target_audience TEXT,                           -- ì§€ì› ëŒ€ìƒ
    
    -- AI ë¶„ì„ ê²°ê³¼
    ai_analysis JSONB,                              -- AI ë¶„ì„ ê²°ê³¼
    template_generated BOOLEAN DEFAULT FALSE,       -- í…œí”Œë¦¿ ìƒì„± ì—¬ë¶€
    
    -- í’ˆì§ˆ ë³´ì¥
    data_quality_score DECIMAL(3,2),               -- ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
    verification_status VARCHAR(20) DEFAULT 'unverified',
    
    -- íƒ€ì„ìŠ¤íƒ¬í”„
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### **Phase 3: 4ì¤‘ í´ë°± ë°±ì—… ì‹œìŠ¤í…œ**
```sql
-- ë°±ì—… ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ë‹¤ì¤‘ í‹°ì–´ ë°±ì—…)
CREATE TABLE IF NOT EXISTS backup_data_registry (
    id BIGSERIAL PRIMARY KEY,
    
    -- ë°±ì—… ì‹ë³„
    backup_id UUID UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    source_table VARCHAR(100) NOT NULL,             -- ì›ë³¸ í…Œì´ë¸”ëª…
    source_record_id BIGINT NOT NULL,               -- ì›ë³¸ ë ˆì½”ë“œ ID
    
    -- 4ì¤‘ ë°±ì—… ë°©ì‹
    backup_method VARCHAR(50) NOT NULL,             -- 'filesystem', 'redis', 'remote', 'hybrid'
    backup_location TEXT NOT NULL,                  -- ë°±ì—… ìœ„ì¹˜
    
    -- ë°±ì—… ë°ì´í„° ë° ë¬´ê²°ì„±
    backup_data JSONB NOT NULL,                     -- ë°±ì—…ëœ ë°ì´í„°
    metadata JSONB,                                 -- ë°±ì—… ë©”íƒ€ë°ì´í„°
    
    -- ìƒíƒœ ë° ë§Œë£Œ
    backup_status VARCHAR(20) DEFAULT 'active',     -- active, expired, corrupted, restored
    verified_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP + INTERVAL '30 days'
);
```

#### **Phase 4: ë³µêµ¬ ì‘ì—… ë¡œê·¸**
```sql
-- ìë™/ìˆ˜ë™ ë³µêµ¬ ì‘ì—… ì¶”ì 
CREATE TABLE IF NOT EXISTS recovery_operations (
    id BIGSERIAL PRIMARY KEY,
    
    -- ë³µêµ¬ ì‘ì—… ì‹ë³„
    operation_id UUID UNIQUE NOT NULL DEFAULT gen_random_uuid(),
    trigger_type VARCHAR(50) NOT NULL,              -- 'manual', 'automatic', 'scheduled'
    recovery_scope VARCHAR(50) NOT NULL,            -- 'single_record', 'session', 'full_portal'
    
    -- ëŒ€ìƒ ë° ê²°ê³¼
    target_portal_id VARCHAR(50),
    target_session_id UUID,
    affected_records JSONB,                         -- ì˜í–¥ë°›ì€ ë ˆì½”ë“œ ëª©ë¡
    
    -- ë³µêµ¬ ì„±ê³¼
    started_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP WITH TIME ZONE,
    status VARCHAR(20) DEFAULT 'running',           -- running, completed, failed, partial
    
    records_recovered INTEGER DEFAULT 0,
    records_failed INTEGER DEFAULT 0,
    recovery_details JSONB,
    
    -- í’ˆì§ˆ ê²€ì¦
    verification_passed BOOLEAN,
    verification_details JSONB
);
```

### ğŸ”§ **ë§ˆì´ê·¸ë ˆì´ì…˜ ì—”ì§„ (ì‹¤ì œ êµ¬í˜„)**
```python
# 3ë‹¨ê³„ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸
class MigrationEngine:
    async def run_full_migration_pipeline(self, portal_id: str = None):
        """ì™„ì „ ìë™í™”ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        
        # Stage 1: Raw Data Processing (ë°°ì¹˜ ì²˜ë¦¬)
        async for batch in self._get_pending_raw_data_batches(portal_id):
            await self._process_raw_data_batch(batch)
        
        # Stage 2: Quality Validation & AI Analysis
        processed_data = await self._get_processed_data_batches(portal_id)
        await self._validate_and_analyze_batch(processed_data)
        
        # Stage 3: Relational Migration
        await self._migrate_to_relational_batch(processed_data)
        
        # Stage 4: Quality Assurance
        await self._quality_assurance_check(portal_id)
```

### ğŸ›¡ï¸ **4ì¤‘ í´ë°± ì‹œìŠ¤í…œ (ì‹¤ì œ êµ¬í˜„)**
```
ğŸ“Š Primary Tier:    PostgreSQL JSONB (ë©”ì¸ ìŠ¤í† ë¦¬ì§€)
ğŸ“ Secondary Tier:  File System JSON (ë¡œì»¬ ë°±ì—…)
âš¡ Tertiary Tier:   Redis Cache (ê³ ì† ë³µêµ¬)
â˜ï¸  Quaternary Tier: S3 Remote Backup (ì¬í•´ ë³µêµ¬)
```

```python
# ë‹¤ì¤‘ í‹°ì–´ ë°±ì—… ì‹œìŠ¤í…œ
class MultiTierBackupSystem:
    async def create_full_backup(self, source_id: str, data: Dict):
        """ëª¨ë“  í‹°ì–´ì— ë™ì‹œ ë°±ì—… ìƒì„±"""
        
        # ëª¨ë“  í‹°ì–´ì— ë³‘ë ¬ ë°±ì—…
        backup_tasks = [
            self._save_to_database(backup_record),      # Primary
            self.filesystem_manager.save_backup(record), # Secondary  
            self.redis_manager.save_backup(record),      # Tertiary
            self.remote_manager.save_backup(record)      # Quaternary
        ]
        
        results = await asyncio.gather(*backup_tasks, return_exceptions=True)
        return self._analyze_backup_results(results)
    
    async def restore_from_any_tier(self, backup_id: UUID):
        """ëª¨ë“  í‹°ì–´ì—ì„œ ë³µêµ¬ ì‹œë„ (ìš°ì„ ìˆœìœ„ë³„)"""
        
        # 1ì°¨: Primary (Database)
        if primary_data := await self._load_from_database(backup_id):
            return primary_data
            
        # 2ì°¨: Tertiary (Redis - ë¹ ë¥¸ ì•¡ì„¸ìŠ¤)
        if redis_data := await self.redis_manager.load_backup(backup_id):
            await self._restore_to_primary(redis_data)
            return redis_data
            
        # 3ì°¨: Secondary (File System)
        if fs_data := await self._find_in_filesystem(backup_id):
            await self._restore_to_primary_and_redis(fs_data)
            return fs_data
            
        # 4ì°¨: Quaternary (S3 Remote)
        if s3_data := await self.remote_manager.load_backup(backup_id):
            await self._full_restore_cascade(s3_data)
            return s3_data
```

---

## ğŸš€ **êµ¬í˜„ ë¡œë“œë§µ**

### ğŸ“… **Phase 1: í•œêµ­ í¬í„¸ ê¸°ë°˜ ì‹œìŠ¤í…œ êµ¬ì¶• (3ì£¼)**
- [ ] ê¸°ì—…ë§ˆë‹¹, K-Startup ìŠ¤í¬ë˜í¼ ê°œë°œ
- [ ] AI íŒ¨í„´ ë¶„ì„ ì—”ì§„ êµ¬í˜„  
- [ ] ìë™ í…œí”Œë¦¿ ìƒì„± ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬í˜„

### ğŸ“… **Phase 2: ê³ ë„í™” ë° ì•ˆì •í™” (2ì£¼)**
- [ ] í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ ê°•í™”
- [ ] Paperwork AI ì—°ë™ API ê°œë°œ
- [ ] ëŒ€ì‹œë³´ë“œ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- [ ] ì„±ëŠ¥ ìµœì í™” ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸

### ğŸ“… **Phase 3: ê¸€ë¡œë²Œ í™•ì¥ ì¤€ë¹„ (2ì£¼)**
- [ ] ë‹¤êµ­ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œ
- [ ] ë¯¸êµ­/ì¼ë³¸ í¬í„¸ ë¶„ì„ ë° ì—°ë™ ì„¤ê³„
- [ ] êµ­ê°€ë³„ ì»¤ìŠ¤í„°ë§ˆì´ì§• í”„ë ˆì„ì›Œí¬

---

**ğŸ’¡ í•µì‹¬ ê°€ì¹˜**: "ì‹¤ì‹œê°„ ì •ë¶€ ì§€ì›ì‚¬ì—… ì¶”ì " - ì •ë¶€ í¬í„¸ì˜ ëª¨ë“  ë³€í™”ë¥¼ AIê°€ 24ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìµœì‹  ì–‘ì‹ê³¼ ìš”êµ¬ì‚¬í•­ì„ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì¦‰ì‹œ í…œí”Œë¦¿í™”í•˜ëŠ” í˜ì‹ ì  ì‹œìŠ¤í…œ

*ğŸ“ ì´ì œ "ì–´ë””ì„œ ìƒˆë¡œìš´ ì§€ì›ì‚¬ì—…ì´ ë‚˜ì™”ëŠ”ì§€ ëª°ë¼ì„œ ë†“ì³¤ë‹¤"ëŠ” ì¼ì´ ì™„ì „íˆ ì‚¬ë¼ì§‘ë‹ˆë‹¤. AIê°€ ëª¨ë“  ì •ë¶€ í¬í„¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì‹œí•˜ê³  ìˆìœ¼ë‹ˆê¹Œìš”!*