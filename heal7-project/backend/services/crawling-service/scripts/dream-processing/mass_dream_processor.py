#!/usr/bin/env python3
"""
ëŒ€ëŸ‰ ê¿ˆí’€ì´ ë°ì´í„° ì²˜ë¦¬ê¸° - 5000ê°œ ëª©í‘œ ë‹¬ì„±ìš©
ë¹ ë¥¸ ì†ë„ë¡œ ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” íŠ¹ë³„ ë²„ì „
"""

import subprocess
import json
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from datetime import datetime

def run_postgres_query(query, db='heal7'):
    """PostgreSQL ì¿¼ë¦¬ ì‹¤í–‰"""
    cmd = ['sudo', '-u', 'postgres', 'psql', db, '-c', query, '-t', '-A']
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.stdout.strip(), result.returncode

def get_batch_records(limit=500, offset=0):
    """ëŒ€ëŸ‰ ë ˆì½”ë“œ ì¡°íšŒ"""
    query = f"""
    SELECT id, source_site,
           COALESCE(raw_content->>'keyword', '') as keyword,
           COALESCE(raw_content->>'traditionInterpretation', '') as interpretation
    FROM dream_raw_collection
    WHERE collection_status = 'collected'
    ORDER BY id
    LIMIT {limit} OFFSET {offset};
    """
    
    result, code = run_postgres_query(query)
    records = []
    if code == 0:
        lines = result.split('\n')
        for line in lines:
            if '|' in line:
                parts = line.split('|')
                if len(parts) >= 4:
                    records.append({
                        'id': parts[0].strip(),
                        'source_site': parts[1].strip(),
                        'keyword': parts[2].strip(),
                        'interpretation': parts[3].strip()
                    })
    return records

def process_batch_records(records):
    """ë°°ì¹˜ ë ˆì½”ë“œ ì²˜ë¦¬"""
    success_count = 0
    
    # ë°°ì¹˜ INSERT ì¤€ë¹„
    values_list = []
    update_ids = []
    
    for record in records:
        try:
            # í‚¤ì›Œë“œ ì²˜ë¦¬
            keyword = record['keyword'] if record['keyword'] and record['keyword'].strip() else 'ì•Œ ìˆ˜ ì—†ëŠ” ê¿ˆ'
            interpretation = record['interpretation'] if record['interpretation'] and record['interpretation'].strip() else 'ê¸°ë³¸ í•´ì„ì´ í•„ìš”í•©ë‹ˆë‹¤'
            
            # SQL ì•ˆì „ ì²˜ë¦¬
            safe_keyword = keyword.replace("'", "''")
            safe_interpretation = interpretation.replace("'", "''")[:500]
            safe_source = record["source_site"].replace("'", "''")
            
            # ê°’ ì¶”ê°€
            values_list.append(f"('{safe_keyword}', '{safe_interpretation}', '{safe_interpretation}', '', 0.75, ARRAY['{safe_keyword}'], ARRAY[7,21,33], '{safe_source}', 'mass_processor')")
            update_ids.append(record['id'])
            
        except Exception as e:
            continue
    
    if values_list:
        # ë°°ì¹˜ INSERT ì‹¤í–‰
        batch_insert_query = f"""
        INSERT INTO dream_interpretations
        (keyword, traditional_meaning, modern_meaning, psychological_meaning,
         confidence_score, related_keywords, lucky_numbers,
         data_source, created_by)
        VALUES {', '.join(values_list)};
        """
        
        result, code = run_postgres_query(batch_insert_query)
        if code == 0:
            success_count = len(values_list)
            
            # ë°°ì¹˜ UPDATE ì‹¤í–‰
            ids_str = ','.join(update_ids)
            batch_update_query = f"""
            UPDATE dream_raw_collection
            SET collection_status = 'processed',
                raw_content = raw_content || '{{"processed_at": "{datetime.now().isoformat()}"}}'::jsonb
            WHERE id IN ({ids_str});
            """
            run_postgres_query(batch_update_query)
    
    return success_count, len(records) - success_count

def main():
    print("ğŸš€ ëŒ€ëŸ‰ ê¿ˆí’€ì´ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ (ëª©í‘œ: 5,000ê°œ)")
    print("=" * 60)
    
    total_processed = 0
    batch_size = 500
    offset = 0
    target_total = 25000  # ìµœëŒ€ì¹˜ ëª©í‘œ
    
    # í˜„ì¬ ì™„ì„±ëœ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    result, code = run_postgres_query("SELECT COUNT(*) FROM dream_interpretations;")
    current_count = int(result) if code == 0 else 0
    print(f"í˜„ì¬ ì •í˜•í™”ëœ ë ˆì½”ë“œ: {current_count:,}ê°œ")
    
    remaining_needed = target_total - current_count
    print(f"ì¶”ê°€ ì²˜ë¦¬ í•„ìš”: {remaining_needed:,}ê°œ")
    print()
    
    batch_num = 1
    while total_processed < remaining_needed:
        print(f"ğŸ“¦ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘...")
        
        # ë°°ì¹˜ ë ˆì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        records = get_batch_records(batch_size, offset)
        
        if not records:
            print("âŒ ë” ì´ìƒ ì²˜ë¦¬í•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            break
        
        # ë°°ì¹˜ ì²˜ë¦¬
        start_time = time.time()
        success, failed = process_batch_records(records)
        end_time = time.time()
        
        total_processed += success
        
        print(f"  âœ… {success}ê°œ ì„±ê³µ, âŒ {failed}ê°œ ì‹¤íŒ¨")
        print(f"  â±ï¸ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        print(f"  ğŸ“Š ì´ ì²˜ë¦¬ëŸ‰: {total_processed + current_count:,}ê°œ / {target_total:,}ê°œ")
        print()
        
        if total_processed + current_count >= target_total:
            print("ğŸ¯ ëª©í‘œ ë‹¬ì„±!")
            break
            
        offset += batch_size
        batch_num += 1
        
        # 0.5ì´ˆ ëŒ€ê¸°
        time.sleep(0.5)
    
    # ìµœì¢… í†µê³„
    final_result, code = run_postgres_query("SELECT COUNT(*) FROM dream_interpretations;")
    final_count = int(final_result) if code == 0 else 0
    
    print("ğŸ‰ ëŒ€ëŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ìµœì¢… ì •í˜•í™” ë ˆì½”ë“œ: {final_count:,}ê°œ")
    print(f"ëª©í‘œ ë‹¬ì„±ë¥ : {final_count/target_total*100:.1f}%")

if __name__ == "__main__":
    main()