#!/usr/bin/env python3
"""
ê¿ˆí’€ì´ ë°ì´í„° ìˆœì°¨ì  ë¶„ë¥˜ ì‹œìŠ¤í…œ
ìˆ˜ì§‘ëœ ì›ì‹œ JSONB ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ êµ¬ì¡°í™”ëœ í…Œì´ë¸”ë¡œ ì´ê´€

ì „ëµ: ë¬´ë¶„ë³„ ìˆ˜ì§‘ â†’ AI ê¸°ë°˜ ì²´ê³„ì  ë¶„ë¥˜ â†’ ìµœì¢… DB ì´ê´€
"""

import psycopg2
import json
import re
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
import hashlib
# import openai  # AI ê¸°ëŠ¥ ì‚¬ìš©ì‹œ ì£¼ì„ í•´ì œ
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import argparse

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass 
class ProcessedDreamData:
    """ì²˜ë¦¬ëœ ê¿ˆí’€ì´ ë°ì´í„° êµ¬ì¡°"""
    keyword: str
    category: str
    subcategory: str
    emoji: str
    traditional_interpretation: str
    modern_interpretation: str
    psychology_interpretation: str
    keywords: List[str]
    related_dreams: List[str]
    lucky_numbers: List[int]
    mood: str  # positive, neutral, negative, warning
    frequency: int
    tags: List[str]
    variations: List[str]
    confidence_score: float
    source_sites: List[str]

class DreamDataClassifier:
    """ê¿ˆí’€ì´ ë°ì´í„° ë¶„ë¥˜ê¸°"""
    
    def __init__(self, db_config: Dict[str, str], use_ai: bool = False):
        self.db_config = db_config
        self.use_ai = use_ai
        self.processed_count = 0
        self.error_count = 0
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        self.category_mapping = {
            'ë™ë¬¼': ['ë™ë¬¼', 'ì§ìŠ¹', 'ìƒˆ', 'ë¬¼ê³ ê¸°', 'ê³¤ì¶©', 'ë±€', 'í˜¸ë‘ì´', 'ìš©', 'ê°œ', 'ê³ ì–‘ì´'],
            'ìì—°': ['ë¬¼', 'ë°”ë‹¤', 'ì‚°', 'ë‚˜ë¬´', 'ê½ƒ', 'ë¶ˆ', 'ë¹„', 'ë°”ëŒ', 'íƒœì–‘', 'ë‹¬'],
            'ì‚¬ëŒ': ['ê°€ì¡±', 'ì¹œêµ¬', 'ì—°ì¸', 'ì•„ì´', 'ì–´ë¥¸', 'ì£½ì€ì‚¬ëŒ', 'ìœ ëª…ì¸'],
            'ì‚¬ë¬¼': ['ì§‘', 'ëˆ', 'ì°¨', 'ì˜·', 'ìŒì‹', 'ì±…', 'í•¸ë“œí°', 'ì»´í“¨í„°'],
            'í–‰ë™': ['ë‚ ê¸°', 'ë–¨ì–´ì§€ê¸°', 'ì«“ê¸°ê¸°', 'ì‹¸ìš°ê¸°', 'ê²°í˜¼', 'ì¶œì‚°', 'ì£½ìŒ'],
            'ê°ì •': ['ê¸°ì¨', 'ìŠ¬í””', 'ë¶„ë…¸', 'ë‘ë ¤ì›€', 'ì‚¬ë‘', 'ì§ˆíˆ¬'],
            'ì‹ ì²´': ['ë¨¸ë¦¬', 'ëˆˆ', 'ì†', 'ë°œ', 'í˜ˆì•¡', 'ìƒì²˜', 'ë³‘'],
            'ì˜ì ': ['ì‹ ', 'ë¶€ì²˜', 'ê·€ì‹ ', 'ì²œì‚¬', 'ì§€ì˜¥', 'ì²œêµ­', 'ì ˆ'],
            'ì¥ì†Œ': ['ì§‘', 'í•™êµ', 'ì§ì¥', 'ë³‘ì›', 'ê³µì›', 'ë°”ë‹¤', 'ì‚°'],
            'ìƒ‰ê¹”': ['ë¹¨ê°•', 'íŒŒë‘', 'ë…¸ë‘', 'ê²€ì •', 'í°ìƒ‰', 'ì´ˆë¡']
        }
        
        # ê°ì • í‚¤ì›Œë“œ
        self.mood_keywords = {
            'positive': ['ì¢‹ì€', 'í–‰ìš´', 'ê¸¸ëª½', 'ì„±ê³µ', 'ë°œì „', 'ê¸°ì¨', 'ì¶•ë³µ', 'ë²ˆì˜'],
            'negative': ['ë‚˜ìœ', 'ë¶ˆìš´', 'í‰ëª½', 'ì‹¤íŒ¨', 'ì†ì‹¤', 'ìŠ¬í””', 'ì¬ì•™', 'ìœ„í—˜'],
            'warning': ['ì£¼ì˜', 'ê²½ê³ ', 'ì¡°ì‹¬', 'ìœ„í—˜', 'ì‹ ì¤‘', 'ê°ì„±'],
            'neutral': ['í‰ë²”í•œ', 'ì¼ë°˜ì ì¸', 'ë³´í†µì˜', 'ì¤‘ê°„', 'í‰ìƒ']
        }
    
    def get_connection(self):
        """DB ì—°ê²°"""
        # postgres ì‚¬ìš©ìë¡œ ì§ì ‘ ì—°ê²°
        import subprocess
        import os
        
        # postgres ì‚¬ìš©ì ê¶Œí•œìœ¼ë¡œ DB ì—°ê²°ì„ ìœ„í•´ subprocess í™œìš©
        return psycopg2.connect(
            host=self.db_config['host'],
            database=self.db_config['database'],
            user='postgres',
            port=self.db_config['port']
        )
    
    def extract_keywords_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return []
        
        # í•œêµ­ì–´ ëª…ì‚¬ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
        korean_words = re.findall(r'[ê°€-í£]{2,}', text)
        
        # ê¿ˆí’€ì´ ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ í•„í„°ë§
        dream_related = []
        for word in korean_words:
            if any(category_word in word for category_list in self.category_mapping.values() 
                   for category_word in category_list):
                dream_related.append(word)
            elif any(keyword in word for mood_list in self.mood_keywords.values() 
                     for keyword in mood_list):
                dream_related.append(word)
        
        return list(set(dream_related))[:10]  # ìƒìœ„ 10ê°œ
    
    def classify_category(self, text: str, keywords: List[str]) -> Tuple[str, str]:
        """ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text_lower = text.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        for category, category_keywords in self.category_mapping.items():
            for keyword in category_keywords:
                if keyword in text_lower or any(keyword in kw for kw in keywords):
                    return category, keyword
        
        # ê¸°ë³¸ê°’
        return 'ê¸°íƒ€', ''
    
    def determine_mood(self, text: str) -> str:
        """ê°ì •/ìš´ì„¸ ë¶„ë¥˜"""
        text_lower = text.lower()
        
        mood_scores = {}
        for mood, mood_keywords in self.mood_keywords.items():
            score = sum(1 for keyword in mood_keywords if keyword in text_lower)
            if score > 0:
                mood_scores[mood] = score
        
        if mood_scores:
            return max(mood_scores, key=mood_scores.get)
        return 'neutral'
    
    def generate_emoji(self, category: str, keyword: str) -> str:
        """ì¹´í…Œê³ ë¦¬ë³„ ì´ëª¨ì§€ ìƒì„±"""
        emoji_map = {
            'ë™ë¬¼': 'ğŸ¾', 'ìì—°': 'ğŸŒ¿', 'ì‚¬ëŒ': 'ğŸ‘¥', 'ì‚¬ë¬¼': 'ğŸº',
            'í–‰ë™': 'ğŸƒâ€â™‚ï¸', 'ê°ì •': 'ğŸ˜Š', 'ì‹ ì²´': 'ğŸ‘¤', 'ì˜ì ': 'ğŸ”®',
            'ì¥ì†Œ': 'ğŸ ', 'ìƒ‰ê¹”': 'ğŸ¨'
        }
        
        return emoji_map.get(category, 'âœ¨')
    
    def generate_lucky_numbers(self, text: str) -> List[int]:
        """í–‰ìš´ì˜ ìˆ«ì ìƒì„± (í…ìŠ¤íŠ¸ í•´ì‹œ ê¸°ë°˜)"""
        hash_value = hashlib.md5(text.encode('utf-8')).hexdigest()
        numbers = []
        for i in range(0, len(hash_value), 2):
            num = int(hash_value[i:i+2], 16) % 45 + 1  # 1-45 ë²”ìœ„
            numbers.append(num)
        return sorted(list(set(numbers)))[:6]  # ìƒìœ„ 6ê°œ
    
    def calculate_confidence_score(self, raw_data: Dict[str, Any]) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 5.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ë°ì´í„° ì™„ì„±ë„
        field_count = len([v for v in raw_data.values() if v and str(v).strip()])
        score += min(field_count * 0.3, 2.0)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´
        total_text = ' '.join(str(v) for v in raw_data.values() if v)
        if len(total_text) > 100:
            score += min(len(total_text) / 100, 2.0)
        
        # í•œêµ­ì–´ ë¹„ìœ¨
        korean_ratio = len(re.findall(r'[ê°€-í£]', total_text)) / len(total_text) if total_text else 0
        score += korean_ratio * 1.0
        
        return min(score, 10.0)
    
    def process_raw_item(self, raw_item: Tuple) -> Optional[ProcessedDreamData]:
        """ê°œë³„ ì›ì‹œ ë°ì´í„° ì²˜ë¦¬"""
        try:
            raw_id, source_site, raw_content, quality_hints = raw_item
            
            # JSON ë°ì´í„° íŒŒì‹±
            if isinstance(raw_content, str):
                content = json.loads(raw_content)
            else:
                content = raw_content
            
            # ì£¼ìš” í…ìŠ¤íŠ¸ ì¶”ì¶œ
            main_text = ""
            keyword_candidates = []
            
            for key, value in content.items():
                if isinstance(value, str) and value.strip():
                    main_text += value + " "
                    if key in ['title', 'keyword', 'name', 'subject']:
                        keyword_candidates.append(value.strip())
                elif isinstance(value, list):
                    main_text += " ".join(str(v) for v in value) + " "
            
            if not main_text.strip():
                return None
            
            # í‚¤ì›Œë“œ ê²°ì •
            if keyword_candidates:
                main_keyword = keyword_candidates[0][:50]  # ì²« ë²ˆì§¸ í›„ë³´, ìµœëŒ€ 50ì
            else:
                # ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ ì¶”ì¶œ
                sentences = main_text.split('.')
                main_keyword = sentences[0][:30].strip() if sentences else "ê¿ˆ"
            
            # ë¶„ë¥˜ ì‘ì—…
            keywords = self.extract_keywords_from_text(main_text)
            category, subcategory = self.classify_category(main_text, keywords)
            mood = self.determine_mood(main_text)
            emoji = self.generate_emoji(category, main_keyword)
            lucky_numbers = self.generate_lucky_numbers(main_text)
            
            # í•´ì„ ë¶„ë¦¬ ì‹œë„
            traditional = content.get('traditional', content.get('traditional_meaning', ''))
            modern = content.get('modern', content.get('modern_meaning', ''))
            
            # ì—†ìœ¼ë©´ main_textì—ì„œ ë¶„ë¦¬ ì‹œë„
            if not traditional and not modern:
                if 'ì „í†µì ìœ¼ë¡œ' in main_text or 'ì˜›ë‚ ë¶€í„°' in main_text:
                    traditional = main_text[:200]
                    modern = "í˜„ëŒ€ì  ê´€ì ì—ì„œ ì¬í•´ì„ì´ í•„ìš”í•œ ê¿ˆì…ë‹ˆë‹¤."
                else:
                    traditional = "ì „í†µì  í•´ì„ì´ í•„ìš”í•œ ê¿ˆì…ë‹ˆë‹¤."
                    modern = main_text[:200]
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self.calculate_confidence_score(content)
            
            return ProcessedDreamData(
                keyword=main_keyword,
                category=category,
                subcategory=subcategory,
                emoji=emoji,
                traditional_interpretation=traditional[:500],
                modern_interpretation=modern[:500], 
                psychology_interpretation=f"{main_keyword}ëŠ” ë¬´ì˜ì‹ì˜ ë©”ì‹œì§€ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.",
                keywords=keywords,
                related_dreams=[],
                lucky_numbers=lucky_numbers,
                mood=mood,
                frequency=1,
                tags=[category, mood],
                variations=[main_keyword],
                confidence_score=confidence,
                source_sites=[source_site]
            )
            
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜ (ID: {raw_item[0]}): {e}")
            self.error_count += 1
            return None
    
    def save_processed_data(self, processed_data: ProcessedDreamData, original_id: int):
        """ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ìµœì¢… í…Œì´ë¸”ì— ì €ì¥"""
        try:
            with self.get_connection() as conn:
                cur = conn.cursor()
                
                # dream_interpretations í…Œì´ë¸”ì´ ìˆëŠ”ì§€ í™•ì¸, ì—†ìœ¼ë©´ ìƒì„±
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS dream_interpretations (
                        id BIGSERIAL PRIMARY KEY,
                        keyword VARCHAR(200) NOT NULL,
                        keyword_variants TEXT[],
                        category_id INTEGER,
                        subcategory_id INTEGER,
                        traditional_meaning TEXT,
                        modern_meaning TEXT,
                        psychological_meaning TEXT,
                        spiritual_meaning TEXT,
                        dream_type VARCHAR(50),
                        fortune_aspect VARCHAR(20),
                        confidence_score DECIMAL(3,2) DEFAULT 0.5,
                        related_keywords TEXT[],
                        lucky_numbers INTEGER[],
                        lucky_colors VARCHAR(100)[],
                        compatible_dreams TEXT[],
                        conflicting_dreams TEXT[],
                        search_frequency INTEGER DEFAULT 0,
                        accuracy_rating DECIMAL(3,2) DEFAULT 0.0,
                        source_reliability INTEGER DEFAULT 1,
                        data_source VARCHAR(200),
                        seasonal_relevance VARCHAR(20)[],
                        cultural_context VARCHAR(100),
                        gender_specific BOOLEAN DEFAULT false,
                        age_group VARCHAR(50),
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                        created_by VARCHAR(100),
                        last_verified_at TIMESTAMP WITH TIME ZONE
                    )
                """)
                
                # ë°ì´í„° ì‚½ì…
                insert_sql = """
                INSERT INTO dream_service.dream_interpretations 
                (keyword, traditional_meaning, modern_meaning, psychological_meaning,
                 fortune_aspect, confidence_score, related_keywords, lucky_numbers,
                 data_source, created_by)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
                """
                
                cur.execute(insert_sql, (
                    processed_data.keyword,
                    processed_data.traditional_interpretation,
                    processed_data.modern_interpretation,
                    processed_data.psychology_interpretation,
                    processed_data.mood,
                    processed_data.confidence_score,
                    processed_data.keywords,
                    processed_data.lucky_numbers,
                    ','.join(processed_data.source_sites),
                    'dream_classifier_v2'
                ))
                
                final_id = cur.fetchone()[0]
                
                # ì›ë³¸ raw_collection ì—…ë°ì´íŠ¸
                cur.execute("""
                    UPDATE dream_service.dream_raw_collection 
                    SET processing_status = 'completed',
                        processed_at = CURRENT_TIMESTAMP,
                        processing_notes = %s
                    WHERE id = %s
                """, (f'Processed to dream_interpretations id: {final_id}', original_id))
                
                conn.commit()
                self.processed_count += 1
                
        except Exception as e:
            logger.error(f"ì €ì¥ ì˜¤ë¥˜: {e}")
            self.error_count += 1
    
    def get_pending_items(self, limit: int = 100) -> List[Tuple]:
        """ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ì›ì‹œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        with self.get_connection() as conn:
            cur = conn.cursor()
            
            cur.execute("""
                SELECT id, source_site, raw_content, quality_hints
                FROM dream_service.dream_raw_collection 
                WHERE processing_status = 'pending'
                AND (quality_hints->>'estimated_quality')::float >= 5.0
                ORDER BY (quality_hints->>'estimated_quality')::float DESC
                LIMIT %s
            """, (limit,))
            
            return cur.fetchall()
    
    def run_classification_batch(self, batch_size: int = 50):
        """ë°°ì¹˜ ë¶„ë¥˜ ì‹¤í–‰"""
        logger.info(f"ğŸ¤– ê¿ˆí’€ì´ ë°ì´í„° ë¶„ë¥˜ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        while True:
            # ì²˜ë¦¬ ëŒ€ê¸° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            pending_items = self.get_pending_items(batch_size)
            
            if not pending_items:
                logger.info("âœ… ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            logger.info(f"ğŸ“¦ {len(pending_items)}ê°œ í•­ëª© ì²˜ë¦¬ ì¤‘...")
            
            # ë³‘ë ¬ ì²˜ë¦¬
            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = {
                    executor.submit(self.process_raw_item, item): item[0] 
                    for item in pending_items
                }
                
                for future in as_completed(futures):
                    original_id = futures[future]
                    try:
                        processed_data = future.result()
                        if processed_data:
                            self.save_processed_data(processed_data, original_id)
                            if self.processed_count % 10 == 0:
                                logger.info(f"âœ¨ ì§„í–‰ë¥ : {self.processed_count}ê°œ ì™„ë£Œ")
                    except Exception as e:
                        logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜ (ID: {original_id}): {e}")
            
            time.sleep(1)  # ë¶€í•˜ ë°©ì§€
        
        logger.info(f"ğŸ‰ ë¶„ë¥˜ ì™„ë£Œ! ì´ ì²˜ë¦¬: {self.processed_count}ê°œ, ì—ëŸ¬: {self.error_count}ê°œ")
    
    def get_classification_stats(self) -> Dict[str, Any]:
        """ë¶„ë¥˜ í†µê³„ ë°˜í™˜"""
        with self.get_connection() as conn:
            cur = conn.cursor()
            
            # ì²˜ë¦¬ ìƒíƒœë³„ í†µê³„
            cur.execute("""
                SELECT processing_status, COUNT(*) 
                FROM dream_service.dream_raw_collection 
                GROUP BY processing_status
            """)
            status_stats = dict(cur.fetchall())
            
            # ìµœì¢… í…Œì´ë¸” í†µê³„
            cur.execute("SELECT COUNT(*) FROM dream_service.dream_interpretations")
            final_count = cur.fetchone()[0] if cur.rowcount > 0 else 0
            
            return {
                'raw_data_stats': status_stats,
                'final_interpretations': final_count,
                'processed_count': self.processed_count,
                'error_count': self.error_count,
                'updated_at': datetime.now().isoformat()
            }

def main():
    parser = argparse.ArgumentParser(description='ê¿ˆí’€ì´ ë°ì´í„° ë¶„ë¥˜ê¸°')
    parser.add_argument('--batch-size', type=int, default=50, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--stats', action='store_true', help='í†µê³„ë§Œ í‘œì‹œ')
    parser.add_argument('--db-name', default='heal7', help='ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„')
    
    args = parser.parse_args()
    
    # DB ì„¤ì • - postgres ì‚¬ìš©ìë¡œ ì—°ê²°
    db_config = {
        'host': 'localhost',
        'database': args.db_name,
        'user': 'postgres', 
        'password': '',
        'port': 5432
    }
    
    classifier = DreamDataClassifier(db_config)
    
    try:
        if args.stats:
            stats = classifier.get_classification_stats()
            print("ğŸ“Š ë¶„ë¥˜ í†µê³„:")
            print(json.dumps(stats, indent=2, ensure_ascii=False))
        else:
            classifier.run_classification_batch(args.batch_size)
            
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()