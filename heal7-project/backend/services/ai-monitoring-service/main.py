#!/usr/bin/env python3
"""
HEAL7 AI Dashboard API with CLI Support
Claude CLIì™€ Gemini CLIë¥¼ í¬í•¨í•œ AI ëª¨ë¸ í†µí•© ëŒ€ì‹œë³´ë“œ API
"""

import asyncio
import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import socket

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

app = FastAPI(title="HEAL7 AI Dashboard API", version="2.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê¸°ë³¸ ì„¤ì •
API_KEYS_FILE = "/home/ubuntu/.env.ai"
CLI_TIMEOUT = 30  # seconds

# .env.ai íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
def load_env_ai():
    env_path = API_KEYS_FILE
    env_vars = {}
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
                    os.environ[key.strip()] = value.strip()
        print(f"âœ… .env.ai íŒŒì¼ì—ì„œ {len(env_vars)}ê°œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
        return env_vars
    except Exception as e:
        print(f"âš ï¸ .env.ai íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

# ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
ENV_VARS = load_env_ai()

class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    model_id: str
    messages: List[ChatMessage]
    max_tokens: Optional[int] = 2000
    temperature: Optional[float] = 0.7
    mode: Optional[str] = "balanced"

class CLITestRequest(BaseModel):
    command: str

class CLIChatRequest(BaseModel):
    model_id: str
    command: str
    context: Optional[str] = ""
    max_tokens: Optional[int] = 2000

# API í‚¤ ë¡œë“œ
def load_api_keys() -> Dict[str, str]:
    """API í‚¤ íŒŒì¼ì—ì„œ í‚¤ë“¤ì„ ë¡œë“œ"""
    keys = {}
    try:
        if os.path.exists(API_KEYS_FILE):
            with open(API_KEYS_FILE, 'r') as f:
                for line in f:
                    if '=' in line and not line.strip().startswith('#'):
                        key, value = line.strip().split('=', 1)
                        keys[key] = value.strip('"\'')
    except Exception as e:
        print(f"API í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return keys

# CLI ê´€ë¦¬ ì‹œìŠ¤í…œ
class CLIManager:
    """Claude CLIì™€ Gemini CLI ê´€ë¦¬"""
    
    def __init__(self):
        self.cli_processes = {}
        self.supported_clis = {
            'claude_cli': {
                'command': 'claude',
                'check_args': ['--version'],
                'test_args': ['--help']
            },
            'gemini_cli': {
                'command': 'gemini',
                'check_args': ['--version'],
                'test_args': ['--help']
            }
        }
    
    async def check_cli_status(self, cli_id: str) -> Dict[str, Any]:
        """CLI ìƒíƒœ í™•ì¸"""
        if cli_id not in self.supported_clis:
            return {'connected': False, 'error': 'Unsupported CLI'}
        
        cli_config = self.supported_clis[cli_id]
        
        try:
            # CLI ëª…ë ¹ì–´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            process = await asyncio.create_subprocess_exec(
                cli_config['command'], *cli_config['check_args'],
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            start_time = datetime.now()
            stdout, stderr = await asyncio.wait_for(
                process.communicate(), 
                timeout=CLI_TIMEOUT
            )
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            
            if process.returncode == 0:
                return {
                    'connected': True,
                    'response_time': response_time,
                    'version': stdout.decode().strip() if stdout else 'Unknown'
                }
            else:
                return {
                    'connected': False,
                    'error': stderr.decode().strip() if stderr else 'Command failed'
                }
                
        except asyncio.TimeoutError:
            return {'connected': False, 'error': 'Timeout'}
        except FileNotFoundError:
            return {'connected': False, 'error': 'CLI not installed'}
        except Exception as e:
            return {'connected': False, 'error': str(e)}
    
    async def test_cli_connection(self, cli_id: str, test_command: str = 'echo test') -> Dict[str, Any]:
        """CLI ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if cli_id not in self.supported_clis:
            return {'success': False, 'error': 'Unsupported CLI'}
        
        cli_config = self.supported_clis[cli_id]
        
        try:
            if cli_id == 'claude_cli':
                # Claude CLI í…ŒìŠ¤íŠ¸ - ê°„ë‹¨í•œ ëª…ë ¹ ì‹¤í–‰
                process = await asyncio.create_subprocess_exec(
                    'claude', '--help',
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
            elif cli_id == 'gemini_cli':
                # Gemini CLI í…ŒìŠ¤íŠ¸
                process = await asyncio.create_subprocess_exec(
                    'gemini', '--help',
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
            
            start_time = datetime.now()
            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=CLI_TIMEOUT
            )
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            
            return {
                'success': process.returncode == 0,
                'response_time': response_time,
                'output': stdout.decode().strip() if stdout else '',
                'error': stderr.decode().strip() if stderr and process.returncode != 0 else None
            }
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    async def send_cli_command(self, cli_id: str, command: str, context: str = '') -> Dict[str, Any]:
        """CLIì— ëª…ë ¹ ì „ì†¡"""
        if cli_id not in self.supported_clis:
            raise HTTPException(status_code=400, detail='Unsupported CLI')
        
        try:
            if cli_id == 'claude_cli':
                # Claude CLIëŠ” --print ì˜µì…˜ì„ ì‚¬ìš©í•´ì„œ ë¹„ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¡œ ì‹¤í–‰
                full_prompt = command
                if context:
                    full_prompt = f"Context: {context}\n\nUser: {command}"
                    
                process = await asyncio.create_subprocess_exec(
                    'claude', '--print', full_prompt,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
            
            elif cli_id == 'gemini_cli':
                # Gemini CLIë„ ë¹„ìŠ·í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as tmp_file:
                    if context:
                        tmp_file.write(f"Context: {context}\n\nUser: {command}")
                    else:
                        tmp_file.write(command)
                    tmp_file.flush()
                    
                    # Gemini CLIëŠ” ì¼ë°˜ì ìœ¼ë¡œ stdinìœ¼ë¡œ ì…ë ¥ì„ ë°›ëŠ”ë‹¤
                    process = await asyncio.create_subprocess_shell(
                        f"cat {tmp_file.name} | gemini",
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                os.unlink(tmp_file.name)
            
            start_time = datetime.now()
            stdout, stderr = await asyncio.wait_for(
                process.communicate(),
                timeout=CLI_TIMEOUT
            )
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            
            if process.returncode == 0:
                response_text = stdout.decode().strip()
                return {
                    'response': response_text or 'ëª…ë ¹ì´ ì‹¤í–‰ë˜ì—ˆì§€ë§Œ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.',
                    'model_name': f"{cli_id.replace('_', ' ').title()}",
                    'response_time': response_time,
                    'usage': {'cost': 0.0}  # CLIëŠ” ë¬´ë£Œ
                }
            else:
                error_text = stderr.decode().strip()
                raise HTTPException(status_code=500, detail=f'CLI ì˜¤ë¥˜: {error_text}')
                
        except asyncio.TimeoutError:
            raise HTTPException(status_code=408, detail='CLI ëª…ë ¹ ì‹œê°„ ì´ˆê³¼')
        except Exception as e:
            raise HTTPException(status_code=500, detail=f'CLI ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}')

# CLI ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
cli_manager = CLIManager()

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """API ì •ë³´ ë°˜í™˜"""
    return {
        "service": "HEAL7 AI Dashboard API",
        "version": "2.0.0",
        "status": "online",
        "supported_models": 9,  # 7ê°œ API ëª¨ë¸ + 2ê°œ CLI ëª¨ë¸
        "cli_support": True,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/models")
async def get_models():
    """ì§€ì›í•˜ëŠ” ëª¨ë“  ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    api_models = [
        {
            "id": "gemini_2_0_flash",
            "name": "Gemini Flash",
            "provider": "Google",
            "status": "online",
            "response_time": 1.2,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "ë¬´ë£Œ (100ë§Œ í† í°)",
            "features": ["í…ìŠ¤íŠ¸", "ì´ë¯¸ì§€ ë¶„ì„", "ë™ì˜ìƒ ë¶„ì„"]
        },
        {
            "id": "gpt_4o",
            "name": "GPT-4o",
            "provider": "OpenAI",
            "status": "online",
            "response_time": 1.8,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$2.5/$10",
            "features": ["í…ìŠ¤íŠ¸", "ì´ë¯¸ì§€ ë¶„ì„", "PDF ë¬¸ì„œ", "ìŒì„± ë¶„ì„"]
        },
        {
            "id": "claude_sonnet_4",
            "name": "Claude Sonnet 4",
            "provider": "Anthropic",
            "status": "online",
            "response_time": 2.1,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$3/$15",
            "features": ["í…ìŠ¤íŠ¸", "ì´ë¯¸ì§€ ë¶„ì„", "ì½”ë”©", "1M ì»¨í…ìŠ¤íŠ¸"]
        },
        {
            "id": "gpt_5",
            "name": "GPT-5",
            "provider": "OpenAI",
            "status": "online",
            "response_time": 2.5,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$4/$20",
            "features": ["í…ìŠ¤íŠ¸", "ê³ ê¸‰ ì¶”ë¡ ", "ì°½ì˜ì„±", "ì½”ë”©"]
        },
        {
            "id": "gpt_5_mini",
            "name": "GPT-5 Mini",
            "provider": "OpenAI",
            "status": "online",
            "response_time": 1.0,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$1/$5",
            "features": ["í…ìŠ¤íŠ¸", "ë¹ ë¥¸ ì‘ë‹µ", "íš¨ìœ¨ì„±"]
        },
        {
            "id": "gpt_4_1",
            "name": "GPT-4.1",
            "provider": "OpenAI",
            "status": "online",
            "response_time": 1.6,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$3/$12",
            "features": ["í…ìŠ¤íŠ¸", "í–¥ìƒëœ ì¶”ë¡ ", "ì½”ë”©", "ë¶„ì„"]
        },
        {
            "id": "claude_35_sonnet",
            "name": "Claude 3.5 Sonnet",
            "provider": "Anthropic",
            "status": "online",
            "response_time": 1.7,
            "last_check": datetime.now().isoformat(),
            "error_message": None,
            "cost": "$3/$15",
            "features": ["í…ìŠ¤íŠ¸", "ë¶„ì„", "ì½”ë”©", "200K ì»¨í…ìŠ¤íŠ¸"]
        }
    ]
    
    # CLI ëª¨ë¸ ìƒíƒœ í™•ì¸ í›„ ì¶”ê°€
    cli_models = []
    for cli_id in ['claude_cli', 'gemini_cli']:
        status = await cli_manager.check_cli_status(cli_id)
        cli_models.append({
            "id": cli_id,
            "name": cli_id.replace('_', ' ').title(),
            "provider": "Anthropic CLI" if "claude" in cli_id else "Google CLI",
            "status": "online" if status.get('connected') else "offline",
            "response_time": status.get('response_time', 0),
            "last_check": datetime.now().isoformat(),
            "error_message": status.get('error'),
            "cost": "ë¡œì»¬ ì‹¤í–‰",
            "features": ["ì½”ë“œ ìƒì„±", "í„°ë¯¸ë„ ì—°ë™"] if "claude" in cli_id else ["ì½”ë“œ ë¶„ì„", "ìë™í™”"],
            "type": "cli"
        })
    
    return api_models + cli_models

@app.get("/cli/status/{cli_id}")
async def get_cli_status(cli_id: str):
    """íŠ¹ì • CLI ìƒíƒœ í™•ì¸"""
    status = await cli_manager.check_cli_status(cli_id)
    return status

@app.post("/cli/test/{cli_id}")
async def test_cli(cli_id: str, request: CLITestRequest):
    """CLI ì—°ê²° í…ŒìŠ¤íŠ¸"""
    result = await cli_manager.test_cli_connection(cli_id, request.command)
    return result

@app.post("/cli/chat")
async def cli_chat(request: CLIChatRequest):
    """CLI ëª¨ë¸ê³¼ ì±„íŒ…"""
    result = await cli_manager.send_cli_command(
        request.model_id, 
        request.command, 
        request.context
    )
    return result

@app.post("/chat")
async def chat(request: ChatRequest):
    """AI ëª¨ë¸ê³¼ ì±„íŒ… (API ëª¨ë¸ ì „ìš©)"""
    # CLI ëª¨ë¸ì€ ë³„ë„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
    if request.model_id in ['claude_cli', 'gemini_cli']:
        raise HTTPException(
            status_code=400, 
            detail="CLI ëª¨ë¸ì€ /cli/chat ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”"
        )
    
    # ì‹¤ì œ AI API í˜¸ì¶œ
    message_text = request.messages[-1].content if request.messages else "Hello"
    
    try:
        if request.model_id == "gemini_2_0_flash":
            # Gemini API í˜¸ì¶œ
            import google.generativeai as genai
            
            # API í‚¤ ì„¤ì •
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                raise HTTPException(status_code=500, detail="Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            conversation_context = ""
            for msg in request.messages:
                conversation_context += f"{msg.role}: {msg.content}\n"
            
            start_time = datetime.now()
            response = model.generate_content(
                conversation_context,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=request.max_tokens,
                    temperature=request.temperature,
                )
            )
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            response_text = response.text
            
            return {
                "response": response_text,
                "model_name": "Gemini 2.0 Flash",
                "response_time": response_time,
                "usage": {
                    "cost": 0.0,  # Gemini FlashëŠ” ë¬´ë£Œ
                    "input_tokens": response.usage_metadata.prompt_token_count if hasattr(response, 'usage_metadata') else 0,
                    "output_tokens": response.usage_metadata.candidates_token_count if hasattr(response, 'usage_metadata') else len(response_text.split())
                }
            }
            
        elif request.model_id == "claude_35_sonnet":
            # Claude API í˜¸ì¶œ
            import anthropic
            
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if not api_key:
                raise HTTPException(status_code=500, detail="Claude API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            client = anthropic.Anthropic(api_key=api_key)
            
            # ë©”ì‹œì§€ í¬ë§· ë³€í™˜
            messages = []
            for msg in request.messages:
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
            
            start_time = datetime.now()
            response = client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=request.max_tokens,
                temperature=request.temperature,
                messages=messages
            )
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            response_text = response.content[0].text
            
            return {
                "response": response_text,
                "model_name": "Claude 3.5 Sonnet",
                "response_time": response_time,
                "usage": {
                    "cost": (response.usage.input_tokens * 0.000003) + (response.usage.output_tokens * 0.000015),
                    "input_tokens": response.usage.input_tokens,
                    "output_tokens": response.usage.output_tokens
                }
            }
            
        else:
            # ë‹¤ë¥¸ ëª¨ë¸ë“¤ì€ ì„ì‹œ Mock ì‘ë‹µ
            mock_responses = {
                "gpt_4o": f"ì•ˆë…•í•˜ì„¸ìš”! GPT-4oì…ë‹ˆë‹¤. '{message_text}'ì— ëŒ€í•´ ìì„¸íˆ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "claude_sonnet_4": f"ì•ˆë…•í•˜ì„¸ìš”! Claude Sonnet 4ì…ë‹ˆë‹¤. '{message_text}'ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "gpt_5": f"ì•ˆë…•í•˜ì„¸ìš”! GPT-5ì…ë‹ˆë‹¤. '{message_text}'ì— ëŒ€í•œ ê³ ê¸‰ ì¶”ë¡  ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                "gpt_5_mini": f"ì•ˆë…•í•˜ì„¸ìš”! GPT-5 Miniì…ë‹ˆë‹¤. '{message_text}'ì— ëŒ€í•´ ë¹ ë¥´ê²Œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.",
                "gpt_4_1": f"ì•ˆë…•í•˜ì„¸ìš”! GPT-4.1ì…ë‹ˆë‹¤. '{message_text}'ì— ëŒ€í•œ í–¥ìƒëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."
            }
            
            response_text = mock_responses.get(
                request.model_id, 
                f"ì£„ì†¡í•©ë‹ˆë‹¤. {request.model_id} ëª¨ë¸ì€ ì•„ì§ ì—°ë™ ì¤‘ì…ë‹ˆë‹¤."
            )
            
            return {
                "response": response_text,
                "model_name": request.model_id.replace('_', ' ').title(),
                "response_time": 1.2,
                "usage": {
                    "cost": 0.005,
                    "input_tokens": len(message_text.split()) * 1.3,
                    "output_tokens": len(response_text.split()) * 1.3
                }
            }
            
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°±
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ {request.model_id} ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (ì˜¤ë¥˜: {str(e)})",
            "model_name": request.model_id.replace('_', ' ').title(),
            "response_time": 0.1,
            "usage": {
                "cost": 0.0,
                "input_tokens": 0,
                "output_tokens": 0
            }
        }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime": "running",
        "cli_support": True
    }

if __name__ == "__main__":
    print("ğŸš€ HEAL7 AI Dashboard API with CLI Support ì‹œì‘")
    print("ğŸ”§ ì§€ì› ëª¨ë¸: 7ê°œ API ëª¨ë¸ + 2ê°œ CLI ëª¨ë¸")
    print("ğŸ’» CLI ì§€ì›: Claude CLI, Gemini CLI")
    print("ğŸŒ í¬íŠ¸: 8004")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8004,
        reload=False,
        access_log=True
    )