# âš™ï¸ HEAL7 DevOps CI/CD íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ v1.0

> **í”„ë¡œì íŠ¸**: HEAL7 ì˜´ë‹ˆë²„ìŠ¤ í”Œë«í¼ DevOps ì „ëµ  
> **ë²„ì „**: v1.0.0  
> **ì‘ì„±ì¼**: 2025-08-18  
> **ëª©ì **: ë¹ ë¥¸ ê°œë°œ ì£¼ê¸°ì™€ ì•ˆì •ì  ë°°í¬ë¥¼ ìœ„í•œ ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸  
> **ë²”ìœ„**: CI/CD, IaC, ì»¨í…Œì´ë„ˆí™”, ëª¨ë‹ˆí„°ë§, í’ˆì§ˆ ê²Œì´íŠ¸

---

## ğŸ¯ **DevOps ì² í•™ ë° ì „ëµ**

### **ğŸš€ í•µì‹¬ DevOps ì›ì¹™**
```yaml
devops_principles:
  shift_left_security: "ê°œë°œ ì´ˆê¸° ë‹¨ê³„ë¶€í„° ë³´ì•ˆ ë‚´ì¬í™”"
  everything_as_code: "ì¸í”„ë¼, êµ¬ì„±, ì •ì±… ëª¨ë“  ê²ƒì„ ì½”ë“œë¡œ ê´€ë¦¬"
  fail_fast_principle: "ë¹ ë¥¸ ì‹¤íŒ¨ë¥¼ í†µí•œ ì‹ ì†í•œ í•™ìŠµ"
  continuous_improvement: "ì§€ì†ì  ê°œì„ ê³¼ ìµœì í™”"
  observability_first: "ê´€ì°°ê°€ëŠ¥ì„± ìš°ì„  ì„¤ê³„"
  
delivery_metrics: # DORA ë©”íŠ¸ë¦­ ê¸°ë°˜
  deployment_frequency: "ì¼ 10íšŒ ì´ìƒ ë°°í¬"
  lead_time: "ì»¤ë°‹ë¶€í„° ë°°í¬ê¹Œì§€ < 30ë¶„"
  mttr: "ì¥ì•  ë³µêµ¬ ì‹œê°„ < 1ì‹œê°„"
  change_failure_rate: "ë°°í¬ ì‹¤íŒ¨ìœ¨ < 5%"
```

### **ğŸ—ï¸ ë ˆê³ ë¸”ëŸ­ ëª¨ë“ˆí˜• íŒŒì´í”„ë¼ì¸**
```yaml
modular_pipeline_philosophy:
  pipeline_as_lego_blocks: "ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸"
  environment_agnostic: "í™˜ê²½ ë…ë¦½ì  íŒŒì´í”„ë¼ì¸ ì„¤ê³„"
  service_specific_pipelines: "ì„œë¹„ìŠ¤ë³„ ë§ì¶¤í˜• íŒŒì´í”„ë¼ì¸"
  shared_pipeline_libraries: "ê³µí†µ íŒŒì´í”„ë¼ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬"
```

---

## ğŸ”„ **ì „ì²´ CI/CD íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜**

### **ğŸ“Š íŒŒì´í”„ë¼ì¸ ì „ì²´ íë¦„**

#### **1. ì†ŒìŠ¤ ì½”ë“œ â†’ í”„ë¡œë•ì…˜ ì „ì²´ ì—¬ì •**
```mermaid
graph TD
    A[ê°œë°œì ì»¤ë°‹] --> B{PR ìƒì„±}
    B --> C[CI Pipeline ì‹œì‘]
    
    C --> D[ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬]
    C --> E[ë³´ì•ˆ ìŠ¤ìº”]
    C --> F[ë‹¨ìœ„ í…ŒìŠ¤íŠ¸]
    C --> G[í†µí•© í…ŒìŠ¤íŠ¸]
    
    D --> H{í’ˆì§ˆ ê²Œì´íŠ¸ í†µê³¼?}
    E --> H
    F --> H
    G --> H
    
    H -->|Pass| I[ì•„í‹°íŒ©íŠ¸ ë¹Œë“œ]
    H -->|Fail| J[PR ë¸”ë¡œí‚¹]
    
    I --> K[ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ]
    K --> L[ë³´ì•ˆ ìŠ¤ìº” (ì´ë¯¸ì§€)]
    L --> M[ë ˆì§€ìŠ¤íŠ¸ë¦¬ Push]
    
    M --> N[CD Pipeline ì‹œì‘]
    N --> O[Dev í™˜ê²½ ë°°í¬]
    O --> P[E2E í…ŒìŠ¤íŠ¸]
    P --> Q{í…ŒìŠ¤íŠ¸ í†µê³¼?}
    
    Q -->|Pass| R[Staging ë°°í¬]
    Q -->|Fail| S[ë¡¤ë°± & ì•Œë¦¼]
    
    R --> T[ì„±ëŠ¥ í…ŒìŠ¤íŠ¸]
    R --> U[ë³´ì•ˆ í…ŒìŠ¤íŠ¸]
    R --> V[UAT]
    
    T --> W{ë°°í¬ ìŠ¹ì¸?}
    U --> W
    V --> W
    
    W -->|Approved| X[Production ë°°í¬]
    W -->|Rejected| Y[ìˆ˜ì • ìš”ì²­]
    
    X --> Z[ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§]
```

#### **2. íŒŒì´í”„ë¼ì¸ êµ¬ì„± ìš”ì†Œ**
```yaml
pipeline_components:
  source_control: # ì†ŒìŠ¤ ì½”ë“œ ê´€ë¦¬
    platform: "GitHub Enterprise"
    branching_strategy: "GitHub Flow + Environment Branches"
    protection_rules: "main branch ë³´í˜¸, í•„ìˆ˜ ë¦¬ë·°"
    
  ci_platform: # ì§€ì†ì  í†µí•©
    primary: "GitHub Actions"
    secondary: "Jenkins (ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°)"
    runners: "Self-hosted + GitHub-hosted"
    
  cd_platform: # ì§€ì†ì  ë°°í¬
    gitops_tool: "ArgoCD"
    deployment_tool: "Helm + Kustomize"
    approval_system: "GitHub Environments"
    
  artifact_storage: # ì•„í‹°íŒ©íŠ¸ ì €ì¥ì†Œ
    container_registry: "Amazon ECR"
    package_registry: "GitHub Packages"
    dependency_cache: "GitHub Actions Cache"
    
  infrastructure: # ì¸í”„ë¼
    iac_tool: "Terraform + Terragrunt"
    container_platform: "Amazon EKS"
    service_mesh: "Istio"
    secrets_management: "AWS Secrets Manager + External Secrets"
```

---

## ğŸ”§ **CI (Continuous Integration) ìƒì„¸ ì„¤ê³„**

### **ğŸ“‹ GitHub Actions ì›Œí¬í”Œë¡œìš°**

#### **1. ë©”ì¸ CI ì›Œí¬í”Œë¡œìš°**
```yaml
# .github/workflows/ci-main.yml
name: ğŸš€ HEAL7 Main CI Pipeline

on:
  pull_request:
    branches: [main, develop]
    paths-ignore: ['docs/**', '*.md']
  push:
    branches: [main]

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  DOCKER_BUILDKIT: 1

jobs:
  # ğŸ” ì½”ë“œ í’ˆì§ˆ ë° ë³´ì•ˆ ê²€ì‚¬
  code-quality:
    name: ğŸ“Š Code Quality & Security
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ›’ Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # SonarQube ë¶„ì„ìš©
          
      - name: ğŸ” Run SonarQube Scan
        uses: sonarqube-quality-gate-action@master
        with:
          scanMetadataReportFile: target/sonar/report-task.txt
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
          
      - name: ğŸ›¡ï¸ Security Scan (Bandit)
        run: |
          pip install bandit[toml]
          bandit -r backend/ -f json -o security-report.json
          
      - name: ğŸ” Dependency Security Scan
        uses: pypa/gh-action-pip-audit@v1.0.8
        with:
          inputs: backend/requirements.txt
          
      - name: ğŸ“¤ Upload Security Reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            security-report.json
            pip-audit-report.json

  # ğŸ§ª í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸
  frontend-tests:
    name: ğŸ¨ Frontend Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./frontend
    steps:
      - name: ğŸ›’ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: ğŸ“¥ Install dependencies
        run: npm ci
        
      - name: ğŸ” ESLint
        run: npm run lint
        
      - name: ğŸ¯ TypeScript Check
        run: npm run type-check
        
      - name: ğŸ§ª Unit Tests
        run: npm run test:unit -- --coverage
        
      - name: ğŸ­ Component Tests (Playwright)
        run: npm run test:component
        
      - name: ğŸ“Š Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./frontend/coverage/lcov.info
          flags: frontend

  # ğŸ ë°±ì—”ë“œ í…ŒìŠ¤íŠ¸
  backend-tests:
    name: ğŸ”§ Backend Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: heal7_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    defaults:
      run:
        working-directory: ./backend
    steps:
      - name: ğŸ›’ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: ğŸ“¥ Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          
      - name: ğŸ” Flake8 Linting
        run: flake8 --config setup.cfg
        
      - name: ğŸ§ª Unit Tests
        run: |
          pytest tests/unit/ --cov=src --cov-report=xml
        env:
          DATABASE_URL: postgresql://test:test@localhost/heal7_test
          REDIS_URL: redis://localhost:6379
          
      - name: ğŸ”— Integration Tests
        run: |
          pytest tests/integration/ --cov-append --cov=src --cov-report=xml
        env:
          DATABASE_URL: postgresql://test:test@localhost/heal7_test
          REDIS_URL: redis://localhost:6379
          
      - name: ğŸ“Š Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./backend/coverage.xml
          flags: backend

  # ğŸ—ï¸ ë¹Œë“œ ë° ì»¨í…Œì´ë„ˆí™”
  build-and-containerize:
    name: ğŸ³ Build & Containerize
    needs: [code-quality, frontend-tests, backend-tests]
    runs-on: ubuntu-latest
    outputs:
      frontend-image: ${{ steps.meta-frontend.outputs.tags }}
      backend-image: ${{ steps.meta-backend.outputs.tags }}
    steps:
      - name: ğŸ›’ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ” Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-2
          
      - name: ğŸ”‘ Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
        
      - name: ğŸ·ï¸ Extract metadata (Frontend)
        id: meta-frontend
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.login-ecr.outputs.registry }}/heal7-frontend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            
      - name: ğŸ·ï¸ Extract metadata (Backend)
        id: meta-backend
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.login-ecr.outputs.registry }}/heal7-backend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            
      - name: ğŸ”¨ Build and push Frontend image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ steps.meta-frontend.outputs.tags }}
          labels: ${{ steps.meta-frontend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: ğŸ”¨ Build and push Backend image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ steps.meta-backend.outputs.tags }}
          labels: ${{ steps.meta-backend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: ğŸ” Container Security Scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.meta-backend.outputs.tags }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          
      - name: ğŸ“¤ Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
```

#### **2. E2E í…ŒìŠ¤íŠ¸ ì›Œí¬í”Œë¡œìš°**
```yaml
# .github/workflows/e2e-tests.yml
name: ğŸ­ E2E Tests

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      frontend-image:
        required: true
        type: string
      backend-image:
        required: true
        type: string

jobs:
  e2e-tests:
    name: ğŸ­ End-to-End Tests
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    steps:
      - name: ğŸ›’ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸš€ Deploy to test environment
        run: |
          # Helmì„ ì‚¬ìš©í•œ ì„ì‹œ í™˜ê²½ ë°°í¬
          helm upgrade --install heal7-e2e ./k8s/helm/heal7 \
            --namespace e2e-${{ github.run_id }} \
            --create-namespace \
            --set frontend.image=${{ inputs.frontend-image }} \
            --set backend.image=${{ inputs.backend-image }} \
            --set ingress.enabled=false \
            --wait --timeout=10m
            
      - name: ğŸ“¦ Setup Node.js for E2E
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: e2e/package-lock.json
          
      - name: ğŸ“¥ Install E2E dependencies
        working-directory: ./e2e
        run: npm ci
        
      - name: ğŸ­ Install Playwright
        working-directory: ./e2e
        run: npx playwright install --with-deps
        
      - name: ğŸ§ª Run E2E tests
        working-directory: ./e2e
        run: |
          export BASE_URL=http://heal7-frontend.e2e-${{ github.run_id }}.svc.cluster.local
          npm run test:e2e
        env:
          CI: true
          
      - name: ğŸ“Š Upload E2E artifacts
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-results
          path: |
            e2e/test-results/
            e2e/playwright-report/
            
      - name: ğŸ§¹ Cleanup test environment
        if: always()
        run: |
          helm uninstall heal7-e2e --namespace e2e-${{ github.run_id }}
          kubectl delete namespace e2e-${{ github.run_id }} --ignore-not-found
```

### **ğŸ” í’ˆì§ˆ ê²Œì´íŠ¸ ë° ê²€ì¦**

#### **1. ì¢…í•© í’ˆì§ˆ ê²Œì´íŠ¸**
```yaml
quality_gates:
  code_coverage:
    frontend_threshold: "80%"
    backend_threshold: "85%"
    integration_threshold: "70%"
    
  security_requirements:
    vulnerability_threshold: "none (high/critical)"
    dependency_updates: "weekly"
    security_scan_required: true
    
  performance_requirements:
    build_time_max: "10 minutes"
    test_time_max: "15 minutes"
    image_size_max: "500MB"
    
  code_quality:
    sonarqube_gate: "passed"
    complexity_threshold: "10"
    duplication_threshold: "3%"
    
  accessibility:
    wcag_compliance: "AA"
    lighthouse_score: "> 90"
    automated_testing: true
```

#### **2. ìë™í™”ëœ í’ˆì§ˆ ê²€ì‚¬**
```python
# scripts/quality-gate-checker.py
#!/usr/bin/env python3
"""
ì¢…í•© í’ˆì§ˆ ê²Œì´íŠ¸ ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
"""
import json
import sys
from typing import Dict, List, Any
import requests

class QualityGateChecker:
    def __init__(self, config_path: str):
        with open(config_path) as f:
            self.config = json.load(f)
        self.results = []
        
    def check_code_coverage(self) -> bool:
        """ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ê²€ì‚¬"""
        try:
            with open('coverage/coverage-summary.json') as f:
                coverage = json.load(f)
            
            frontend_coverage = coverage.get('total', {}).get('lines', {}).get('pct', 0)
            backend_coverage = self._get_backend_coverage()
            
            frontend_pass = frontend_coverage >= self.config['coverage']['frontend_threshold']
            backend_pass = backend_coverage >= self.config['coverage']['backend_threshold']
            
            self.results.append({
                'check': 'code_coverage',
                'status': 'pass' if (frontend_pass and backend_pass) else 'fail',
                'details': {
                    'frontend': f"{frontend_coverage}%",
                    'backend': f"{backend_coverage}%"
                }
            })
            
            return frontend_pass and backend_pass
            
        except Exception as e:
            self.results.append({
                'check': 'code_coverage',
                'status': 'error',
                'error': str(e)
            })
            return False
    
    def check_security_vulnerabilities(self) -> bool:
        """ë³´ì•ˆ ì·¨ì•½ì  ê²€ì‚¬"""
        try:
            # Trivy ê²°ê³¼ íŒŒì‹±
            with open('security-reports/trivy-results.json') as f:
                trivy_results = json.load(f)
            
            high_critical_vulns = []
            for result in trivy_results.get('Results', []):
                for vuln in result.get('Vulnerabilities', []):
                    if vuln.get('Severity') in ['HIGH', 'CRITICAL']:
                        high_critical_vulns.append(vuln)
            
            has_critical_vulns = len(high_critical_vulns) > 0
            
            self.results.append({
                'check': 'security_vulnerabilities',
                'status': 'fail' if has_critical_vulns else 'pass',
                'details': {
                    'high_critical_count': len(high_critical_vulns),
                    'vulnerabilities': high_critical_vulns[:5]  # ìƒìœ„ 5ê°œë§Œ
                }
            })
            
            return not has_critical_vulns
            
        except Exception as e:
            self.results.append({
                'check': 'security_vulnerabilities',
                'status': 'error',
                'error': str(e)
            })
            return False
    
    def check_performance_benchmarks(self) -> bool:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²€ì‚¬"""
        try:
            # Lighthouse ê²°ê³¼ í™•ì¸
            with open('lighthouse-results.json') as f:
                lighthouse = json.load(f)
            
            performance_score = lighthouse.get('lhr', {}).get('categories', {}).get('performance', {}).get('score', 0) * 100
            accessibility_score = lighthouse.get('lhr', {}).get('categories', {}).get('accessibility', {}).get('score', 0) * 100
            
            performance_pass = performance_score >= self.config['performance']['lighthouse_threshold']
            accessibility_pass = accessibility_score >= self.config['accessibility']['lighthouse_threshold']
            
            self.results.append({
                'check': 'performance_benchmarks',
                'status': 'pass' if (performance_pass and accessibility_pass) else 'fail',
                'details': {
                    'performance_score': f"{performance_score}%",
                    'accessibility_score': f"{accessibility_score}%"
                }
            })
            
            return performance_pass and accessibility_pass
            
        except Exception as e:
            self.results.append({
                'check': 'performance_benchmarks',
                'status': 'error',
                'error': str(e)
            })
            return False
    
    def run_all_checks(self) -> bool:
        """ëª¨ë“  í’ˆì§ˆ ê²€ì‚¬ ì‹¤í–‰"""
        checks = [
            self.check_code_coverage(),
            self.check_security_vulnerabilities(),
            self.check_performance_benchmarks()
        ]
        
        all_passed = all(checks)
        
        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“Š Quality Gate Results:")
        print("=" * 50)
        
        for result in self.results:
            status_emoji = "âœ…" if result['status'] == 'pass' else "âŒ" if result['status'] == 'fail' else "âš ï¸"
            print(f"{status_emoji} {result['check']}: {result['status']}")
            
            if 'details' in result:
                for key, value in result['details'].items():
                    print(f"   {key}: {value}")
            
            if 'error' in result:
                print(f"   Error: {result['error']}")
        
        print("=" * 50)
        print(f"Overall Result: {'âœ… PASSED' if all_passed else 'âŒ FAILED'}")
        
        return all_passed

if __name__ == "__main__":
    checker = QualityGateChecker("quality-gate-config.json")
    success = checker.run_all_checks()
    sys.exit(0 if success else 1)
```

---

## ğŸš€ **CD (Continuous Deployment) ìƒì„¸ ì„¤ê³„**

### **ğŸ¯ GitOps ê¸°ë°˜ ë°°í¬ ì „ëµ**

#### **1. ArgoCD GitOps ì›Œí¬í”Œë¡œìš°**
```yaml
# argocd/applications/heal7-frontend-dev.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: heal7-frontend-dev
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: heal7
  source:
    repoURL: https://github.com/heal7/k8s-manifests
    path: environments/dev/frontend
    targetRevision: HEAD
    helm:
      valueFiles:
        - values.yaml
        - values-dev.yaml
      parameters:
        - name: image.tag
          value: $ARGOCD_ENV_IMAGE_TAG
  destination:
    server: https://kubernetes.default.svc
    namespace: heal7-dev
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    syncOptions:
      - CreateNamespace=true
      - PrunePropagationPolicy=foreground
      - PruneLast=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
  revisionHistoryLimit: 10
```

#### **2. í™˜ê²½ë³„ ë°°í¬ ì „ëµ**
```yaml
deployment_environments:
  development: # ê°œë°œ í™˜ê²½
    trigger: "ëª¨ë“  ì»¤ë°‹ (ìë™)"
    approval: "ë¶ˆí•„ìš”"
    deployment_strategy: "rolling_update"
    rollback_policy: "ìë™ (ì‹¤íŒ¨ ì‹œ)"
    resource_limits: "ìµœì†Œ ë¦¬ì†ŒìŠ¤"
    monitoring_level: "ê¸°ë³¸"
    
  staging: # ìŠ¤í…Œì´ì§• í™˜ê²½
    trigger: "develop ë¸Œëœì¹˜ (ìë™)"
    approval: "íŒ€ ë¦¬ë“œ ìŠ¹ì¸"
    deployment_strategy: "blue_green"
    rollback_policy: "ìˆ˜ë™ ìŠ¹ì¸"
    resource_limits: "í”„ë¡œë•ì…˜ì˜ 50%"
    monitoring_level: "ìƒì„¸"
    
  production: # í”„ë¡œë•ì…˜ í™˜ê²½
    trigger: "main ë¸Œëœì¹˜ (ìˆ˜ë™)"
    approval: "CTO + DevOps íŒ€ì¥"
    deployment_strategy: "canary"
    rollback_policy: "ì¦‰ì‹œ ê°€ëŠ¥"
    resource_limits: "ìµœëŒ€ ë¦¬ì†ŒìŠ¤"
    monitoring_level: "ì „ì²´"
```

#### **3. Canary ë°°í¬ êµ¬í˜„**
```yaml
# k8s/canary-deployment.yaml
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: heal7-backend
  namespace: heal7-prod
spec:
  # ëŒ€ìƒ ì„œë¹„ìŠ¤
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: heal7-backend
  
  # í”„ë¡œê·¸ë ˆì‹œë¸Œ ë°°í¬ ì„¤ì •
  progressDeadlineSeconds: 60
  
  # HPA ì°¸ì¡°
  autoscalerRef:
    apiVersion: autoscaling/v2
    kind: HorizontalPodAutoscaler
    name: heal7-backend
  
  # ì„œë¹„ìŠ¤ í¬íŠ¸
  service:
    port: 8080
    targetPort: 8080
    gateways:
      - heal7-gateway
    hosts:
      - api.heal7.com
  
  # ë¶„ì„ ì„¤ì •
  analysis:
    # ë¶„ì„ ê°„ê²©
    interval: 1m
    # ë¶„ì„ ìµœëŒ€ ì‹œê°„
    threshold: 5
    # ìµœëŒ€ ê°€ì¤‘ì¹˜
    maxWeight: 50
    # ê°€ì¤‘ì¹˜ ì¦ê°€ ë‹¨ê³„
    stepWeight: 10
    
    # ì„±ê³µ ë©”íŠ¸ë¦­
    metrics:
      - name: request-success-rate
        thresholdRange:
          min: 99
        interval: 1m
      - name: request-duration
        thresholdRange:
          max: 500
        interval: 30s
      - name: error-rate
        thresholdRange:
          max: 1
        interval: 30s
    
    # ì›¹í›… (Slack ì•Œë¦¼)
    webhooks:
      - name: send-to-slack
        type: pre-rollout
        url: http://slack-webhook.default/
        timeout: 15s
        metadata:
          type: "info"
          cmd: "Canary deployment started for heal7-backend"
      - name: send-to-slack-success
        type: post-rollout
        url: http://slack-webhook.default/
        timeout: 15s
        metadata:
          type: "success"
          cmd: "Canary deployment completed successfully"
      - name: send-to-slack-failure
        type: rollback
        url: http://slack-webhook.default/
        timeout: 15s
        metadata:
          type: "error"
          cmd: "Canary deployment failed and rolled back"

# Istio VirtualService for traffic splitting
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: heal7-backend
  namespace: heal7-prod
spec:
  hosts:
    - api.heal7.com
  gateways:
    - heal7-gateway
  http:
    - match:
        - headers:
            canary:
              exact: "true"
      route:
        - destination:
            host: heal7-backend-canary
    - route:
        - destination:
            host: heal7-backend-primary
          weight: 90
        - destination:
            host: heal7-backend-canary
          weight: 10
```

### **ğŸ”„ ìë™í™”ëœ ë¡¤ë°± ì‹œìŠ¤í…œ**

#### **1. ìŠ¤ë§ˆíŠ¸ ë¡¤ë°± ë¡œì§**
```python
# scripts/smart-rollback.py
#!/usr/bin/env python3
"""
ìŠ¤ë§ˆíŠ¸ ë¡¤ë°± ì‹œìŠ¤í…œ - ë©”íŠ¸ë¦­ ê¸°ë°˜ ìë™ ë¡¤ë°±
"""
import time
import requests
import json
from typing import Dict, List, Any
from dataclasses import dataclass
from prometheus_api_client import PrometheusConnect

@dataclass
class RollbackCriteria:
    metric_name: str
    threshold: float
    comparison: str  # 'gt', 'lt', 'eq'
    evaluation_period: int  # seconds
    
@dataclass
class DeploymentHealth:
    error_rate: float
    response_time_p95: float
    cpu_usage: float
    memory_usage: float
    success_rate: float

class SmartRollbackManager:
    def __init__(self, prometheus_url: str, app_name: str):
        self.prometheus = PrometheusConnect(url=prometheus_url)
        self.app_name = app_name
        self.rollback_criteria = [
            RollbackCriteria("error_rate", 5.0, "gt", 300),  # 5% ì´ìƒ ì—ëŸ¬ìœ¨
            RollbackCriteria("response_time_p95", 2000, "gt", 300),  # 2ì´ˆ ì´ìƒ ì‘ë‹µì‹œê°„
            RollbackCriteria("success_rate", 95.0, "lt", 180),  # 95% ë¯¸ë§Œ ì„±ê³µë¥ 
            RollbackCriteria("cpu_usage", 90.0, "gt", 600),  # 90% ì´ìƒ CPU ì‚¬ìš©ë¥ 
        ]
        
    def get_deployment_health(self) -> DeploymentHealth:
        """í˜„ì¬ ë°°í¬ ìƒíƒœ ê±´ê°•ë„ ì¡°íšŒ"""
        queries = {
            'error_rate': f'rate(http_requests_total{{app="{self.app_name}",status=~"5.."}}[5m]) / rate(http_requests_total{{app="{self.app_name}"}}[5m]) * 100',
            'response_time_p95': f'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{app="{self.app_name}"}}[5m])) * 1000',
            'cpu_usage': f'rate(container_cpu_usage_seconds_total{{app="{self.app_name}"}}[5m]) * 100',
            'memory_usage': f'container_memory_usage_bytes{{app="{self.app_name}"}} / container_spec_memory_limit_bytes{{app="{self.app_name}"}} * 100',
            'success_rate': f'rate(http_requests_total{{app="{self.app_name}",status!~"5.."}}[5m]) / rate(http_requests_total{{app="{self.app_name}"}}[5m]) * 100'
        }
        
        metrics = {}
        for name, query in queries.items():
            result = self.prometheus.custom_query(query)
            if result:
                metrics[name] = float(result[0]['value'][1])
            else:
                metrics[name] = 0.0
                
        return DeploymentHealth(
            error_rate=metrics['error_rate'],
            response_time_p95=metrics['response_time_p95'],
            cpu_usage=metrics['cpu_usage'],
            memory_usage=metrics['memory_usage'],
            success_rate=metrics['success_rate']
        )
    
    def evaluate_rollback_criteria(self, health: DeploymentHealth) -> List[str]:
        """ë¡¤ë°± ê¸°ì¤€ í‰ê°€"""
        violations = []
        
        health_dict = {
            'error_rate': health.error_rate,
            'response_time_p95': health.response_time_p95,
            'cpu_usage': health.cpu_usage,
            'memory_usage': health.memory_usage,
            'success_rate': health.success_rate
        }
        
        for criteria in self.rollback_criteria:
            metric_value = health_dict.get(criteria.metric_name, 0)
            
            if criteria.comparison == 'gt' and metric_value > criteria.threshold:
                violations.append(f"{criteria.metric_name}: {metric_value} > {criteria.threshold}")
            elif criteria.comparison == 'lt' and metric_value < criteria.threshold:
                violations.append(f"{criteria.metric_name}: {metric_value} < {criteria.threshold}")
                
        return violations
    
    def execute_rollback(self, reason: str) -> bool:
        """ë¡¤ë°± ì‹¤í–‰"""
        try:
            # ArgoCDë¥¼ í†µí•œ ë¡¤ë°±
            rollback_cmd = f"""
            kubectl rollout undo deployment/{self.app_name} -n heal7-prod
            kubectl rollout status deployment/{self.app_name} -n heal7-prod --timeout=300s
            """
            
            import subprocess
            result = subprocess.run(rollback_cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.send_alert(f"ğŸ”„ ìë™ ë¡¤ë°± ì„±ê³µ: {reason}", "success")
                return True
            else:
                self.send_alert(f"âŒ ìë™ ë¡¤ë°± ì‹¤íŒ¨: {result.stderr}", "error")
                return False
                
        except Exception as e:
            self.send_alert(f"âŒ ë¡¤ë°± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", "error")
            return False
    
    def send_alert(self, message: str, level: str):
        """ì•Œë¦¼ ë°œì†¡"""
        slack_webhook = "https://hooks.slack.com/services/xxx"  # ì‹¤ì œ ì›¹í›… URL
        
        color_map = {
            'success': 'good',
            'warning': 'warning', 
            'error': 'danger'
        }
        
        payload = {
            "attachments": [{
                "color": color_map.get(level, 'warning'),
                "title": f"HEAL7 {self.app_name} - ìë™ ë¡¤ë°± ì‹œìŠ¤í…œ",
                "text": message,
                "ts": int(time.time())
            }]
        }
        
        requests.post(slack_webhook, json=payload)
    
    def monitor_and_rollback(self, monitoring_duration: int = 900):  # 15ë¶„ ëª¨ë‹ˆí„°ë§
        """ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë¡¤ë°±"""
        print(f"ğŸ” ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ì‹œì‘: {self.app_name} ({monitoring_duration}ì´ˆ)")
        
        start_time = time.time()
        check_interval = 60  # 1ë¶„ë§ˆë‹¤ ì²´í¬
        
        while time.time() - start_time < monitoring_duration:
            health = self.get_deployment_health()
            violations = self.evaluate_rollback_criteria(health)
            
            print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ: ì—ëŸ¬ìœ¨ {health.error_rate:.2f}%, ì‘ë‹µì‹œê°„ {health.response_time_p95:.0f}ms, ì„±ê³µë¥  {health.success_rate:.2f}%")
            
            if violations:
                print(f"âš ï¸ ë¡¤ë°± ê¸°ì¤€ ìœ„ë°˜ ê°ì§€: {violations}")
                
                # 30ì´ˆ ëŒ€ê¸° í›„ ì¬í™•ì¸
                time.sleep(30)
                health_recheck = self.get_deployment_health()
                violations_recheck = self.evaluate_rollback_criteria(health_recheck)
                
                if violations_recheck:
                    print("ğŸš¨ ë¡¤ë°± ê¸°ì¤€ ìœ„ë°˜ ì¬í™•ì¸ë¨. ìë™ ë¡¤ë°± ì‹¤í–‰...")
                    reason = "; ".join(violations_recheck)
                    success = self.execute_rollback(reason)
                    
                    if success:
                        print("âœ… ìë™ ë¡¤ë°± ì™„ë£Œ")
                        return True
                    else:
                        print("âŒ ìë™ ë¡¤ë°± ì‹¤íŒ¨ - ìˆ˜ë™ ê°œì… í•„ìš”")
                        return False
                else:
                    print("âœ… ì¼ì‹œì  ì´ìƒìœ¼ë¡œ íŒë‹¨, ëª¨ë‹ˆí„°ë§ ê³„ì†")
            
            time.sleep(check_interval)
        
        print("âœ… ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - ë°°í¬ ì•ˆì •ì ")
        return True

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python smart-rollback.py <app-name>")
        sys.exit(1)
    
    app_name = sys.argv[1]
    prometheus_url = "http://prometheus.monitoring.svc.cluster.local:9090"
    
    manager = SmartRollbackManager(prometheus_url, app_name)
    success = manager.monitor_and_rollback()
    
    sys.exit(0 if success else 1)
```

---

## ğŸ—ï¸ **Infrastructure as Code (IaC)**

### **ğŸŒ Terraform ê¸°ë°˜ ì¸í”„ë¼ ê´€ë¦¬**

#### **1. ëª¨ë“ˆí™”ëœ Terraform êµ¬ì¡°**
```hcl
# terraform/environments/prod/main.tf
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.20"
    }
    helm = {
      source  = "hashicorp/helm"
      version = "~> 2.10"
    }
  }
  
  backend "s3" {
    bucket         = "heal7-terraform-state"
    key            = "environments/prod/terraform.tfstate"
    region         = "ap-northeast-2"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}

# ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©
module "vpc" {
  source = "../../modules/vpc"
  
  environment = "prod"
  vpc_cidr = "10.0.0.0/16"
  availability_zones = ["ap-northeast-2a", "ap-northeast-2b", "ap-northeast-2c"]
  
  public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
  private_subnet_cidrs = ["10.0.11.0/24", "10.0.12.0/24", "10.0.13.0/24"]
  database_subnet_cidrs = ["10.0.21.0/24", "10.0.22.0/24", "10.0.23.0/24"]
  
  tags = local.common_tags
}

module "eks" {
  source = "../../modules/eks"
  
  cluster_name = "heal7-prod"
  cluster_version = "1.28"
  
  vpc_id = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnet_ids
  
  node_groups = {
    general = {
      desired_size = 3
      max_size     = 10
      min_size     = 3
      
      instance_types = ["t3.large"]
      capacity_type  = "ON_DEMAND"
      
      k8s_labels = {
        Environment = "prod"
        NodePool    = "general"
      }
      
      taints = []
    }
    
    compute_intensive = {
      desired_size = 2
      max_size     = 5
      min_size     = 2
      
      instance_types = ["c5.xlarge"]
      capacity_type  = "ON_DEMAND"
      
      k8s_labels = {
        Environment = "prod"
        NodePool    = "compute"
      }
      
      taints = [
        {
          key    = "compute-intensive"
          value  = "true"
          effect = "NO_SCHEDULE"
        }
      ]
    }
  }
  
  tags = local.common_tags
}

module "rds" {
  source = "../../modules/rds"
  
  identifier = "heal7-prod"
  engine     = "postgres"
  engine_version = "16.1"
  
  instance_class = "db.r6g.xlarge"
  allocated_storage = 100
  max_allocated_storage = 1000
  
  vpc_id = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnet_ids
  
  backup_retention_period = 30
  backup_window = "03:00-04:00"
  maintenance_window = "sun:04:00-sun:05:00"
  
  monitoring_interval = 60
  performance_insights_enabled = true
  
  tags = local.common_tags
}

module "elasticache" {
  source = "../../modules/elasticache"
  
  cluster_id = "heal7-prod"
  node_type = "cache.r6g.large"
  num_cache_nodes = 3
  
  vpc_id = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnet_ids
  
  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  
  tags = local.common_tags
}

# ë¡œì»¬ ë³€ìˆ˜
locals {
  common_tags = {
    Environment = "prod"
    Project     = "heal7"
    ManagedBy   = "terraform"
    Owner       = "devops-team"
  }
}

# ì¶œë ¥ê°’
output "eks_cluster_endpoint" {
  value = module.eks.cluster_endpoint
}

output "rds_endpoint" {
  value = module.rds.endpoint
  sensitive = true
}

output "elasticache_endpoint" {
  value = module.elasticache.endpoint
  sensitive = true
}
```

#### **2. EKS ëª¨ë“ˆ ìƒì„¸ êµ¬í˜„**
```hcl
# terraform/modules/eks/main.tf
data "aws_caller_identity" "current" {}

# EKS í´ëŸ¬ìŠ¤í„°
resource "aws_eks_cluster" "main" {
  name     = var.cluster_name
  role_arn = aws_iam_role.cluster.arn
  version  = var.cluster_version

  vpc_config {
    subnet_ids              = var.subnet_ids
    endpoint_private_access = true
    endpoint_public_access  = true
    public_access_cidrs     = var.public_access_cidrs
    
    security_group_ids = [aws_security_group.cluster.id]
  }

  encryption_config {
    provider {
      key_arn = aws_kms_key.eks.arn
    }
    resources = ["secrets"]
  }

  enabled_cluster_log_types = [
    "api",
    "audit", 
    "authenticator",
    "controllerManager",
    "scheduler"
  ]

  depends_on = [
    aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy,
    aws_cloudwatch_log_group.cluster,
  ]

  tags = var.tags
}

# CloudWatch ë¡œê·¸ ê·¸ë£¹
resource "aws_cloudwatch_log_group" "cluster" {
  name              = "/aws/eks/${var.cluster_name}/cluster"
  retention_in_days = 30
  kms_key_id       = aws_kms_key.eks.arn

  tags = var.tags
}

# KMS í‚¤ (ì•”í˜¸í™”ìš©)
resource "aws_kms_key" "eks" {
  description             = "EKS Secret Encryption Key"
  deletion_window_in_days = 7
  enable_key_rotation     = true

  tags = merge(var.tags, {
    Name = "${var.cluster_name}-encryption-key"
  })
}

resource "aws_kms_alias" "eks" {
  name          = "alias/${var.cluster_name}-encryption-key"
  target_key_id = aws_kms_key.eks.key_id
}

# IAM ì—­í•  - í´ëŸ¬ìŠ¤í„°
resource "aws_iam_role" "cluster" {
  name = "${var.cluster_name}-cluster-role"

  assume_role_policy = jsonencode({
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"
      }
    }]
    Version = "2012-10-17"
  })

  tags = var.tags
}

resource "aws_iam_role_policy_attachment" "cluster_AmazonEKSClusterPolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.cluster.name
}

# ë³´ì•ˆ ê·¸ë£¹ - í´ëŸ¬ìŠ¤í„°
resource "aws_security_group" "cluster" {
  name_prefix = "${var.cluster_name}-cluster-"
  vpc_id      = var.vpc_id

  tags = merge(var.tags, {
    Name = "${var.cluster_name}-cluster-sg"
  })
}

resource "aws_security_group_rule" "cluster_egress" {
  description       = "Allow all egress"
  from_port         = 0
  protocol          = "-1"
  security_group_id = aws_security_group.cluster.id
  to_port           = 0
  type              = "egress"
  cidr_blocks       = ["0.0.0.0/0"]
}

# ë…¸ë“œ ê·¸ë£¹
resource "aws_eks_node_group" "main" {
  for_each = var.node_groups

  cluster_name    = aws_eks_cluster.main.name
  node_group_name = each.key
  node_role_arn   = aws_iam_role.node_group.arn
  subnet_ids      = var.subnet_ids

  capacity_type  = each.value.capacity_type
  instance_types = each.value.instance_types

  scaling_config {
    desired_size = each.value.desired_size
    max_size     = each.value.max_size
    min_size     = each.value.min_size
  }

  update_config {
    max_unavailable_percentage = 25
  }

  # Kubernetes ë¼ë²¨
  labels = each.value.k8s_labels

  # Taints
  dynamic "taint" {
    for_each = each.value.taints
    content {
      key    = taint.value.key
      value  = taint.value.value
      effect = taint.value.effect
    }
  }

  # Launch template
  launch_template {
    id      = aws_launch_template.node_group[each.key].id
    version = aws_launch_template.node_group[each.key].latest_version
  }

  depends_on = [
    aws_iam_role_policy_attachment.node_group_AmazonEKSWorkerNodePolicy,
    aws_iam_role_policy_attachment.node_group_AmazonEKS_CNI_Policy,
    aws_iam_role_policy_attachment.node_group_AmazonEC2ContainerRegistryReadOnly,
  ]

  tags = var.tags
}

# Launch Template (ì‚¬ìš©ì ë°ì´í„° ë° ì¶”ê°€ ì„¤ì •ìš©)
resource "aws_launch_template" "node_group" {
  for_each = var.node_groups

  name_prefix   = "${var.cluster_name}-${each.key}-"
  image_id      = data.aws_ssm_parameter.eks_ami_release_version.value
  instance_type = each.value.instance_types[0]

  vpc_security_group_ids = [aws_security_group.node_group.id]

  user_data = base64encode(templatefile("${path.module}/userdata.sh", {
    cluster_name = aws_eks_cluster.main.name
    endpoint     = aws_eks_cluster.main.endpoint
    ca_data      = aws_eks_cluster.main.certificate_authority[0].data
  }))

  block_device_mappings {
    device_name = "/dev/xvda"
    ebs {
      volume_size           = 100
      volume_type           = "gp3"
      encrypted             = true
      delete_on_termination = true
    }
  }

  metadata_options {
    http_endpoint               = "enabled"
    http_tokens                 = "required"
    http_put_response_hop_limit = 2
  }

  tag_specifications {
    resource_type = "instance"
    tags = merge(var.tags, {
      Name = "${var.cluster_name}-${each.key}-node"
    })
  }

  tags = var.tags
}

# IAM ì—­í•  - ë…¸ë“œ ê·¸ë£¹
resource "aws_iam_role" "node_group" {
  name = "${var.cluster_name}-node-group-role"

  assume_role_policy = jsonencode({
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
    }]
    Version = "2012-10-17"
  })

  tags = var.tags
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEKSWorkerNodePolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.node_group.name
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEKS_CNI_Policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role       = aws_iam_role.node_group.name
}

resource "aws_iam_role_policy_attachment" "node_group_AmazonEC2ContainerRegistryReadOnly" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.node_group.name
}

# AWS Load Balancer Controllerìš© IAM ì—­í• 
resource "aws_iam_role" "load_balancer_controller" {
  name = "${var.cluster_name}-aws-load-balancer-controller"

  assume_role_policy = jsonencode({
    Statement = [{
      Action = "sts:AssumeRoleWithWebIdentity"
      Effect = "Allow"
      Principal = {
        Federated = aws_iam_openid_connect_provider.cluster.arn
      }
      Condition = {
        StringEquals = {
          "${replace(aws_iam_openid_connect_provider.cluster.url, "https://", "")}:sub" = "system:serviceaccount:kube-system:aws-load-balancer-controller"
          "${replace(aws_iam_openid_connect_provider.cluster.url, "https://", "")}:aud" = "sts.amazonaws.com"
        }
      }
    }]
    Version = "2012-10-17"
  })

  tags = var.tags
}

resource "aws_iam_role_policy_attachment" "load_balancer_controller" {
  policy_arn = aws_iam_policy.load_balancer_controller.arn
  role       = aws_iam_role.load_balancer_controller.name
}

# OIDC Identity Provider
resource "aws_iam_openid_connect_provider" "cluster" {
  client_id_list  = ["sts.amazonaws.com"]
  thumbprint_list = [data.tls_certificate.cluster.certificates[0].sha1_fingerprint]
  url             = aws_eks_cluster.main.identity[0].oidc[0].issuer

  tags = var.tags
}

data "tls_certificate" "cluster" {
  url = aws_eks_cluster.main.identity[0].oidc[0].issuer
}

# ë³´ì•ˆ ê·¸ë£¹ - ë…¸ë“œ ê·¸ë£¹
resource "aws_security_group" "node_group" {
  name_prefix = "${var.cluster_name}-node-group-"
  vpc_id      = var.vpc_id

  tags = merge(var.tags, {
    Name = "${var.cluster_name}-node-group-sg"
  })
}

resource "aws_security_group_rule" "node_group_egress" {
  description       = "Allow all egress"
  from_port         = 0
  protocol          = "-1"
  security_group_id = aws_security_group.node_group.id
  to_port           = 0
  type              = "egress"
  cidr_blocks       = ["0.0.0.0/0"]
}

# AMI ë°ì´í„° ì†ŒìŠ¤
data "aws_ssm_parameter" "eks_ami_release_version" {
  name = "/aws/service/eks/optimized-ami/${aws_eks_cluster.main.version}/amazon-linux-2/recommended/image_id"
}
```

### **ğŸ“¦ Helm Charts ê´€ë¦¬**

#### **1. HEAL7 ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ Helm Chart**
```yaml
# k8s/helm/heal7/Chart.yaml
apiVersion: v2
name: heal7
description: HEAL7 ì˜´ë‹ˆë²„ìŠ¤ í”Œë«í¼ Helm Chart
type: application
version: 1.0.0
appVersion: "1.0.0"
dependencies:
  - name: postgresql
    version: 12.x.x
    repository: https://charts.bitnami.com/bitnami
    condition: postgresql.enabled
  - name: redis
    version: 17.x.x  
    repository: https://charts.bitnami.com/bitnami
    condition: redis.enabled
  - name: ingress-nginx
    version: 4.x.x
    repository: https://kubernetes.github.io/ingress-nginx
    condition: ingress.nginx.enabled

# k8s/helm/heal7/values.yaml
global:
  environment: production
  imageRegistry: 123456789012.dkr.ecr.ap-northeast-2.amazonaws.com
  imagePullSecrets:
    - name: ecr-secret

# í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹„ìŠ¤
frontend:
  enabled: true
  replicaCount: 3
  
  image:
    repository: heal7-frontend
    tag: latest
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 20
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  
  nodeSelector:
    NodePool: general
  
  tolerations: []
  
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - heal7-frontend
            topologyKey: kubernetes.io/hostname

# ë°±ì—”ë“œ ì„œë¹„ìŠ¤  
backend:
  enabled: true
  replicaCount: 5
  
  image:
    repository: heal7-backend
    tag: latest
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8000
  
  resources:
    limits:
      cpu: 1000m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 256Mi
  
  autoscaling:
    enabled: true
    minReplicas: 5
    maxReplicas: 50
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
    behavior:
      scaleUp:
        stabilizationWindowSeconds: 60
        policies:
          - type: Percent
            value: 100
            periodSeconds: 15
      scaleDown:
        stabilizationWindowSeconds: 300
        policies:
          - type: Percent
            value: 10
            periodSeconds: 60
  
  # í™˜ê²½ ë³€ìˆ˜
  env:
    DATABASE_URL:
      valueFrom:
        secretKeyRef:
          name: heal7-secrets
          key: database-url
    REDIS_URL:
      valueFrom:
        secretKeyRef:
          name: heal7-secrets
          key: redis-url
    SECRET_KEY:
      valueFrom:
        secretKeyRef:
          name: heal7-secrets
          key: secret-key
  
  # ì„¤ì • íŒŒì¼ ë§ˆìš´íŠ¸
  configMaps:
    - name: heal7-config
      mountPath: /app/config
  
  # Health checks
  livenessProbe:
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  
  readinessProbe:
    httpGet:
      path: /ready
      port: 8000
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  
  nodeSelector:
    NodePool: general
  
  tolerations: []

# ì‚¬ì£¼ ê³„ì‚° íŠ¹í™” ì„œë¹„ìŠ¤ (ê³ ì„±ëŠ¥)
saju-calculator:
  enabled: true
  replicaCount: 3
  
  image:
    repository: heal7-saju-calculator
    tag: latest
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8001
  
  resources:
    limits:
      cpu: 2000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 512Mi
  
  nodeSelector:
    NodePool: compute
  
  tolerations:
    - key: compute-intensive
      operator: Equal
      value: "true"
      effect: NoSchedule
  
  # ì „ìš© ë¦¬ì†ŒìŠ¤ ë³´ì¥
  priorityClassName: high-priority

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
postgresql:
  enabled: false  # ì™¸ë¶€ RDS ì‚¬ìš©
  
redis:
  enabled: false  # ì™¸ë¶€ ElastiCache ì‚¬ìš©

# Ingress ì„¤ì •
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
  
  hosts:
    - host: heal7.com
      paths:
        - path: /
          pathType: Prefix
          service: frontend
        - path: /api
          pathType: Prefix
          service: backend
        - path: /saju-api
          pathType: Prefix
          service: saju-calculator
  
  tls:
    - secretName: heal7-com-tls
      hosts:
        - heal7.com

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitoring:
  enabled: true
  
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics
    
  prometheusRule:
    enabled: true
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"

# ë³´ì•ˆ ì„¤ì •
security:
  networkPolicies:
    enabled: true
  
  podSecurityPolicy:
    enabled: true
  
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault
  
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
```

---

## ğŸ“Š **ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ê°€ëŠ¥ì„±**

### **ğŸ” Observability Stack**

#### **1. Prometheus + Grafana ëª¨ë‹ˆí„°ë§**
```yaml
# monitoring/prometheus/values.yaml
prometheus:
  prometheusSpec:
    retention: 30d
    retentionSize: 100GB
    
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    
    resources:
      limits:
        cpu: 2000m
        memory: 8Gi
      requests:
        cpu: 500m
        memory: 2Gi
    
    # HEAL7 íŠ¹í™” ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê·œì¹™
    additionalScrapeConfigs:
      - job_name: 'heal7-saju-metrics'
        kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
                - heal7-prod
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)

grafana:
  adminPassword: ${GRAFANA_ADMIN_PASSWORD}
  
  # HEAL7 ëŒ€ì‹œë³´ë“œ ìë™ í”„ë¡œë¹„ì €ë‹
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'heal7-dashboards'
          orgId: 1
          folder: 'HEAL7'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/heal7
  
  dashboards:
    heal7-dashboards:
      heal7-overview:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      heal7-saju-performance:
        file: dashboards/saju-performance.json
      heal7-user-analytics:
        file: dashboards/user-analytics.json
      heal7-infrastructure:
        file: dashboards/infrastructure.json

# monitoring/grafana/dashboards/saju-performance.json
{
  "dashboard": {
    "title": "HEAL7 ì‚¬ì£¼ ì‹œìŠ¤í…œ ì„±ëŠ¥",
    "panels": [
      {
        "title": "ì‚¬ì£¼ ê³„ì‚° ìš”ì²­ëŸ‰",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(saju_calculations_total[5m])",
            "legendFormat": "ì´ˆë‹¹ ì‚¬ì£¼ ê³„ì‚° ìˆ˜"
          }
        ],
        "yAxes": [
          {
            "label": "Requests/sec"
          }
        ]
      },
      {
        "title": "ì‚¬ì£¼ ê³„ì‚° ì‘ë‹µ ì‹œê°„",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(saju_calculation_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(saju_calculation_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(saju_calculation_duration_seconds_bucket[5m]))",
            "legendFormat": "99th percentile"
          }
        ],
        "yAxes": [
          {
            "label": "Seconds"
          }
        ]
      },
      {
        "title": "ì˜¤í–‰ ë¶„ì„ ì •í™•ë„",
        "type": "stat",
        "targets": [
          {
            "expr": "avg(saju_analysis_accuracy_score)",
            "legendFormat": "í‰ê·  ì •í™•ë„"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100
          }
        }
      }
    ]
  }
}
```

#### **2. ë¶„ì‚° ì¶”ì  (Jaeger)**
```yaml
# monitoring/jaeger/values.yaml
jaeger:
  strategy: production
  
  collector:
    resources:
      limits:
        cpu: 1000m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 256Mi
  
  query:
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
  
  storage:
    type: elasticsearch
    elasticsearch:
      host: elasticsearch.monitoring.svc.cluster.local
      port: 9200
      
  # HEAL7 ì• í”Œë¦¬ì¼€ì´ì…˜ ì¶”ì  ì„¤ì •
  agent:
    annotations:
      sidecar.jaegertracing.io/inject: "true"
    daemonset:
      useHostNetwork: true
      useHostPort: true
```

#### **3. ë¡œê·¸ ì§‘ê³„ (ELK Stack)**
```yaml
# monitoring/elastic/values.yaml
elasticsearch:
  replicas: 3
  minimumMasterNodes: 2
  
  esConfig:
    elasticsearch.yml: |
      cluster.name: "heal7-logs"
      network.host: 0.0.0.0
      discovery.seed_hosts: "elasticsearch-master-headless"
      cluster.initial_master_nodes: "elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2"
      
  resources:
    requests:
      cpu: "1000m"
      memory: "2Gi"
    limits:
      cpu: "2000m"
      memory: "4Gi"
  
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: "gp3"
    resources:
      requests:
        storage: 100Gi

logstash:
  logstashConfig:
    logstash.yml: |
      http.host: 0.0.0.0
      pipeline.ecs_compatibility: disabled
      
  logstashPipeline:
    heal7-logs.conf: |
      input {
        beats {
          port => 5044
        }
      }
      
      filter {
        # HEAL7 ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ íŒŒì‹±
        if [fields][app] == "heal7-backend" {
          grok {
            match => { 
              "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" 
            }
          }
          
          # ì‚¬ì£¼ ê³„ì‚° ê´€ë ¨ ë¡œê·¸ íŠ¹ë³„ ì²˜ë¦¬
          if [message] =~ /saju_calculation/ {
            grok {
              match => { 
                "message" => "saju_calculation user_id=%{UUID:user_id} duration=%{NUMBER:duration:float} accuracy=%{NUMBER:accuracy:float}" 
              }
            }
            
            mutate {
              add_tag => ["saju_performance"]
            }
          }
        }
        
        # ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹
        mutate {
          gsub => [
            "message", "\d{4}-\d{2}-\d{2}", "****-**-**",  # ìƒë…„ì›”ì¼ ë§ˆìŠ¤í‚¹
            "message", "\d{10,11}", "***-****-****"        # ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
          ]
        }
      }
      
      output {
        elasticsearch {
          hosts => ["elasticsearch-master:9200"]
          index => "heal7-logs-%{+YYYY.MM.dd}"
        }
      }

kibana:
  elasticsearchHosts: "http://elasticsearch-master:9200"
  
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
```

---

## ğŸ† **ê²°ë¡ **

### **âœ¨ DevOps CI/CD ì•„í‚¤í…ì²˜ í•µì‹¬ ê°€ì¹˜**

ì´ DevOps CI/CD íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ëŠ” **ë ˆê³ ë¸”ëŸ­ ëª¨ë“ˆí˜• ì„¤ê³„**ì™€ **ì™„ì „ ìë™í™”**ë¥¼ í†µí•´ ë‹¤ìŒì„ ë‹¬ì„±í•©ë‹ˆë‹¤:

#### **âš™ï¸ í•µì‹¬ DevOps ì„±ê³¼**
1. **ğŸš€ ë¹ ë¥¸ ë°°í¬ ì£¼ê¸°**: ì»¤ë°‹ë¶€í„° ë°°í¬ê¹Œì§€ 30ë¶„ ì´ë‚´, ì¼ 10íšŒ ì´ìƒ ë°°í¬
2. **ğŸ›¡ï¸ ë³´ì•ˆ ìš°ì„  ì„¤ê³„**: Shift-Left ë³´ì•ˆ, ëª¨ë“  ë‹¨ê³„ ë³´ì•ˆ ìŠ¤ìº” ë° ê²€ì¦
3. **ğŸ“Š ì™„ì „í•œ ê´€ì°°ê°€ëŠ¥ì„±**: ë©”íŠ¸ë¦­, ë¡œê·¸, ì¶”ì  í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
4. **ğŸ”„ ìë™í™”ëœ í’ˆì§ˆ ê´€ë¦¬**: ì½”ë“œë¶€í„° ë°°í¬ê¹Œì§€ ì „ ë‹¨ê³„ í’ˆì§ˆ ê²Œì´íŠ¸
5. **âš¡ ìŠ¤ë§ˆíŠ¸ ë¡¤ë°±**: AI ê¸°ë°˜ ìë™ ë¡¤ë°± ë° ì¥ì•  ëŒ€ì‘ ì‹œìŠ¤í…œ

#### **ğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**
```bash
# âš™ï¸ DevOps íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ í™•ì¸
cat CORE/architecture-diagrams/devops-architecture/DevOps-CICD-Pipeline-Architecture-v1.0*.md

# ğŸš€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì‹œì‘
# 1ë‹¨ê³„: GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ì •
# 2ë‹¨ê³„: Terraform ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹
# 3ë‹¨ê³„: Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„±
# 4ë‹¨ê³„: ArgoCD GitOps ì„¤ì •
# 5ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬
```

**ì´ì œ í˜„ëŒ€ì ì¸ DevOps ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ê°€ ì™„ì „íˆ êµ¬í˜„ëœ ìë™í™” íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!** âš™ï¸âœ¨

---

*ğŸ“… DevOps CI/CD ì•„í‚¤í…ì²˜ ì™„ì„±ì¼: 2025-08-18 19:15 KST*  
*âš™ï¸ íŒŒì´í”„ë¼ì¸: GitHub Actions + ArgoCD + Kubernetes*  
*ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ìƒì„¸ UI ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ê³„*