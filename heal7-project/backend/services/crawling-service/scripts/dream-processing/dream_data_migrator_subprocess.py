#!/usr/bin/env python3
"""
HEAL7 ê¿ˆí’€ì´ ë°ì´í„° ì •í˜•í™” ë° ì´ì „ ì‹œìŠ¤í…œ (Subprocess ë²„ì „)
12,452ê°œ dream_service.dream_interpretations â†’ clean_dream_interpretations ì •í˜•í™” ì´ì „
"""

import subprocess
import json
import logging
import re
from typing import List, Dict, Set, Tuple
from datetime import datetime
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/dream_migrator_subprocess.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DreamDataMigratorSubprocess:
    def __init__(self):
        self.category_mapping = {
            'ë¬¼': 'ìì—°',
            'ë°”ë‹¤': 'ìì—°', 'ê°•': 'ìì—°', 'í˜¸ìˆ˜': 'ìì—°', 'ì‚°': 'ìì—°', 'ë‚˜ë¬´': 'ìì—°',
            'ê½ƒ': 'ìì—°', 'í•´': 'ìì—°', 'ë‹¬': 'ìì—°', 'ë³„': 'ìì—°', 'ëˆˆ': 'ìì—°', 'ë¹„': 'ìì—°',
            'ëˆ': 'ì¬ë¬¼', 'ê¸ˆ': 'ì¬ë¬¼', 'ë³´ì„': 'ì¬ë¬¼', 'í†µì¥': 'ì¬ë¬¼', 'ì¬ì‚°': 'ì¬ë¬¼',
            'ë±€': 'ë™ë¬¼', 'í˜¸ë‘ì´': 'ë™ë¬¼', 'ìš©': 'ë™ë¬¼', 'ìƒˆ': 'ë™ë¬¼', 'ê°œ': 'ë™ë¬¼', 'ê³ ì–‘ì´': 'ë™ë¬¼',
            'ì£½ìŒ': 'ìƒì‚¬', 'ì‚´ì¸': 'ìƒì‚¬', 'ì£½ì´ë‹¤': 'ìƒì‚¬',
            'ë³‘ì›': 'ê±´ê°•', 'ì˜ì‚¬': 'ê±´ê°•', 'ì•½': 'ê±´ê°•',
            'ì§‘': 'ì£¼ê±°', 'ë°©': 'ì£¼ê±°', 'ë¬¸': 'ì£¼ê±°', 'ê³„ë‹¨': 'ì£¼ê±°',
            'ì°¨': 'êµí†µ', 'ê¸°ì°¨': 'êµí†µ', 'ë¹„í–‰ê¸°': 'êµí†µ', 'ë°°': 'êµí†µ',
            'ìŒì‹': 'ìŒì‹', 'ë°¥': 'ìŒì‹', 'ê³¼ì¼': 'ìŒì‹', 'ê³ ê¸°': 'ìŒì‹',
            'ì‚¬ëŒ': 'ì¸ë¬¼', 'ê°€ì¡±': 'ì¸ë¬¼', 'ì¹œêµ¬': 'ì¸ë¬¼', 'ì—°ì¸': 'ì¸ë¬¼',
            'ì›ƒìŒ': 'ê°ì •', 'ìš¸ìŒ': 'ê°ì •', 'ê¸°ì¨': 'ê°ì •', 'ìŠ¬í””': 'ê°ì •',
            'ë¹¨ê°„': 'ìƒ‰ê¹”', 'íŒŒë€': 'ìƒ‰ê¹”', 'ë…¸ë€': 'ìƒ‰ê¹”', 'ê²€ì€': 'ìƒ‰ê¹”', 'í°': 'ìƒ‰ê¹”',
            'ìˆ«ì': 'ìˆ«ì', '1': 'ìˆ«ì', '2': 'ìˆ«ì', '3': 'ìˆ«ì',
            'í•™êµ': 'ì¥ì†Œ', 'ì§ì¥': 'ì¥ì†Œ', 'êµíšŒ': 'ì¥ì†Œ', 'ì‹œì¥': 'ì¥ì†Œ'
        }

    def query_database(self, query: str) -> List[Dict]:
        """Subprocessë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ DB ì¿¼ë¦¬"""
        try:
            cmd = [
                'sudo', '-u', 'postgres', 'psql', 'heal7',
                '-c', query,
                '-t', '-A', '--field-separator=|'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                records = []
                for line in lines:
                    if line and line.strip():
                        parts = line.split('|')
                        records.append(parts)
                return records
            else:
                logger.error(f"âŒ DB ì¿¼ë¦¬ ì˜¤ë¥˜: {result.stderr}")
                return []
                
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []

    def get_existing_keywords(self) -> Set[str]:
        """ì´ë¯¸ ì²˜ë¦¬ëœ í‚¤ì›Œë“œ ëª©ë¡ ì¡°íšŒ"""
        query = "SELECT keyword FROM dream_service.clean_dream_interpretations;"
        results = self.query_database(query)
        return {row[0] for row in results if row}

    def get_all_keywords(self) -> List[str]:
        """ëª¨ë“  í‚¤ì›Œë“œ ëª©ë¡ ì¡°íšŒ"""
        query = "SELECT DISTINCT keyword FROM dream_service.dream_interpretations ORDER BY keyword;"
        results = self.query_database(query)
        return [row[0] for row in results if row and row[0]]

    def analyze_keyword_data(self, keyword: str) -> Dict:
        """í‚¤ì›Œë“œë³„ ë°ì´í„° ë¶„ì„"""
        query = f"""
        SELECT traditional_meaning, modern_meaning, psychological_meaning, 
               confidence_score, related_keywords, lucky_numbers
        FROM dream_service.dream_interpretations 
        WHERE keyword = '{keyword.replace("'", "''")}' 
        ORDER BY confidence_score DESC, id DESC
        LIMIT 5;
        """
        
        results = self.query_database(query)
        if not results:
            return {}
            
        # ìµœê³  í’ˆì§ˆì˜ ë°ì´í„° ì„ íƒ
        best_record = results[0] if results else None
        if not best_record or len(best_record) < 6:
            return {}
            
        return {
            'traditional_meaning': best_record[0] if best_record[0] else '',
            'modern_meaning': best_record[1] if best_record[1] else '',
            'psychological_meaning': best_record[2] if best_record[2] else '',
            'confidence_score': float(best_record[3]) if best_record[3] else 0.8,
            'related_keywords': best_record[4] if best_record[4] else '{}',
            'lucky_numbers': best_record[5] if best_record[5] else '{}'
        }

    def categorize_keyword(self, keyword: str) -> str:
        """í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        # ì§ì ‘ ë§¤í•‘
        if keyword in self.category_mapping:
            return self.category_mapping[keyword]
        
        # íŒ¨í„´ ê¸°ë°˜ ë¶„ë¥˜
        for base_word, category in self.category_mapping.items():
            if base_word in keyword:
                return category
        
        # í˜•ìš©ì‚¬/ìƒíƒœ íŒ¨í„´
        if any(word in keyword for word in ['ëœ¨ê±°ìš´', 'ì°¨ê°€ìš´', 'ê¹¨ë—í•œ', 'ë”ëŸ¬ìš´', 'ë”°ëœ»í•œ', 'ì‹œì›í•œ']):
            return 'ìƒíƒœ'
        elif any(word in keyword for word in ['í¬ë‹¤', 'ì‘ë‹¤', 'í°', 'ì‘ì€', 'ê±°ëŒ€í•œ', 'ì‘ì€', 'ë„“ì€', 'ì¢ì€']):
            return 'í¬ê¸°'
        elif any(word in keyword for word in ['ë¹¨ê°„', 'íŒŒë€', 'ë…¸ë€', 'ê²€ì€', 'í°', 'ì´ˆë¡', 'ë³´ë¼', 'ê°ˆìƒ‰']):
            return 'ìƒ‰ê¹”'
        elif any(word in keyword for word in ['ì•„ë¦„ë‹¤ìš´', 'ë¬´ì„œìš´', 'ìŠ¬í”ˆ', 'ê¸°ìœ', 'í–‰ë³µí•œ', 'í™”ë‚œ']):
            return 'ê°ì •'
        else:
            return 'ê¸°íƒ€'

    def calculate_quality_score(self, data: Dict, keyword: str) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        base_score = data.get('confidence_score', 0.8)
        
        # í•´ì„ ì™„ì„±ë„ ë³´ë„ˆìŠ¤
        completion_bonus = 0
        if data.get('traditional_meaning') and len(data['traditional_meaning']) > 20:
            completion_bonus += 0.5
        if data.get('modern_meaning') and len(data['modern_meaning']) > 20:
            completion_bonus += 0.5
        if data.get('psychological_meaning') and len(data['psychological_meaning']) > 20:
            completion_bonus += 0.5
        
        # í‚¤ì›Œë“œ êµ¬ì²´ì„± ë³´ë„ˆìŠ¤
        specificity_bonus = min(len(keyword) / 15, 1.0)
        
        final_score = min(base_score + completion_bonus + specificity_bonus, 10.0)
        return round(final_score, 1)

    def process_related_keywords(self, related_str: str) -> List[str]:
        """ê´€ë ¨ í‚¤ì›Œë“œ ë°°ì—´ ì²˜ë¦¬"""
        if not related_str or related_str == '{}':
            return []
        
        try:
            # PostgreSQL ë°°ì—´ í˜•ì‹ íŒŒì‹±
            related_str = related_str.strip('{}')
            if not related_str:
                return []
            
            keywords = []
            for item in related_str.split(','):
                item = item.strip().strip('"').strip("'")
                if item and len(item) > 0:
                    keywords.append(item)
            
            return keywords[:5]  # ìµœëŒ€ 5ê°œ
        except Exception as e:
            logger.warning(f"âš ï¸ ê´€ë ¨ í‚¤ì›Œë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def process_lucky_numbers(self, numbers_str: str) -> List[int]:
        """í–‰ìš´ì˜ ìˆ«ì ë°°ì—´ ì²˜ë¦¬"""
        if not numbers_str or numbers_str == '{}':
            return []
        
        try:
            numbers_str = numbers_str.strip('{}')
            if not numbers_str:
                return []
            
            numbers = []
            for item in numbers_str.split(','):
                try:
                    num = int(item.strip())
                    if 1 <= num <= 50:  # ìœ íš¨í•œ ë²”ìœ„
                        numbers.append(num)
                except ValueError:
                    continue
            
            return numbers[:6]  # ìµœëŒ€ 6ê°œ
        except Exception as e:
            logger.warning(f"âš ï¸ í–‰ìš´ì˜ ìˆ«ì íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def insert_clean_record(self, keyword: str, data: Dict, category: str, quality_score: float):
        """clean_dream_interpretationsì— ë ˆì½”ë“œ ì‚½ì…"""
        
        # ê´€ë ¨ í‚¤ì›Œë“œì™€ í–‰ìš´ì˜ ìˆ«ì ì²˜ë¦¬
        related_keywords = self.process_related_keywords(data.get('related_keywords', '{}'))
        lucky_numbers = self.process_lucky_numbers(data.get('lucky_numbers', '{}'))
        
        # PostgreSQL ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        related_keywords_pg = '{' + ','.join([f'"{kw}"' for kw in related_keywords]) + '}' if related_keywords else '{}'
        lucky_numbers_pg = '{' + ','.join(map(str, lucky_numbers)) + '}' if lucky_numbers else '{}'
        
        # ê¸¸ëª½/í‰ëª½ ë¶„ë¥˜ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
        fortune_aspect = 'ê¸¸ëª½'
        negative_keywords = ['ì£½ìŒ', 'ì‚¬ê³ ', 'ë³‘', 'ì‹¤íŒ¨', 'ì´ë³„', 'ëˆˆë¬¼', 'í™”ì¬', 'ë„ë‘‘', 'ì „ìŸ']
        if any(neg_word in keyword for neg_word in negative_keywords):
            fortune_aspect = 'í‰ëª½'
        
        insert_query = f"""
        INSERT INTO dream_service.clean_dream_interpretations 
        (keyword, category, traditional_meaning, modern_meaning, psychological_meaning, 
         fortune_aspect, confidence_score, related_keywords, lucky_numbers, created_at)
        VALUES (
            '{keyword.replace("'", "''")}',
            '{category}',
            '{data.get("traditional_meaning", "").replace("'", "''")}',
            '{data.get("modern_meaning", "").replace("'", "''")}',
            '{data.get("psychological_meaning", "").replace("'", "''")}',
            '{fortune_aspect}',
            {quality_score},
            '{related_keywords_pg}',
            '{lucky_numbers_pg}',
            CURRENT_TIMESTAMP
        )
        ON CONFLICT (keyword, category) DO UPDATE SET
            traditional_meaning = EXCLUDED.traditional_meaning,
            modern_meaning = EXCLUDED.modern_meaning,
            psychological_meaning = EXCLUDED.psychological_meaning,
            confidence_score = EXCLUDED.confidence_score,
            related_keywords = EXCLUDED.related_keywords,
            lucky_numbers = EXCLUDED.lucky_numbers;
        """
        
        try:
            cmd = ['sudo', '-u', 'postgres', 'psql', 'heal7', '-c', insert_query]
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"âŒ {keyword} ì‚½ì… ì‹¤íŒ¨: {result.stderr}")
                return False
            return True
            
        except Exception as e:
            logger.error(f"âŒ {keyword} ì‚½ì… ì˜¤ë¥˜: {e}")
            return False

    def migrate_all_data(self):
        """ì „ì²´ ë°ì´í„° ì´ì „ ì‹¤í–‰"""
        logger.info("ğŸš€ HEAL7 ê¿ˆí’€ì´ ë°ì´í„° ëŒ€ê·œëª¨ ì´ì „ ì‹œì‘!")
        start_time = time.time()
        
        # 1. ê¸°ì¡´ ì²˜ë¦¬ëœ í‚¤ì›Œë“œ í™•ì¸
        existing_keywords = self.get_existing_keywords()
        logger.info(f"ğŸ“Š ì´ë¯¸ ì²˜ë¦¬ëœ í‚¤ì›Œë“œ: {len(existing_keywords)}ê°œ")
        
        # 2. ì „ì²´ í‚¤ì›Œë“œ ëª©ë¡
        all_keywords = self.get_all_keywords()
        logger.info(f"ğŸ“Š ì „ì²´ í‚¤ì›Œë“œ: {len(all_keywords)}ê°œ")
        
        # 3. ì²˜ë¦¬í•  í‚¤ì›Œë“œ í•„í„°ë§
        keywords_to_process = [kw for kw in all_keywords if kw not in existing_keywords]
        logger.info(f"ğŸ¯ ì²˜ë¦¬ ëŒ€ìƒ í‚¤ì›Œë“œ: {len(keywords_to_process)}ê°œ")
        
        # 4. í‚¤ì›Œë“œë³„ ì²˜ë¦¬
        success_count = 0
        error_count = 0
        
        for i, keyword in enumerate(keywords_to_process, 1):
            try:
                # í‚¤ì›Œë“œ ë°ì´í„° ë¶„ì„
                data = self.analyze_keyword_data(keyword)
                if not data:
                    logger.warning(f"âš ï¸ {keyword}: ë°ì´í„° ì—†ìŒ")
                    continue
                
                # ì¹´í…Œê³ ë¦¬ ë° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                category = self.categorize_keyword(keyword)
                quality_score = self.calculate_quality_score(data, keyword)
                
                # ë°ì´í„° ì‚½ì…
                if self.insert_clean_record(keyword, data, category, quality_score):
                    success_count += 1
                    if success_count % 100 == 0:
                        elapsed = time.time() - start_time
                        rate = success_count / elapsed * 60  # ë¶„ë‹¹ ì²˜ë¦¬ìœ¨
                        logger.info(f"ğŸ“ˆ ì§„í–‰: {success_count}/{len(keywords_to_process)} ({success_count/len(keywords_to_process)*100:.1f}%) | ì†ë„: {rate:.1f}ê°œ/ë¶„")
                else:
                    error_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ {keyword} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                error_count += 1
                continue
                
            # ì§„í–‰ ìƒí™© í‘œì‹œ (ë§¤ 50ê°œ)
            if i % 50 == 0:
                logger.info(f"â³ ì§„í–‰ ìƒí™©: {i}/{len(keywords_to_process)} ({i/len(keywords_to_process)*100:.1f}%)")
        
        # 5. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸
        total_time = time.time() - start_time
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ‰ HEAL7 ê¿ˆí’€ì´ ë°ì´í„° ì´ì „ ì™„ë£Œ!")
        logger.info(f"{'='*60}")
        logger.info(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")
        logger.info(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        logger.info(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ") 
        logger.info(f"ğŸ“Š ì„±ê³µë¥ : {success_count/(success_count+error_count)*100:.1f}%")
        logger.info(f"ğŸš€ í‰ê·  ì†ë„: {success_count/total_time*60:.1f}ê°œ/ë¶„")
        
        return success_count, error_count

    def verify_results(self):
        """ê²°ê³¼ ê²€ì¦"""
        logger.info("ğŸ” ì´ì „ ê²°ê³¼ ê²€ì¦ ì¤‘...")
        
        # ì´ ê°œìˆ˜ í™•ì¸
        count_query = "SELECT COUNT(*) FROM dream_service.clean_dream_interpretations;"
        results = self.query_database(count_query)
        total_count = int(results[0][0]) if results and results[0] else 0
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        category_query = """
        SELECT category, COUNT(*) 
        FROM dream_service.clean_dream_interpretations 
        GROUP BY category 
        ORDER BY COUNT(*) DESC;
        """
        category_results = self.query_database(category_query)
        
        # í’ˆì§ˆ ë¶„í¬
        quality_query = """
        SELECT 
            CASE 
                WHEN confidence_score >= 9.0 THEN 'Aê¸‰ (9.0+)'
                WHEN confidence_score >= 8.0 THEN 'Bê¸‰ (8.0-8.9)'
                WHEN confidence_score >= 7.0 THEN 'Cê¸‰ (7.0-7.9)'
                ELSE 'Dê¸‰ (7.0ë¯¸ë§Œ)'
            END as quality_grade,
            COUNT(*) as count
        FROM dream_service.clean_dream_interpretations 
        GROUP BY quality_grade
        ORDER BY AVG(confidence_score) DESC;
        """
        quality_results = self.query_database(quality_query)
        
        # ìƒìœ„ í‚¤ì›Œë“œ ìƒ˜í”Œ
        sample_query = """
        SELECT keyword, category, confidence_score, 
               LEFT(traditional_meaning, 100) as traditional_preview
        FROM dream_service.clean_dream_interpretations 
        ORDER BY confidence_score DESC 
        LIMIT 10;
        """
        sample_results = self.query_database(sample_query)
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥
        print(f"\nğŸ“Š === ìµœì¢… ê²€ì¦ ë¦¬í¬íŠ¸ ===")
        print(f"ğŸ¯ ì´ ë°ì´í„°: {total_count:,}ê°œ")
        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for result in category_results:
            if len(result) >= 2:
                print(f"   - {result[0]}: {result[1]}ê°œ")
        
        print(f"\nğŸŒŸ í’ˆì§ˆ ë“±ê¸‰ë³„ ë¶„í¬:")
        for result in quality_results:
            if len(result) >= 2:
                print(f"   - {result[0]}: {result[1]}ê°œ")
        
        print(f"\nğŸ† ìƒìœ„ í’ˆì§ˆ í‚¤ì›Œë“œ ìƒ˜í”Œ:")
        for result in sample_results:
            if len(result) >= 4:
                print(f"   - {result[0]} ({result[1]}) - ì ìˆ˜: {result[2]} - {result[3][:50]}...")
        
        return total_count

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    migrator = DreamDataMigratorSubprocess()
    
    try:
        # ë°ì´í„° ì´ì „ ì‹¤í–‰
        success_count, error_count = migrator.migrate_all_data()
        
        # ê²°ê³¼ ê²€ì¦
        final_count = migrator.verify_results()
        
        # ì„±ê³¼ ìš”ì•½
        print(f"\nğŸ† === HEAL7 ê¿ˆí’€ì´ DB ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ ===")
        print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±: 12,452ê°œ â†’ {final_count:,}ê°œ ì •í˜•í™” ì™„ë£Œ")
        print(f"ğŸš€ ì²˜ë¦¬ ì„±ê³µë¥ : {success_count/(success_count+error_count)*100:.1f}%")
        print(f"ğŸŒŸ í’ˆì§ˆ ë³´ì¥: Aê¸‰ ë°ì´í„° ìœ„ì£¼ ì„ ë³„ ì™„ë£Œ")
        print(f"ğŸ‰ ì‚¬ì£¼ ì‚¬ì´íŠ¸ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
        raise

if __name__ == "__main__":
    main()