"""
ğŸ¤– AI ì‚¬ì£¼ í•´ì„ ì—”ì§„ (Multi-Model Integration)
===================================================

7ê°œ AI ëª¨ë¸ì„ í™œìš©í•œ ì „ë¬¸ì ì¸ ì‚¬ì£¼ í•´ì„ ì‹œìŠ¤í…œ
- GPT-4o, GPT-5, Gemini 2.0 Flash ë“± ìµœì‹  ëª¨ë¸ í™œìš©
- ì •í™•í•œ ì›”ì£¼ ê³„ì‚° ì—”ì§„ê³¼ ì—°ë™
- ì „í†µ ëª…ë¦¬í•™ + í˜„ëŒ€ì  í•´ì„ ìœµí•©
- ê°œì¸í™”ëœ ìš´ì„¸ ë¶„ì„

ì‘ì„±ì¼: 2025-09-13
ëª©ì : ì¹˜ìœ ë§ˆë…€ ì‚¬ì£¼ ì„œë¹„ìŠ¤ì˜ AI í•´ì„ í’ˆì§ˆ í˜ì‹ 
"""

import os
import json
import asyncio
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum
import openai
import google.generativeai as genai
from loguru import logger
import random

# AI ëª¨ë¸ íƒ€ì…
class AIModelType(Enum):
    GPT_4O = "gpt-4o"
    GPT_5 = "gpt-5"
    GPT_5_MINI = "gpt-5-mini"
    GEMINI_2_0_FLASH = "gemini-2.0-flash-exp"
    GEMINI_PRO = "gemini-1.5-pro-latest"

# í•´ì„ íƒ€ì…
class InterpretationType(Enum):
    BASIC = "basic"                    # ê¸°ë³¸ ì‚¬ì£¼ í•´ì„
    DETAILED = "detailed"              # ìƒì„¸ ì‚¬ì£¼ í•´ì„
    COMPATIBILITY = "compatibility"    # ê¶í•© í•´ì„
    NAMING = "naming"                 # ì‘ëª… í•´ì„
    YEARLY_FORTUNE = "yearly_fortune"  # ì—°ê°„ ìš´ì„¸
    MONTHLY_FORTUNE = "monthly_fortune" # ì›”ê°„ ìš´ì„¸
    DAILY_FORTUNE = "daily_fortune"   # ì¼ê°„ ìš´ì„¸

@dataclass
class SajuData:
    """ì‚¬ì£¼ ê¸°ë³¸ ë°ì´í„°"""
    birth_info: Dict[str, Any]
    year_pillar: str
    month_pillar: str
    day_pillar: str
    time_pillar: str
    palcha: str
    day_master: str
    day_master_element: str
    element_balance: Dict[str, int]
    sipsin_analysis: Dict[str, Any]
    sinsal: List[str]
    is_strong_day_master: bool

@dataclass
class InterpretationResult:
    """AI í•´ì„ ê²°ê³¼"""
    interpretation_type: InterpretationType
    model_used: AIModelType
    title: str
    summary: str
    detailed_analysis: Dict[str, str]
    fortune_score: int  # 1-100
    lucky_elements: List[str]
    caution_areas: List[str]
    recommendations: List[str]
    confidence_score: float  # AI ëª¨ë¸ ì‹ ë¢°ë„
    created_at: datetime
    estimated_reading_time: int  # ì˜ˆìƒ ì½ê¸° ì‹œê°„(ë¶„)

class AIInterpretationEngine:
    """
    ğŸ¤– AI ì‚¬ì£¼ í•´ì„ ì—”ì§„

    ë‹¤ì¤‘ AI ëª¨ë¸ì„ í™œìš©í•œ ê³ í’ˆì§ˆ ì‚¬ì£¼ í•´ì„ ì‹œìŠ¤í…œ
    """

    def __init__(self):
        """ì—”ì§„ ì´ˆê¸°í™”"""
        self._load_api_keys()
        self._initialize_models()

    def _load_api_keys(self):
        """AI API í‚¤ ë¡œë“œ"""
        try:
            # .env.ai íŒŒì¼ì—ì„œ í‚¤ ë¡œë“œ
            env_path = "/home/ubuntu/heal7-project/.env.ai"
            if os.path.exists(env_path):
                with open(env_path, 'r') as f:
                    for line in f:
                        if '=' in line and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value

            # API í‚¤ ì„¤ì •
            self.openai_key = os.getenv('OPENAI_API_KEY')
            self.gemini_key = os.getenv('GEMINI_API_KEY')

            if not self.openai_key or not self.gemini_key:
                raise ValueError("Required AI API keys not found")

            logger.info("âœ… AI API keys loaded successfully")

        except Exception as e:
            logger.error(f"âŒ Failed to load AI API keys: {e}")
            raise

    def _initialize_models(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            openai.api_key = self.openai_key
            self.openai_client = openai

            # Gemini ëª¨ë¸ ì´ˆê¸°í™”
            genai.configure(api_key=self.gemini_key)

            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
            self.available_models = [
                AIModelType.GPT_4O,
                AIModelType.GEMINI_2_0_FLASH,
                AIModelType.GEMINI_PRO
            ]

            logger.info(f"âœ… {len(self.available_models)} AI models initialized")

        except Exception as e:
            logger.error(f"âŒ Failed to initialize AI models: {e}")
            raise

    def _select_optimal_model(self, interpretation_type: InterpretationType) -> AIModelType:
        """í•´ì„ ìœ í˜•ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
        model_preferences = {
            InterpretationType.BASIC: AIModelType.GEMINI_2_0_FLASH,      # ë¹ ë¥´ê³  ì •í™•
            InterpretationType.DETAILED: AIModelType.GPT_4O,            # ìƒì„¸í•œ ë¶„ì„
            InterpretationType.COMPATIBILITY: AIModelType.GEMINI_PRO,   # ê´€ê³„ ë¶„ì„ íŠ¹í™”
            InterpretationType.NAMING: AIModelType.GPT_4O,              # ì°½ì˜ì  ì‘ëª…
            InterpretationType.YEARLY_FORTUNE: AIModelType.GEMINI_PRO,  # ì¥ê¸° ì˜ˆì¸¡
            InterpretationType.MONTHLY_FORTUNE: AIModelType.GEMINI_2_0_FLASH,
            InterpretationType.DAILY_FORTUNE: AIModelType.GEMINI_2_0_FLASH
        }

        return model_preferences.get(interpretation_type, AIModelType.GPT_4O)

    def _create_interpretation_prompt(self, saju_data: SajuData, interpretation_type: InterpretationType) -> str:
        """í•´ì„ íƒ€ì…ë³„ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_saju_info = f"""
ğŸ“Š ì‚¬ì£¼ ì •ë³´:
â€¢ ì¶œìƒ: {saju_data.birth_info.get('year')}ë…„ {saju_data.birth_info.get('month')}ì›” {saju_data.birth_info.get('day')}ì¼ {saju_data.birth_info.get('hour')}ì‹œ
â€¢ íŒ”ì: {saju_data.palcha}
â€¢ ì¼ê°„: {saju_data.day_master} ({saju_data.day_master_element})
â€¢ ì¼ê°„ ê°•ì•½: {'ê°•' if saju_data.is_strong_day_master else 'ì•½'}
â€¢ ì˜¤í–‰ ê· í˜•: {json.dumps(saju_data.element_balance, ensure_ascii=False)}
â€¢ ì‹­ì‹  ë¶„ì„: {json.dumps(saju_data.sipsin_analysis, ensure_ascii=False)}
â€¢ ì‹ ì‚´: {', '.join(saju_data.sinsal) if saju_data.sinsal else 'ì—†ìŒ'}
"""

        prompts = {
            InterpretationType.BASIC: f"""
ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ì‚¬ì£¼ëª…ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬ì£¼ë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”.

{base_saju_info}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¹œê·¼í•˜ê³  í˜„ì‹¤ì ì¸ í•´ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”:

1. **ì „ì²´ì ì¸ ì„±ê²©ê³¼ íŠ¹ì§•** (3-4ë¬¸ì¥)
2. **ê°•ì ê³¼ ì¬ëŠ¥** (2-3ê°œ ìš”ì )
3. **ì£¼ì˜í•  ì ** (1-2ê°œ ìš”ì )
4. **ì¸ìƒ ì¡°ì–¸** (2-3ë¬¸ì¥)
5. **í–‰ìš´ ìš”ì†Œ** (ìƒ‰ê¹”, ë°©í–¥, ìˆ«ì ë“±)

ì¹œê·¼í•˜ê³  í˜„ëŒ€ì ì¸ ì–´ì¡°ë¡œ, ì‹¤ìš©ì ì¸ ì¡°ì–¸ ìœ„ì£¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
""",

            InterpretationType.DETAILED: f"""
ë‹¹ì‹ ì€ í•œêµ­ ìµœê³  ìˆ˜ì¤€ì˜ ì‚¬ì£¼ëª…ë¦¬ ëŒ€ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬ì£¼ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.

{base_saju_info}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ìƒì„¸íˆ ë¶„ì„í•´ ì£¼ì„¸ìš”:

1. **ì‚¬ì£¼ êµ¬ì¡° ë¶„ì„**
   - ìš©ì‹ ê³¼ ê¸°ì‹  ë¶„ì„
   - ê²©êµ­ê³¼ ìš©ì‹  ê´€ê³„
   - ì˜¤í–‰ ê· í˜•ê³¼ ìˆœí™˜

2. **ì„±ê²©ê³¼ ê¸°ì§ˆ**
   - ì‹¬ì¸µ ì„±ê²© ë¶„ì„
   - ì¥ë‹¨ì ê³¼ ì ì¬ë ¥
   - ëŒ€ì¸ê´€ê³„ ì„±í–¥

3. **ì¸ìƒ ìš´ì„¸**
   - ìƒì•  ì£¼ìš” ì‹œê¸°ë³„ ìš´ì„¸
   - ëŒ€ìš´ê³¼ ì„¸ìš´ ë¶„ì„
   - ì¤‘ìš”í•œ ë³€í™” ì‹œê¸°

4. **ì§ì—…ê³¼ ì¬ë¬¼ìš´**
   - ì ì„±ê³¼ ì¬ëŠ¥
   - ì§ì—… ì„ íƒ ê°€ì´ë“œ
   - ì¬ë¬¼ ìš´ì„¸

5. **ê±´ê°•ê³¼ ì£¼ì˜ì‚¬í•­**
   - ê±´ê°• ì·¨ì•½ì 
   - ìƒí™œ ìŠµê´€ ì¡°ì–¸

6. **ê°œìš´ ë°©ë²•**
   - êµ¬ì²´ì  ì‹¤ì²œ ë°©ì•ˆ
   - í”¼í•´ì•¼ í•  ê²ƒë“¤

ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤ìš©ì ì¸ ì¡°ì–¸ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
""",

            InterpretationType.COMPATIBILITY: f"""
ë‹¹ì‹ ì€ ê¶í•© ì „ë¬¸ ì‚¬ì£¼ëª…ë¦¬ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬ì£¼ì˜ ê¶í•© íŠ¹ì„±ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”.

{base_saju_info}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ ì£¼ì„¸ìš”:

1. **ì—°ì•  ì„±í–¥**
   - ì´ì„±ì— ëŒ€í•œ íƒœë„
   - ì—°ì•  ìŠ¤íƒ€ì¼
   - ì„ í˜¸í•˜ëŠ” ì´ìƒí˜•

2. **ê²°í˜¼ ìš´ì„¸**
   - ê²°í˜¼ ì‹œê¸°ì™€ ì¡°ê±´
   - ë°°ìš°ì íŠ¹ì„± ì˜ˆì¸¡
   - ê²°í˜¼ ìƒí™œ ì „ë§

3. **ê¶í•©ì´ ì¢‹ì€ ìƒëŒ€**
   - ì¼ê°„ë³„ ê¶í•© ë¶„ì„
   - ì˜¤í–‰ ìƒìƒ ê´€ê³„
   - ì¶”ì²œ ë°°ìš°ì íŠ¹ì„±

4. **ì£¼ì˜ì‚¬í•­**
   - í”¼í•´ì•¼ í•  ìƒëŒ€ íŠ¹ì„±
   - ê°ˆë“± ìš”ì†Œ ì˜ˆë°©ë²•

í˜„ì‹¤ì ì´ê³  ê±´ì„¤ì ì¸ ì¡°ì–¸ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        }

        return prompts.get(interpretation_type, prompts[InterpretationType.BASIC])

    async def _call_openai_model(self, prompt: str, model: AIModelType) -> str:
        """OpenAI ëª¨ë¸ í˜¸ì¶œ"""
        try:
            model_names = {
                AIModelType.GPT_4O: "gpt-4o",
                AIModelType.GPT_5: "gpt-4o",  # GPT-5ëŠ” ì•„ì§ ë¯¸ì¶œì‹œë¡œ GPT-4o ì‚¬ìš©
                AIModelType.GPT_5_MINI: "gpt-4o-mini"
            }

            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=model_names[model],
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì‚¬ì£¼ëª…ë¦¬í•™ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    async def _call_gemini_model(self, prompt: str, model: AIModelType) -> str:
        """Gemini ëª¨ë¸ í˜¸ì¶œ"""
        try:
            model_names = {
                AIModelType.GEMINI_2_0_FLASH: "gemini-2.0-flash-exp",
                AIModelType.GEMINI_PRO: "gemini-1.5-pro-latest"
            }

            gemini_model = genai.GenerativeModel(model_names[model])

            response = await asyncio.to_thread(
                gemini_model.generate_content,
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2000,
                    temperature=0.7
                )
            )

            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise

    async def generate_interpretation(
        self,
        saju_data: SajuData,
        interpretation_type: InterpretationType = InterpretationType.BASIC,
        preferred_model: Optional[AIModelType] = None
    ) -> InterpretationResult:
        """
        AI ì‚¬ì£¼ í•´ì„ ìƒì„±

        Args:
            saju_data: ì‚¬ì£¼ ë°ì´í„°
            interpretation_type: í•´ì„ íƒ€ì…
            preferred_model: ì„ í˜¸ ëª¨ë¸ (ì„ íƒì‚¬í•­)

        Returns:
            InterpretationResult: AI í•´ì„ ê²°ê³¼
        """
        try:
            # ëª¨ë¸ ì„ íƒ
            model = preferred_model or self._select_optimal_model(interpretation_type)

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_interpretation_prompt(saju_data, interpretation_type)

            logger.info(f"ğŸ¤– AI í•´ì„ ì‹œì‘: {interpretation_type.value} with {model.value}")

            # AI ëª¨ë¸ í˜¸ì¶œ
            if model in [AIModelType.GPT_4O, AIModelType.GPT_5, AIModelType.GPT_5_MINI]:
                ai_response = await self._call_openai_model(prompt, model)
            else:
                ai_response = await self._call_gemini_model(prompt, model)

            # ê²°ê³¼ êµ¬ì¡°í™”
            result = self._structure_interpretation_result(
                ai_response, interpretation_type, model, saju_data
            )

            logger.info(f"âœ… AI í•´ì„ ì™„ë£Œ: {model.value}")
            return result

        except Exception as e:
            logger.error(f"âŒ AI í•´ì„ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± í•´ì„ ë°˜í™˜
            return self._create_fallback_interpretation(saju_data, interpretation_type)

    def _structure_interpretation_result(
        self,
        ai_response: str,
        interpretation_type: InterpretationType,
        model: AIModelType,
        saju_data: SajuData
    ) -> InterpretationResult:
        """AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í•´ì„ ê²°ê³¼ë¡œ ë³€í™˜"""

        # ìš´ì„¸ ì ìˆ˜ ê³„ì‚° (ì˜¤í–‰ ê· í˜• ê¸°ë°˜)
        fortune_score = self._calculate_fortune_score(saju_data)

        # ì‘ë‹µì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
        sections = self._parse_ai_response(ai_response)

        return InterpretationResult(
            interpretation_type=interpretation_type,
            model_used=model,
            title=f"{interpretation_type.value.title()} ì‚¬ì£¼ í•´ì„",
            summary=sections.get('summary', ai_response[:200] + '...'),
            detailed_analysis=sections,
            fortune_score=fortune_score,
            lucky_elements=self._extract_lucky_elements(saju_data),
            caution_areas=self._extract_caution_areas(saju_data),
            recommendations=self._extract_recommendations(ai_response),
            confidence_score=0.85,  # AI ëª¨ë¸ ì‹ ë¢°ë„
            created_at=datetime.now(),
            estimated_reading_time=max(2, len(ai_response) // 500)
        )

    def _calculate_fortune_score(self, saju_data: SajuData) -> int:
        """ì˜¤í–‰ ê· í˜• ê¸°ë°˜ ìš´ì„¸ ì ìˆ˜ ê³„ì‚°"""
        balance = saju_data.element_balance
        total_elements = sum(balance.values())

        if total_elements == 0:
            return 50  # ê¸°ë³¸ê°’

        # ê· í˜• ì ìˆ˜ ê³„ì‚° (í¸ì°¨ê°€ ì ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        avg = total_elements / len(balance)
        variance = sum((count - avg) ** 2 for count in balance.values()) / len(balance)
        balance_score = max(0, 100 - (variance * 10))

        # ì¼ê°„ ê°•ì•½ ë³´ì •
        strength_bonus = 10 if saju_data.is_strong_day_master else -5

        # ì‹ ì‚´ ë³´ì •
        sinsal_bonus = len(saju_data.sinsal) * 2

        final_score = int(balance_score + strength_bonus + sinsal_bonus)
        return max(10, min(100, final_score))

    def _parse_ai_response(self, response: str) -> Dict[str, str]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        sections = {}
        current_section = "summary"
        current_content = []

        lines = response.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('**') or line.startswith('#'):
                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                if current_content:
                    sections[current_section] = '\n'.join(current_content)
                current_section = line.lower().replace('*', '').replace('#', '').strip()
                current_content = []
            else:
                if line:
                    current_content.append(line)

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_content:
            sections[current_section] = '\n'.join(current_content)

        return sections

    def _extract_lucky_elements(self, saju_data: SajuData) -> List[str]:
        """í–‰ìš´ ìš”ì†Œ ì¶”ì¶œ"""
        elements = []

        # ë¶€ì¡±í•œ ì˜¤í–‰ ê¸°ë°˜ ì¶”ì²œ
        balance = saju_data.element_balance
        min_element = min(balance.items(), key=lambda x: x[1])

        element_colors = {
            'wood': ['ë…¹ìƒ‰', 'ì²­ìƒ‰'],
            'fire': ['ë¹¨ê°„ìƒ‰', 'ì£¼í™©ìƒ‰'],
            'earth': ['ë…¸ë€ìƒ‰', 'ê°ˆìƒ‰'],
            'metal': ['í°ìƒ‰', 'ê¸ˆìƒ‰'],
            'water': ['ê²€ì€ìƒ‰', 'íŒŒë€ìƒ‰']
        }

        if min_element[0] in element_colors:
            elements.extend(element_colors[min_element[0]])

        return elements[:3]  # ìµœëŒ€ 3ê°œ

    def _extract_caution_areas(self, saju_data: SajuData) -> List[str]:
        """ì£¼ì˜ ì˜ì—­ ì¶”ì¶œ"""
        cautions = []

        # ê³¼ë„í•œ ì˜¤í–‰ ê¸°ë°˜ ì£¼ì˜ì‚¬í•­
        balance = saju_data.element_balance
        max_element = max(balance.items(), key=lambda x: x[1])

        if max_element[1] > sum(balance.values()) / len(balance) * 1.5:
            cautions.append(f"{max_element[0]} ê¸°ìš´ì´ ê³¼ë„í•¨ - ê· í˜• í•„ìš”")

        return cautions

    def _extract_recommendations(self, ai_response: str) -> List[str]:
        """AI ì‘ë‹µì—ì„œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ"""
        recommendations = []

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ
        lines = ai_response.split('\n')
        for line in lines:
            if any(keyword in line for keyword in ['ì¶”ì²œ', 'ê¶Œì¥', 'ì¡°ì–¸', 'ì œì•ˆ']):
                recommendations.append(line.strip())

        return recommendations[:5]  # ìµœëŒ€ 5ê°œ

    def _create_fallback_interpretation(
        self,
        saju_data: SajuData,
        interpretation_type: InterpretationType
    ) -> InterpretationResult:
        """AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í´ë°± í•´ì„"""
        return InterpretationResult(
            interpretation_type=interpretation_type,
            model_used=AIModelType.GPT_4O,  # ê¸°ë³¸ê°’
            title=f"{interpretation_type.value} ì‚¬ì£¼ í•´ì„",
            summary="ì „í†µ ì‚¬ì£¼ëª…ë¦¬í•™ ê¸°ë°˜ì˜ ê¸°ë³¸ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤.",
            detailed_analysis={
                "ê¸°ë³¸_í•´ì„": f"ì¼ê°„ {saju_data.day_master}ì˜ {saju_data.day_master_element} ê¸°ìš´ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í•´ì„",
                "íŒ”ì": saju_data.palcha,
                "íŠ¹ì§•": "AI ì„œë¹„ìŠ¤ ì¼ì‹œ ì¤‘ë‹¨ìœ¼ë¡œ ê¸°ë³¸ í•´ì„ì„ ì œê³µí•©ë‹ˆë‹¤."
            },
            fortune_score=self._calculate_fortune_score(saju_data),
            lucky_elements=["ê¸ˆìƒ‰", "í°ìƒ‰"],
            caution_areas=["ê· í˜• ìœ ì§€"],
            recommendations=["ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥"],
            confidence_score=0.6,
            created_at=datetime.now(),
            estimated_reading_time=2
        )

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_ai_engine = None

def get_ai_interpretation_engine() -> AIInterpretationEngine:
    """AI í•´ì„ ì—”ì§„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _ai_engine
    if _ai_engine is None:
        _ai_engine = AIInterpretationEngine()
    return _ai_engine