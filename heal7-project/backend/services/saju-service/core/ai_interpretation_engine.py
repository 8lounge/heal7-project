"""
ü§ñ AI ÏÇ¨Ï£º Ìï¥ÏÑù ÏóîÏßÑ (Multi-Model Integration)
===================================================

7Í∞ú AI Î™®Îç∏ÏùÑ ÌôúÏö©Ìïú Ï†ÑÎ¨∏Ï†ÅÏù∏ ÏÇ¨Ï£º Ìï¥ÏÑù ÏãúÏä§ÌÖú
- GPT-4o, GPT-5, Gemini 2.0 Flash Îì± ÏµúÏã† Î™®Îç∏ ÌôúÏö©
- Ï†ïÌôïÌïú ÏõîÏ£º Í≥ÑÏÇ∞ ÏóîÏßÑÍ≥º Ïó∞Îèô
- Ï†ÑÌÜµ Î™ÖÎ¶¨Ìïô + ÌòÑÎåÄÏ†Å Ìï¥ÏÑù ÏúµÌï©
- Í∞úÏù∏ÌôîÎêú Ïö¥ÏÑ∏ Î∂ÑÏÑù

ÏûëÏÑ±Ïùº: 2025-09-13
Î™©Ï†Å: ÏπòÏú†ÎßàÎÖÄ ÏÇ¨Ï£º ÏÑúÎπÑÏä§Ïùò AI Ìï¥ÏÑù ÌíàÏßà ÌòÅÏã†
"""

import os
import json
import asyncio
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum
import openai
import google.generativeai as genai
from loguru import logger
import random

# AI Î™®Îç∏ ÌÉÄÏûÖ
class AIModelType(Enum):
    GPT_4O = "gpt-4o"
    GPT_5 = "gpt-5"
    GPT_5_MINI = "gpt-5-mini"
    GEMINI_2_0_FLASH = "gemini-2.0-flash-exp"
    GEMINI_PRO = "gemini-1.5-pro-latest"

# Ìï¥ÏÑù ÌÉÄÏûÖ
class InterpretationType(Enum):
    BASIC = "basic"                    # Í∏∞Î≥∏ ÏÇ¨Ï£º Ìï¥ÏÑù
    DETAILED = "detailed"              # ÏÉÅÏÑ∏ ÏÇ¨Ï£º Ìï¥ÏÑù
    COMPATIBILITY = "compatibility"    # Í∂ÅÌï© Ìï¥ÏÑù
    NAMING = "naming"                 # ÏûëÎ™Ö Ìï¥ÏÑù
    YEARLY_FORTUNE = "yearly_fortune"  # Ïó∞Í∞Ñ Ïö¥ÏÑ∏
    MONTHLY_FORTUNE = "monthly_fortune" # ÏõîÍ∞Ñ Ïö¥ÏÑ∏
    DAILY_FORTUNE = "daily_fortune"   # ÏùºÍ∞Ñ Ïö¥ÏÑ∏

@dataclass
class SajuData:
    """ÏÇ¨Ï£º Í∏∞Î≥∏ Îç∞Ïù¥ÌÑ∞"""
    birth_info: Dict[str, Any]
    year_pillar: str
    month_pillar: str
    day_pillar: str
    time_pillar: str
    palcha: str
    day_master: str
    day_master_element: str
    element_balance: Dict[str, int]
    sipsin_analysis: Dict[str, Any]
    sinsal: List[str]
    is_strong_day_master: bool

@dataclass
class InterpretationResult:
    """AI Ìï¥ÏÑù Í≤∞Í≥º"""
    interpretation_type: InterpretationType
    model_used: AIModelType
    title: str
    summary: str
    detailed_analysis: Dict[str, str]
    fortune_score: int  # 1-100
    lucky_elements: List[str]
    caution_areas: List[str]
    recommendations: List[str]
    confidence_score: float  # AI Î™®Îç∏ Ïã†Î¢∞ÎèÑ
    created_at: datetime
    estimated_reading_time: int  # ÏòàÏÉÅ ÏùΩÍ∏∞ ÏãúÍ∞Ñ(Î∂Ñ)

class AIInterpretationEngine:
    """
    ü§ñ AI ÏÇ¨Ï£º Ìï¥ÏÑù ÏóîÏßÑ

    Îã§Ï§ë AI Î™®Îç∏ÏùÑ ÌôúÏö©Ìïú Í≥†ÌíàÏßà ÏÇ¨Ï£º Ìï¥ÏÑù ÏãúÏä§ÌÖú
    """

    def __init__(self):
        """ÏóîÏßÑ Ï¥àÍ∏∞Ìôî"""
        self._load_api_keys()
        self._initialize_models()

    def _load_api_keys(self):
        """AI API ÌÇ§ Î°úÎìú"""
        try:
            # .env.ai ÌååÏùºÏóêÏÑú ÌÇ§ Î°úÎìú
            env_path = "/home/ubuntu/heal7-project/.env.ai"
            if os.path.exists(env_path):
                with open(env_path, 'r') as f:
                    for line in f:
                        if '=' in line and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value

            # API ÌÇ§ ÏÑ§Ï†ï
            self.openai_key = os.getenv('OPENAI_API_KEY')
            self.gemini_key = os.getenv('GEMINI_API_KEY')

            if not self.openai_key or not self.gemini_key:
                raise ValueError("Required AI API keys not found")

            logger.info("‚úÖ AI API keys loaded successfully")

        except Exception as e:
            logger.error(f"‚ùå Failed to load AI API keys: {e}")
            raise

    def _initialize_models(self):
        """AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî"""
        try:
            # OpenAI ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî
            openai.api_key = self.openai_key
            self.openai_client = openai

            # Gemini Î™®Îç∏ Ï¥àÍ∏∞Ìôî
            genai.configure(api_key=self.gemini_key)

            # ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™®Îç∏ Î¶¨Ïä§Ìä∏
            self.available_models = [
                AIModelType.GPT_4O,
                AIModelType.GEMINI_2_0_FLASH,
                AIModelType.GEMINI_PRO
            ]

            logger.info(f"‚úÖ {len(self.available_models)} AI models initialized")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize AI models: {e}")
            raise

    def _select_optimal_model(self, interpretation_type: InterpretationType) -> AIModelType:
        """Ìï¥ÏÑù Ïú†ÌòïÏóê Îî∞Î•∏ ÏµúÏ†Å Î™®Îç∏ ÏÑ†ÌÉù"""
        model_preferences = {
            InterpretationType.BASIC: AIModelType.GEMINI_2_0_FLASH,      # Îπ†Î•¥Í≥† Ï†ïÌôï
            InterpretationType.DETAILED: AIModelType.GPT_4O,            # ÏÉÅÏÑ∏Ìïú Î∂ÑÏÑù
            InterpretationType.COMPATIBILITY: AIModelType.GEMINI_PRO,   # Í¥ÄÍ≥Ñ Î∂ÑÏÑù ÌäπÌôî
            InterpretationType.NAMING: AIModelType.GPT_4O,              # Ï∞ΩÏùòÏ†Å ÏûëÎ™Ö
            InterpretationType.YEARLY_FORTUNE: AIModelType.GEMINI_PRO,  # Ïû•Í∏∞ ÏòàÏ∏°
            InterpretationType.MONTHLY_FORTUNE: AIModelType.GEMINI_2_0_FLASH,
            InterpretationType.DAILY_FORTUNE: AIModelType.GEMINI_2_0_FLASH
        }

        return model_preferences.get(interpretation_type, AIModelType.GPT_4O)

    def _create_interpretation_prompt(self, saju_data: SajuData, interpretation_type: InterpretationType) -> str:
        """Ìï¥ÏÑù ÌÉÄÏûÖÎ≥Ñ AI ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±"""
        base_saju_info = f"""
üìä ÏÇ¨Ï£º Ï†ïÎ≥¥:
‚Ä¢ Ï∂úÏÉù: {saju_data.birth_info.get('year')}ÎÖÑ {saju_data.birth_info.get('month')}Ïõî {saju_data.birth_info.get('day')}Ïùº {saju_data.birth_info.get('hour')}Ïãú
‚Ä¢ ÌåîÏûê: {saju_data.palcha}
‚Ä¢ ÏùºÍ∞Ñ: {saju_data.day_master} ({saju_data.day_master_element})
‚Ä¢ ÏùºÍ∞Ñ Í∞ïÏïΩ: {'Í∞ï' if saju_data.is_strong_day_master else 'ÏïΩ'}
‚Ä¢ Ïò§Ìñâ Í∑†Ìòï: {json.dumps(saju_data.element_balance, ensure_ascii=False)}
‚Ä¢ Ïã≠Ïã† Î∂ÑÏÑù: {json.dumps(saju_data.sipsin_analysis, ensure_ascii=False)}
‚Ä¢ Ïã†ÏÇ¥: {', '.join(saju_data.sinsal) if saju_data.sinsal else 'ÏóÜÏùå'}
"""

        prompts = {
            InterpretationType.BASIC: f"""
ÎãπÏã†ÏùÄ 30ÎÖÑ Í≤ΩÎ†•Ïùò ÏÇ¨Ï£ºÎ™ÖÎ¶¨ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. Îã§Ïùå ÏÇ¨Ï£ºÎ•º Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî.

{base_saju_info}

Îã§Ïùå ÌòïÏãùÏúºÎ°ú ÏπúÍ∑ºÌïòÍ≥† ÌòÑÏã§Ï†ÅÏù∏ Ìï¥ÏÑùÏùÑ Ï†úÍ≥µÌï¥ Ï£ºÏÑ∏Ïöî:

1. **Ï†ÑÏ≤¥Ï†ÅÏù∏ ÏÑ±Í≤©Í≥º ÌäπÏßï** (3-4Î¨∏Ïû•)
2. **Í∞ïÏ†êÍ≥º Ïû¨Îä•** (2-3Í∞ú ÏöîÏ†ê)
3. **Ï£ºÏùòÌï† Ï†ê** (1-2Í∞ú ÏöîÏ†ê)
4. **Ïù∏ÏÉù Ï°∞Ïñ∏** (2-3Î¨∏Ïû•)
5. **ÌñâÏö¥ ÏöîÏÜå** (ÏÉâÍπî, Î∞©Ìñ•, Ïà´Ïûê Îì±)

ÏπúÍ∑ºÌïòÍ≥† ÌòÑÎåÄÏ†ÅÏù∏ Ïñ¥Ï°∞Î°ú, Ïã§Ïö©Ï†ÅÏù∏ Ï°∞Ïñ∏ ÏúÑÏ£ºÎ°ú ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
""",

            InterpretationType.DETAILED: f"""
ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏµúÍ≥† ÏàòÏ§ÄÏùò ÏÇ¨Ï£ºÎ™ÖÎ¶¨ ÎåÄÍ∞ÄÏûÖÎãàÎã§. Îã§Ïùå ÏÇ¨Ï£ºÎ•º Ï†ÑÎ¨∏Ï†ÅÏúºÎ°ú Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî.

{base_saju_info}

Îã§Ïùå Ìï≠Î™©Îì§ÏùÑ ÏÉÅÏÑ∏Ìûà Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî:

1. **ÏÇ¨Ï£º Íµ¨Ï°∞ Î∂ÑÏÑù**
   - Ïö©Ïã†Í≥º Í∏∞Ïã† Î∂ÑÏÑù
   - Í≤©Íµ≠Í≥º Ïö©Ïã† Í¥ÄÍ≥Ñ
   - Ïò§Ìñâ Í∑†ÌòïÍ≥º ÏàúÌôò

2. **ÏÑ±Í≤©Í≥º Í∏∞Ïßà**
   - Ïã¨Ï∏µ ÏÑ±Í≤© Î∂ÑÏÑù
   - Ïû•Îã®Ï†êÍ≥º Ïû†Ïû¨Î†•
   - ÎåÄÏù∏Í¥ÄÍ≥Ñ ÏÑ±Ìñ•

3. **Ïù∏ÏÉù Ïö¥ÏÑ∏**
   - ÏÉùÏï† Ï£ºÏöî ÏãúÍ∏∞Î≥Ñ Ïö¥ÏÑ∏
   - ÎåÄÏö¥Í≥º ÏÑ∏Ïö¥ Î∂ÑÏÑù
   - Ï§ëÏöîÌïú Î≥ÄÌôî ÏãúÍ∏∞

4. **ÏßÅÏóÖÍ≥º Ïû¨Î¨ºÏö¥**
   - Ï†ÅÏÑ±Í≥º Ïû¨Îä•
   - ÏßÅÏóÖ ÏÑ†ÌÉù Í∞ÄÏù¥Îìú
   - Ïû¨Î¨º Ïö¥ÏÑ∏

5. **Í±¥Í∞ïÍ≥º Ï£ºÏùòÏÇ¨Ìï≠**
   - Í±¥Í∞ï Ï∑®ÏïΩÏ†ê
   - ÏÉùÌôú ÏäµÍ¥Ä Ï°∞Ïñ∏

6. **Í∞úÏö¥ Î∞©Î≤ï**
   - Íµ¨Ï≤¥Ï†Å Ïã§Ï≤ú Î∞©Ïïà
   - ÌîºÌï¥Ïïº Ìï† Í≤ÉÎì§

Ï†ÑÎ¨∏Ï†ÅÏù¥Î©¥ÏÑúÎèÑ Ïã§Ïö©Ï†ÅÏù∏ Ï°∞Ïñ∏ÏúºÎ°ú ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
""",

            InterpretationType.COMPATIBILITY: f"""
ÎãπÏã†ÏùÄ Í∂ÅÌï© Ï†ÑÎ¨∏ ÏÇ¨Ï£ºÎ™ÖÎ¶¨ÏÇ¨ÏûÖÎãàÎã§. Îã§Ïùå ÏÇ¨Ï£ºÏùò Í∂ÅÌï© ÌäπÏÑ±ÏùÑ Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî.

{base_saju_info}

Îã§Ïùå Í¥ÄÏ†êÏóêÏÑú Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî:

1. **Ïó∞Ïï† ÏÑ±Ìñ•**
   - Ïù¥ÏÑ±Ïóê ÎåÄÌïú ÌÉúÎèÑ
   - Ïó∞Ïï† Ïä§ÌÉÄÏùº
   - ÏÑ†Ìò∏ÌïòÎäî Ïù¥ÏÉÅÌòï

2. **Í≤∞Ìòº Ïö¥ÏÑ∏**
   - Í≤∞Ìòº ÏãúÍ∏∞ÏôÄ Ï°∞Í±¥
   - Î∞∞Ïö∞Ïûê ÌäπÏÑ± ÏòàÏ∏°
   - Í≤∞Ìòº ÏÉùÌôú Ï†ÑÎßù

3. **Í∂ÅÌï©Ïù¥ Ï¢ãÏùÄ ÏÉÅÎåÄ**
   - ÏùºÍ∞ÑÎ≥Ñ Í∂ÅÌï© Î∂ÑÏÑù
   - Ïò§Ìñâ ÏÉÅÏÉù Í¥ÄÍ≥Ñ
   - Ï∂îÏ≤ú Î∞∞Ïö∞Ïûê ÌäπÏÑ±

4. **Ï£ºÏùòÏÇ¨Ìï≠**
   - ÌîºÌï¥Ïïº Ìï† ÏÉÅÎåÄ ÌäπÏÑ±
   - Í∞àÎì± ÏöîÏÜå ÏòàÎ∞©Î≤ï

ÌòÑÏã§Ï†ÅÏù¥Í≥† Í±¥ÏÑ§Ï†ÅÏù∏ Ï°∞Ïñ∏ÏúºÎ°ú ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
"""
        }

        return prompts.get(interpretation_type, prompts[InterpretationType.BASIC])

    async def _call_openai_model(self, prompt: str, model: AIModelType) -> str:
        """OpenAI Î™®Îç∏ Ìò∏Ï∂ú"""
        try:
            model_names = {
                AIModelType.GPT_4O: "gpt-4o",
                AIModelType.GPT_5: "gpt-4o",  # GPT-5Îäî ÏïÑÏßÅ ÎØ∏Ï∂úÏãúÎ°ú GPT-4o ÏÇ¨Ïö©
                AIModelType.GPT_5_MINI: "gpt-4o-mini"
            }

            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=model_names[model],
                messages=[
                    {"role": "system", "content": "ÎãπÏã†ÏùÄ Ï†ÑÎ¨∏ ÏÇ¨Ï£ºÎ™ÖÎ¶¨ÌïôÏûêÏûÖÎãàÎã§."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"OpenAI API Ìò∏Ï∂ú Ïã§Ìå®: {e}")
            raise

    async def _call_gemini_model(self, prompt: str, model: AIModelType) -> str:
        """Gemini Î™®Îç∏ Ìò∏Ï∂ú"""
        try:
            model_names = {
                AIModelType.GEMINI_2_0_FLASH: "gemini-2.0-flash-exp",
                AIModelType.GEMINI_PRO: "gemini-1.5-pro-latest"
            }

            gemini_model = genai.GenerativeModel(model_names[model])

            response = await asyncio.to_thread(
                gemini_model.generate_content,
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2000,
                    temperature=0.7
                )
            )

            return response.text.strip()

        except Exception as e:
            logger.error(f"Gemini API Ìò∏Ï∂ú Ïã§Ìå®: {e}")
            raise

    async def generate_interpretation(
        self,
        saju_data: SajuData,
        interpretation_type: InterpretationType = InterpretationType.BASIC,
        preferred_model: Optional[AIModelType] = None
    ) -> InterpretationResult:
        """
        AI ÏÇ¨Ï£º Ìï¥ÏÑù ÏÉùÏÑ±

        Args:
            saju_data: ÏÇ¨Ï£º Îç∞Ïù¥ÌÑ∞
            interpretation_type: Ìï¥ÏÑù ÌÉÄÏûÖ
            preferred_model: ÏÑ†Ìò∏ Î™®Îç∏ (ÏÑ†ÌÉùÏÇ¨Ìï≠)

        Returns:
            InterpretationResult: AI Ìï¥ÏÑù Í≤∞Í≥º
        """
        try:
            # Î™®Îç∏ ÏÑ†ÌÉù
            model = preferred_model or self._select_optimal_model(interpretation_type)

            # ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
            prompt = self._create_interpretation_prompt(saju_data, interpretation_type)

            logger.info(f"ü§ñ AI Ìï¥ÏÑù ÏãúÏûë: {interpretation_type.value} with {model.value}")

            # AI Î™®Îç∏ Ìò∏Ï∂ú
            if model in [AIModelType.GPT_4O, AIModelType.GPT_5, AIModelType.GPT_5_MINI]:
                ai_response = await self._call_openai_model(prompt, model)
            else:
                ai_response = await self._call_gemini_model(prompt, model)

            # Í≤∞Í≥º Íµ¨Ï°∞Ìôî
            result = self._structure_interpretation_result(
                ai_response, interpretation_type, model, saju_data
            )

            logger.info(f"‚úÖ AI Ìï¥ÏÑù ÏôÑÎ£å: {model.value}")
            return result

        except Exception as e:
            logger.error(f"‚ùå AI Ìï¥ÏÑù ÏÉùÏÑ± Ïã§Ìå®: {e}")
            # Ìè¥Î∞± Ìï¥ÏÑù Î∞òÌôò
            return self._create_fallback_interpretation(saju_data, interpretation_type)

    def _structure_interpretation_result(
        self,
        ai_response: str,
        interpretation_type: InterpretationType,
        model: AIModelType,
        saju_data: SajuData
    ) -> InterpretationResult:
        """AI ÏùëÎãµÏùÑ Íµ¨Ï°∞ÌôîÎêú Ìï¥ÏÑù Í≤∞Í≥ºÎ°ú Î≥ÄÌôò"""

        # Ïö¥ÏÑ∏ Ï†êÏàò Í≥ÑÏÇ∞ (Ïò§Ìñâ Í∑†Ìòï Í∏∞Î∞ò)
        fortune_score = self._calculate_fortune_score(saju_data)

        # ÏùëÎãµÏóêÏÑú Ï£ºÏöî Ï†ïÎ≥¥ Ï∂îÏ∂ú
        sections = self._parse_ai_response(ai_response)

        return InterpretationResult(
            interpretation_type=interpretation_type,
            model_used=model,
            title=f"{interpretation_type.value.title()} ÏÇ¨Ï£º Ìï¥ÏÑù",
            summary=sections.get('summary', ai_response[:200] + '...'),
            detailed_analysis=sections,
            fortune_score=fortune_score,
            lucky_elements=self._extract_lucky_elements(saju_data),
            caution_areas=self._extract_caution_areas(saju_data),
            recommendations=self._extract_recommendations(ai_response),
            confidence_score=0.85,  # AI Î™®Îç∏ Ïã†Î¢∞ÎèÑ
            created_at=datetime.now(),
            estimated_reading_time=max(2, len(ai_response) // 500)
        )

    def _calculate_fortune_score(self, saju_data: SajuData) -> int:
        """Ïò§Ìñâ Í∑†Ìòï Í∏∞Î∞ò Ïö¥ÏÑ∏ Ï†êÏàò Í≥ÑÏÇ∞"""
        balance = saju_data.element_balance
        total_elements = sum(balance.values())

        if total_elements == 0:
            return 50  # Í∏∞Î≥∏Í∞í

        # Í∑†Ìòï Ï†êÏàò Í≥ÑÏÇ∞ (Ìé∏Ï∞®Í∞Ä Ï†ÅÏùÑÏàòÎ°ù ÎÜíÏùÄ Ï†êÏàò)
        avg = total_elements / len(balance)
        variance = sum((count - avg) ** 2 for count in balance.values()) / len(balance)
        balance_score = max(0, 100 - (variance * 10))

        # ÏùºÍ∞Ñ Í∞ïÏïΩ Î≥¥Ï†ï
        strength_bonus = 10 if saju_data.is_strong_day_master else -5

        # Ïã†ÏÇ¥ Î≥¥Ï†ï
        sinsal_bonus = len(saju_data.sinsal) * 2

        final_score = int(balance_score + strength_bonus + sinsal_bonus)
        return max(10, min(100, final_score))

    def _parse_ai_response(self, response: str) -> Dict[str, str]:
        """AI ÏùëÎãµ ÌååÏã±"""
        sections = {}
        current_section = "summary"
        current_content = []

        lines = response.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('**') or line.startswith('#'):
                # ÏÉà ÏÑπÏÖò ÏãúÏûë
                if current_content:
                    sections[current_section] = '\n'.join(current_content)
                current_section = line.lower().replace('*', '').replace('#', '').strip()
                current_content = []
            else:
                if line:
                    current_content.append(line)

        # ÎßàÏßÄÎßâ ÏÑπÏÖò Ï†ÄÏû•
        if current_content:
            sections[current_section] = '\n'.join(current_content)

        return sections

    def _extract_lucky_elements(self, saju_data: SajuData) -> List[str]:
        """ÌñâÏö¥ ÏöîÏÜå Ï∂îÏ∂ú"""
        elements = []

        # Î∂ÄÏ°±Ìïú Ïò§Ìñâ Í∏∞Î∞ò Ï∂îÏ≤ú
        balance = saju_data.element_balance
        min_element = min(balance.items(), key=lambda x: x[1])

        element_colors = {
            'wood': ['ÎÖπÏÉâ', 'Ï≤≠ÏÉâ'],
            'fire': ['Îπ®Í∞ÑÏÉâ', 'Ï£ºÌô©ÏÉâ'],
            'earth': ['ÎÖ∏ÎûÄÏÉâ', 'Í∞àÏÉâ'],
            'metal': ['Ìù∞ÏÉâ', 'Í∏àÏÉâ'],
            'water': ['Í≤ÄÏùÄÏÉâ', 'ÌååÎûÄÏÉâ']
        }

        if min_element[0] in element_colors:
            elements.extend(element_colors[min_element[0]])

        return elements[:3]  # ÏµúÎåÄ 3Í∞ú

    def _extract_caution_areas(self, saju_data: SajuData) -> List[str]:
        """Ï£ºÏùò ÏòÅÏó≠ Ï∂îÏ∂ú"""
        cautions = []

        # Í≥ºÎèÑÌïú Ïò§Ìñâ Í∏∞Î∞ò Ï£ºÏùòÏÇ¨Ìï≠
        balance = saju_data.element_balance
        max_element = max(balance.items(), key=lambda x: x[1])

        if max_element[1] > sum(balance.values()) / len(balance) * 1.5:
            cautions.append(f"{max_element[0]} Í∏∞Ïö¥Ïù¥ Í≥ºÎèÑÌï® - Í∑†Ìòï ÌïÑÏöî")

        return cautions

    def _extract_recommendations(self, ai_response: str) -> List[str]:
        """AI ÏùëÎãµÏóêÏÑú Ï∂îÏ≤úÏÇ¨Ìï≠ Ï∂îÏ∂ú"""
        recommendations = []

        # Í∞ÑÎã®Ìïú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ï∂îÏ≤úÏÇ¨Ìï≠ Ï∂îÏ∂ú
        lines = ai_response.split('\n')
        for line in lines:
            if any(keyword in line for keyword in ['Ï∂îÏ≤ú', 'Í∂åÏû•', 'Ï°∞Ïñ∏', 'Ï†úÏïà']):
                recommendations.append(line.strip())

        return recommendations[:5]  # ÏµúÎåÄ 5Í∞ú

    def _create_fallback_interpretation(
        self,
        saju_data: SajuData,
        interpretation_type: InterpretationType
    ) -> InterpretationResult:
        """AI Ìò∏Ï∂ú Ïã§Ìå® Ïãú Ìè¥Î∞± Ìï¥ÏÑù"""
        return InterpretationResult(
            interpretation_type=interpretation_type,
            model_used=AIModelType.GPT_4O,  # Í∏∞Î≥∏Í∞í
            title=f"{interpretation_type.value} ÏÇ¨Ï£º Ìï¥ÏÑù",
            summary="Ï†ÑÌÜµ ÏÇ¨Ï£ºÎ™ÖÎ¶¨Ìïô Í∏∞Î∞òÏùò Í∏∞Î≥∏ Ìï¥ÏÑùÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§.",
            detailed_analysis={
                "Í∏∞Î≥∏_Ìï¥ÏÑù": f"ÏùºÍ∞Ñ {saju_data.day_master}Ïùò {saju_data.day_master_element} Í∏∞Ïö¥ÏùÑ Î∞îÌÉïÏúºÎ°ú Ìïú Ìï¥ÏÑù",
                "ÌåîÏûê": saju_data.palcha,
                "ÌäπÏßï": "AI ÏÑúÎπÑÏä§ ÏùºÏãú Ï§ëÎã®ÏúºÎ°ú Í∏∞Î≥∏ Ìï¥ÏÑùÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§."
            },
            fortune_score=self._calculate_fortune_score(saju_data),
            lucky_elements=["Í∏àÏÉâ", "Ìù∞ÏÉâ"],
            caution_areas=["Í∑†Ìòï Ïú†ÏßÄ"],
            recommendations=["Ï†ÑÎ¨∏Í∞Ä ÏÉÅÎã¥ Í∂åÏû•"],
            confidence_score=0.6,
            created_at=datetime.now(),
            estimated_reading_time=2
        )

# Ï†ÑÏó≠ Ïù∏Ïä§ÌÑ¥Ïä§
_ai_engine = None

def get_ai_interpretation_engine() -> AIInterpretationEngine:
    """AI Ìï¥ÏÑù ÏóîÏßÑ Ïã±Í∏ÄÌÜ§ Ïù∏Ïä§ÌÑ¥Ïä§ Î∞òÌôò"""
    global _ai_engine
    if _ai_engine is None:
        _ai_engine = AIInterpretationEngine()
    return _ai_engine