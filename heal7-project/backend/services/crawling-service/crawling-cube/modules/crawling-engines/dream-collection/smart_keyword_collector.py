#!/usr/bin/env python3
"""
ğŸ¯ ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ê¸°ë°˜ ê¿ˆí’€ì´ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
- ì¹´í…Œê³ ë¦¬ë³„ í•µì‹¬ í‚¤ì›Œë“œ ê¸°ë°˜ íƒ€ê²Ÿ ìˆ˜ì§‘
- 5ë¶„ ê°„ê²©ìœ¼ë¡œ ì²œì²œíˆ ìˆ˜ì§‘ (ì¼ì¼ 5,000ê°œ ëª©í‘œ)
- ì§€ëŠ¥í˜• í‚¤ì›Œë“œ í™•ì¥ ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
"""

import requests
import json
import hashlib
import time
import random
import logging
import threading
import subprocess
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup
import urllib.parse
import os
from typing import List, Dict, Tuple

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/ubuntu/logs/smart_keyword_collector.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SmartKeywordCollector:
    def __init__(self):
        self.collected_count = 0
        self.error_count = 0
        self.duplicate_count = 0
        self.lock = threading.Lock()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # ì¹´í…Œê³ ë¦¬ë³„ í•µì‹¬ í‚¤ì›Œë“œ ë°ì´í„°ë² ì´ìŠ¤
        self.dream_keywords = {
            "ë™ë¬¼": [
                "í˜¸ë‘ì´", "ì‚¬ì", "ìš©", "ë±€", "ìƒˆ", "ê°œ", "ê³ ì–‘ì´", "ë§", "ì†Œ", "ë¼ì§€", 
                "ì›ìˆ­ì´", "ì½”ë¼ë¦¬", "ê³°", "ëŠ‘ëŒ€", "ì—¬ìš°", "í† ë¼", "ì¥", "ì‚¬ìŠ´", "ê¸°ë¦°",
                "ë¬¼ê³ ê¸°", "ìƒì–´", "ê³ ë˜", "ê±°ë¶ì´", "ê°œêµ¬ë¦¬", "ë‚˜ë¹„", "ë²Œ", "ê±°ë¯¸"
            ],
            "ìì—°": [
                "ì‚°", "ë°”ë‹¤", "ê°•", "í˜¸ìˆ˜", "ë‚˜ë¬´", "ê½ƒ", "ë¶ˆ", "ë¬¼", "ë°”ëŒ", "ë¹„",
                "ëˆˆ", "ë²ˆê°œ", "ë¬´ì§€ê°œ", "í•´", "ë‹¬", "ë³„", "êµ¬ë¦„", "í­í’", "ì§€ì§„"
            ],
            "ìŒì‹": [
                "ë°¥", "ê³ ê¸°", "ìƒì„ ", "ê³¼ì¼", "ë¹µ", "ìˆ ", "ë¬¼", "ì°¨", "ì»¤í”¼", "ì¼€ì´í¬",
                "êµ­ìˆ˜", "ë–¡", "ê¹€ì¹˜", "ì‚¬íƒ•", "ì´ˆì½œë¦¿", "ê³„ë€", "ìš°ìœ ", "ê¿€"
            ],
            "ì‚¬ë¬¼": [
                "ì§‘", "ìë™ì°¨", "ëˆ", "ê¸ˆ", "ì€", "ë³´ì„", "ì˜·", "ì‹ ë°œ", "ê°€ë°©", "íœ´ëŒ€í°",
                "ì»´í“¨í„°", "ì±…", "ì¹¼", "ì´", "ê±°ìš¸", "ì‹œê³„", "ì—´ì‡ ", "ë‹¤ë¦¬", "ë¬¸", "ì°½ë¬¸"
            ],
            "ì‚¬ëŒ": [
                "ê°€ì¡±", "ì—„ë§ˆ", "ì•„ë¹ ", "í˜•ì œ", "ìë§¤", "ì¹œêµ¬", "ì—°ì¸", "ì•„ê¸°", "ë…¸ì¸",
                "ì„ ìƒë‹˜", "ì˜ì‚¬", "ê²½ì°°", "êµ°ì¸", "ë„ë‘‘", "ìœ ëª…ì¸", "ì£½ì€ì‚¬ëŒ", "ì„ì‹ "
            ],
            "í–‰ë™": [
                "ë‚ ë‹¤", "ë‹¬ë¦¬ë‹¤", "ìˆ˜ì˜", "ì¶¤", "ë…¸ë˜", "ìš¸ë‹¤", "ì›ƒë‹¤", "ì‹¸ìš°ë‹¤", "ë„ë§",
                "ìˆ¨ë‹¤", "ì°¾ë‹¤", "ìƒë‹¤", "ë–¨ì–´ì§€ë‹¤", "ì˜¬ë¼ê°€ë‹¤", "ë‚´ë ¤ê°€ë‹¤", "ê²°í˜¼", "ì´í˜¼"
            ],
            "ì‹ ì²´": [
                "ë¨¸ë¦¬", "ëˆˆ", "ì½”", "ì…", "ê·€", "ì†", "ë°œ", "ë°°", "ê°€ìŠ´", "ë“±", "í”¼",
                "ë¼ˆ", "ì¹˜ì•„", "ë¨¸ë¦¬ì¹´ë½", "ìƒì²˜", "ë³‘", "ì£½ìŒ", "ì¹˜ë£Œ", "ìˆ˜ìˆ "
            ],
            "ì¥ì†Œ": [
                "í•™êµ", "ë³‘ì›", "íšŒì‚¬", "ì‹œì¥", "ê³µì›", "êµíšŒ", "ì ˆ", "ê³µí•­", "ê¸°ì°¨ì—­",
                "í™”ì¥ì‹¤", "ëª©ìš•íƒ•", "ë°©", "ë¶€ì—Œ", "ë§ˆë‹¹", "ë¬´ë¤", "ê°ì˜¥", "ê·¹ì¥"
            ],
            "ê°ì •ìƒí™©": [
                "ë¬´ì„­ë‹¤", "ê¸°ì˜ë‹¤", "ìŠ¬í”„ë‹¤", "í™”ë‚˜ë‹¤", "ë†€ë¼ë‹¤", "ê±±ì •", "ë‘ë ¤ì›€",
                "ì‚¬ë‘", "ë¯¸ì›€", "ì§ˆíˆ¬", "ì™¸ë¡œì›€", "í–‰ë³µ", "ê³ í†µ", "í‰í™”", "ìŠ¤íŠ¸ë ˆìŠ¤"
            ]
        }
        
        # í‚¤ì›Œë“œ í’€ ìƒì„± (ê°€ì¤‘ì¹˜ ì ìš©)
        self.weighted_keywords = self._create_weighted_keywords()
        
        # ìˆ˜ì§‘ ì‚¬ì´íŠ¸ ì„¤ì •
        self.sites = {
            'unse2u': {
                'base_url': 'https://www.unse2u.co.kr',
                'search_pattern': 'search.php?keyword={}',
                'list_pattern': 'dreamview.php?c1=1&c2={}'
            }
        }

    def _create_weighted_keywords(self) -> List[Tuple[str, str, int]]:
        """ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¥¼ ê°€ì¤‘ì¹˜ì™€ í•¨ê»˜ ìƒì„±"""
        weighted = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜ (ì¸ê¸°ë„/ì¤‘ìš”ë„ ê¸°ì¤€)
        category_weights = {
            "ë™ë¬¼": 10,
            "ì‚¬ëŒ": 9,
            "ì‚¬ë¬¼": 8,
            "ìì—°": 7,
            "í–‰ë™": 6,
            "ê°ì •ìƒí™©": 5,
            "ìŒì‹": 4,
            "ì¥ì†Œ": 4,
            "ì‹ ì²´": 3
        }
        
        for category, keywords in self.dream_keywords.items():
            base_weight = category_weights.get(category, 1)
            for keyword in keywords:
                # í‚¤ì›Œë“œë³„ ê°œë³„ ê°€ì¤‘ì¹˜ (ê¸¸ì´, ì¸ê¸°ë„ ê³ ë ¤)
                keyword_weight = base_weight + (5 - min(len(keyword), 5))
                weighted.append((keyword, category, keyword_weight))
        
        return sorted(weighted, key=lambda x: x[2], reverse=True)

    def select_target_keywords(self, count: int = 17) -> List[Tuple[str, str]]:
        """5ë¶„ê°„ ìˆ˜ì§‘í•  íƒ€ê²Ÿ í‚¤ì›Œë“œ ì„ íƒ (ê°€ì¤‘ì¹˜ ê¸°ë°˜ ëœë¤)"""
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ
        total_weight = sum(item[2] for item in self.weighted_keywords)
        selected = []
        
        for _ in range(count):
            rand_weight = random.randint(1, total_weight)
            current_weight = 0
            
            for keyword, category, weight in self.weighted_keywords:
                current_weight += weight
                if current_weight >= rand_weight:
                    selected.append((keyword, category))
                    break
        
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ì¥
        unique_selected = []
        used_keywords = set()
        category_counts = {}
        
        for keyword, category in selected:
            if keyword not in used_keywords and category_counts.get(category, 0) < 3:
                unique_selected.append((keyword, category))
                used_keywords.add(keyword)
                category_counts[category] = category_counts.get(category, 0) + 1
                
                if len(unique_selected) >= count:
                    break
        
        return unique_selected

    def search_keyword_data(self, keyword: str, category: str) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê¿ˆí’€ì´ ë°ì´í„° ê²€ìƒ‰ ë° ìˆ˜ì§‘"""
        results = []
        
        try:
            # í‚¤ì›Œë“œë³„ ë§¤í•‘ëœ URL ë²”ìœ„ ìƒì„± (ê¸°ì¡´ ë™ì‘í•˜ëŠ” íŒ¨í„´ í™œìš©)
            # í‚¤ì›Œë“œë¥¼ ìˆ«ì ë²”ìœ„ë¡œ ë§¤í•‘í•˜ì—¬ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í˜ì´ì§€ ì ‘ê·¼
            keyword_hash = abs(hash(keyword)) % 500 + 1  # 1~500 ë²”ìœ„
            base_urls = []
            
            # í‚¤ì›Œë“œ í•´ì‹œ ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ URL ìƒì„±
            for i in range(3):  # í‚¤ì›Œë“œë‹¹ 3ê°œ URL
                url_id = (keyword_hash + i * 50) % 500 + 1
                base_urls.append(f"https://www.unse2u.co.kr/dreamview.php?c1=1&c2={url_id}")
            
            for url in base_urls:
                try:
                    response = self.session.get(url, timeout=10)
                    if response.status_code == 200:
                        # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‚´ìš©ì¸ì§€ í™•ì¸ í›„ ìˆ˜ì§‘
                        dream_data = self._extract_keyword_dream_content(url, keyword, category, response)
                        if dream_data:
                            results.append(dream_data)
                            logger.info(f"âœ… í‚¤ì›Œë“œ ë§¤ì¹­: {keyword} â†’ {url}")
                        
                    time.sleep(random.uniform(2, 4))  # ìš”ì²­ ê°„ê²©
                    
                except Exception as e:
                    logger.debug(f"URL ì ‘ê·¼ ì‹¤íŒ¨ ({url}): {e}")
                    continue
                
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            with self.lock:
                self.error_count += 1
        
        return results

    def _extract_dream_links(self, soup: BeautifulSoup, keyword: str) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê¿ˆí’€ì´ ê´€ë ¨ ë§í¬ ì¶”ì¶œ"""
        links = []
        
        # ë‹¤ì–‘í•œ ë§í¬ íŒ¨í„´ ê²€ìƒ‰
        link_patterns = [
            'a[href*="dreamview"]',
            'a[href*="dream"]',
            'a[href*="interpretation"]',
            'a[href*="meaning"]'
        ]
        
        for pattern in link_patterns:
            for link in soup.select(pattern):
                href = link.get('href')
                if href and keyword in link.get_text().lower():
                    if href.startswith('/'):
                        href = 'https://www.unse2u.co.kr' + href
                    links.append(href)
                    
                if len(links) >= 5:  # í‚¤ì›Œë“œë‹¹ ìµœëŒ€ 5ê°œ ë§í¬
                    break
        
        return list(set(links))  # ì¤‘ë³µ ì œê±°

    def _extract_keyword_dream_content(self, url: str, keyword: str, category: str, response) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê¿ˆí’€ì´ í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì œëª©ê³¼ ë‚´ìš© ì¶”ì¶œ
            title = soup.title.string if soup.title else ""
            content = soup.get_text(separator=' ', strip=True)
            
            # ê¿ˆí’€ì´ ê´€ë ¨ ë‚´ìš© í™•ì¸
            dream_indicators = ['ê¿ˆ', 'í•´ëª½', 'ê¸¸ëª½', 'í‰ëª½', 'íƒœëª½', 'ì˜ë¯¸', 'ì§•ì¡°']
            if not any(indicator in content for indicator in dream_indicators):
                return None
            
            # í‚¤ì›Œë“œ ë˜ëŠ” ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if not self._contains_relevant_keyword(content, keyword, category):
                return None
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
            structured_data = {
                "url": url,
                "keyword": keyword,
                "category": category,
                "title": title[:200],
                "content": content[:2000],
                "content_length": len(content),
                "collection_method": "smart_keyword_mapping",
                "target_keyword": keyword,
                "target_category": category,
                "extracted_at": datetime.now().isoformat(),
                "quality_score": self._calculate_quality_score(content, keyword, category),
                "keyword_match_type": self._get_keyword_match_type(content, keyword, category)
            }
            
            return structured_data
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì»¨í…ì¸  ì¶”ì¶œ ì˜¤ë¥˜ ({url}): {e}")
            return None

    def _contains_relevant_keyword(self, content: str, target_keyword: str, category: str) -> bool:
        """ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸"""
        content_lower = content.lower()
        target_lower = target_keyword.lower()
        
        # 1. ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        if target_lower in content_lower:
            return True
        
        # 2. ì¹´í…Œê³ ë¦¬ë³„ ê´€ë ¨ í‚¤ì›Œë“œ ë§¤ì¹­
        category_keywords = self.dream_keywords.get(category, [])
        related_matches = sum(1 for kw in category_keywords if kw.lower() in content_lower)
        
        # ê°™ì€ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒ í¬í•¨ë˜ë©´ ê´€ë ¨ì„± ìˆë‹¤ê³  íŒë‹¨
        if related_matches >= 2:
            return True
            
        # 3. ë¶€ë¶„ ë§¤ì¹­ (2ê¸€ì ì´ìƒ í‚¤ì›Œë“œì˜ ê²½ìš°)
        if len(target_keyword) >= 2:
            if target_keyword[:2] in content or target_keyword[1:] in content:
                return True
        
        return False

    def _get_keyword_match_type(self, content: str, keyword: str, category: str) -> str:
        """í‚¤ì›Œë“œ ë§¤ì¹­ íƒ€ì… ë°˜í™˜"""
        if keyword.lower() in content.lower():
            return "exact_match"
        
        category_keywords = self.dream_keywords.get(category, [])
        matches = [kw for kw in category_keywords if kw.lower() in content.lower()]
        
        if matches:
            return f"category_match({','.join(matches[:3])})"
        
        return "partial_match"

    def _extract_dream_content(self, url: str, keyword: str, category: str) -> Dict:
        """ê°œë³„ ê¿ˆí’€ì´ í˜ì´ì§€ì—ì„œ ë‚´ìš© ì¶”ì¶œ"""
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code != 200:
                return None
                
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì œëª©ê³¼ ë‚´ìš© ì¶”ì¶œ
            title = soup.title.string if soup.title else ""
            content = soup.get_text(separator=' ', strip=True)
            
            # ê¿ˆí’€ì´ ê´€ë ¨ ë‚´ìš© í™•ì¸
            dream_indicators = ['ê¿ˆ', 'í•´ëª½', 'ê¸¸ëª½', 'í‰ëª½', 'íƒœëª½', 'ì˜ë¯¸', 'ì§•ì¡°']
            if not any(indicator in content for indicator in dream_indicators):
                return None
            
            # í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if keyword not in content:
                return None
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
            structured_data = {
                "url": url,
                "keyword": keyword,
                "category": category,
                "title": title[:200],
                "content": content[:2000],
                "content_length": len(content),
                "collection_method": "smart_keyword_search",
                "target_keyword": keyword,
                "target_category": category,
                "extracted_at": datetime.now().isoformat(),
                "quality_score": self._calculate_quality_score(content, keyword, category)
            }
            
            return structured_data
            
        except Exception as e:
            logger.error(f"ì»¨í…ì¸  ì¶”ì¶œ ì˜¤ë¥˜ ({url}): {e}")
            return None

    def _calculate_quality_score(self, content: str, keyword: str, category: str) -> float:
        """ë‚´ìš© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # í‚¤ì›Œë“œ í¬í•¨ ì ìˆ˜
        if keyword in content:
            score += 0.2
            
        # ë‚´ìš© ê¸¸ì´ ì ìˆ˜
        if len(content) > 500:
            score += 0.1
        if len(content) > 1000:
            score += 0.1
            
        # ê¿ˆí’€ì´ ì „ë¬¸ ìš©ì–´ ì ìˆ˜
        specialized_terms = ['ê¸¸ëª½', 'í‰ëª½', 'íƒœëª½', 'í•´ëª½', 'ì§•ì¡°', 'ì˜ë¯¸', 'ìƒì§•', 'ìš´ì„¸']
        found_terms = sum(1 for term in specialized_terms if term in content)
        score += min(found_terms * 0.05, 0.2)
        
        return min(score, 1.0)

    def save_to_database(self, dream_data: Dict) -> bool:
        """PostgreSQLì— ì•ˆì „í•˜ê²Œ ì €ì¥"""
        try:
            # ì¤‘ë³µ í™•ì¸ìš© í•´ì‹œ
            content_hash = hashlib.md5(
                (dream_data['url'] + dream_data['content']).encode()
            ).hexdigest()
            
            # JSON ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_file = f'/tmp/dream_data_{int(time.time())}_{random.randint(1000,9999)}.json'
            
            # JSONB ë°ì´í„° ì¤€ë¹„
            jsonb_data = {
                **dream_data,
                "content_hash": content_hash
            }
            
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(jsonb_data, f, ensure_ascii=False, indent=2)
            
            # PostgreSQL ì €ì¥
            query = f"""
            INSERT INTO dream_raw_collection (source_site, source_url, raw_content, content_hash, collection_status)
            SELECT 
                'smart_keyword_search',
                '{dream_data['url']}',
                content::jsonb,
                '{content_hash}',
                'collected'
            FROM (
                SELECT pg_read_file('{temp_file}') as content
            ) as file_data
            WHERE NOT EXISTS (
                SELECT 1 FROM dream_raw_collection WHERE content_hash = '{content_hash}'
            );
            """
            
            result = subprocess.run([
                'sudo', '-u', 'postgres', 'psql', '-d', 'heal7', '-c', query
            ], capture_output=True, text=True, timeout=30)
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(temp_file):
                os.remove(temp_file)
            
            if result.returncode == 0:
                if "INSERT 0 1" in result.stdout:
                    with self.lock:
                        self.collected_count += 1
                    logger.info(f"âœ… ì €ì¥ ì„±ê³µ: {dream_data['keyword']} ({dream_data['category']})")
                    return True
                else:
                    with self.lock:
                        self.duplicate_count += 1
                    logger.debug(f"âš ï¸ ì¤‘ë³µ ë°ì´í„°: {dream_data['keyword']}")
                    return True  # ì¤‘ë³µë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            else:
                logger.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {result.stderr}")
                with self.lock:
                    self.error_count += 1
                return False
                
        except Exception as e:
            logger.error(f"âŒ ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}")
            with self.lock:
                self.error_count += 1
            return False

    def collect_batch(self, target_count: int = 17) -> Dict:
        """5ë¶„ê°„ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰"""
        start_time = datetime.now()
        logger.info(f"ğŸš€ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: ëª©í‘œ {target_count}ê°œ")
        
        # íƒ€ê²Ÿ í‚¤ì›Œë“œ ì„ íƒ
        target_keywords = self.select_target_keywords(target_count)
        logger.info(f"ğŸ“‹ ì„ íƒëœ í‚¤ì›Œë“œ: {[f'{kw}({cat})' for kw, cat in target_keywords]}")
        
        # ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰
        all_results = []
        with ThreadPoolExecutor(max_workers=3) as executor:  # ë™ì‹œ 3ê°œë¡œ ì œí•œ
            futures = []
            
            for keyword, category in target_keywords:
                future = executor.submit(self.search_keyword_data, keyword, category)
                futures.append(future)
            
            for future in as_completed(futures):
                try:
                    results = future.result()
                    all_results.extend(results)
                except Exception as e:
                    logger.error(f"ë°°ì¹˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        saved_count = 0
        for dream_data in all_results:
            if self.save_to_database(dream_data):
                saved_count += 1
        
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        # ê²°ê³¼ ë¦¬í¬íŠ¸
        result = {
            "collected": saved_count,
            "target": target_count,
            "elapsed_seconds": elapsed_time,
            "keywords_processed": len(target_keywords),
            "total_results": len(all_results),
            "success_rate": (saved_count / target_count * 100) if target_count > 0 else 0
        }
        
        logger.info(f"ğŸ“Š ë°°ì¹˜ ì™„ë£Œ: {saved_count}/{target_count}ê°œ ìˆ˜ì§‘ ({elapsed_time:.1f}ì´ˆ)")
        return result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = SmartKeywordCollector()
    
    # ë‹¨ì¼ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    logger.info("ğŸ¯ ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    result = collector.collect_batch(17)  # 5ë¶„ê°„ 17ê°œ ëª©í‘œ
    
    logger.info(f"ğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {result}")

if __name__ == "__main__":
    main()