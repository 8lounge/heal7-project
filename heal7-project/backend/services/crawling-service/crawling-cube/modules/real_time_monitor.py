#!/usr/bin/env python3
"""
âš¡ ì‹¤ì‹œê°„ í¬ë¡¤ë§ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸

Author: HEAL7 Development Team
Version: 1.0.0  
Date: 2025-08-29
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Set, Optional
from dataclasses import dataclass, asdict

import asyncpg
from fastapi import WebSocket, WebSocketDisconnect
from fastapi.routing import APIRouter


logger = logging.getLogger(__name__)


@dataclass
class MonitoringEvent:
    """ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸ ë°ì´í„° êµ¬ì¡°"""
    event_type: str  # 'collection_start', 'collection_complete', 'new_item', 'stats_update'
    portal_id: Optional[str] = None
    data: Dict = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()
        if self.data is None:
            self.data = {}


class RealTimeMonitor:
    """âš¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê´€ë¦¬ì"""
    
    def __init__(self, db_connection_string: str):
        self.db_connection_string = db_connection_string
        self.db_pool = None
        
        # WebSocket ì—°ê²° ê´€ë¦¬
        self.active_connections: Set[WebSocket] = set()
        self.connection_portals: Dict[WebSocket, List[str]] = {}  # í´ë¼ì´ì–¸íŠ¸ë³„ ê´€ì‹¬ í¬í„¸
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.stats_update_interval = 30  # 30ì´ˆë§ˆë‹¤ í†µê³„ ì—…ë°ì´íŠ¸
        self.is_monitoring = False
        
        # ìµœì‹  í†µê³„ ìºì‹œ
        self.latest_stats = {}
        self.latest_events = []
        self.max_events = 100
    
    async def initialize(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("âš¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        try:
            self.db_pool = await asyncpg.create_pool(
                self.db_connection_string,
                min_size=1,
                max_size=3,
                command_timeout=30
            )
            logger.info("âœ… ëª¨ë‹ˆí„°ë§ DB ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ DB ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        
        # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        asyncio.create_task(self.start_background_monitoring())
        
        logger.info("ğŸš€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
    
    async def close(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        self.is_monitoring = False
        
        # ëª¨ë“  WebSocket ì—°ê²° ì¢…ë£Œ
        for ws in self.active_connections.copy():
            try:
                await ws.close()
            except:
                pass
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
        if self.db_pool:
            await self.db_pool.close()
        
        logger.info("ğŸ›‘ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")
    
    async def connect_websocket(self, websocket: WebSocket, portal_filter: List[str] = None):
        """ìƒˆ WebSocket í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
        await websocket.accept()
        self.active_connections.add(websocket)
        
        if portal_filter:
            self.connection_portals[websocket] = portal_filter
            logger.info(f"ğŸ“¡ WebSocket ì—°ê²°: í¬í„¸ í•„í„° {portal_filter}")
        else:
            logger.info(f"ğŸ“¡ WebSocket ì—°ê²°: ì „ì²´ ëª¨ë‹ˆí„°ë§")
        
        # ì—°ê²° ì¦‰ì‹œ ìµœì‹  í†µê³„ ì „ì†¡
        if self.latest_stats:
            await self.send_to_client(websocket, {
                'type': 'initial_stats',
                'data': self.latest_stats,
                'timestamp': datetime.now().isoformat()
            })
        
        # ìµœê·¼ ì´ë²¤íŠ¸ ì „ì†¡
        recent_events = self.latest_events[-20:] if self.latest_events else []
        if recent_events:
            await self.send_to_client(websocket, {
                'type': 'recent_events',
                'data': {'events': recent_events},
                'timestamp': datetime.now().isoformat()
            })
    
    async def disconnect_websocket(self, websocket: WebSocket):
        """WebSocket í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ"""
        self.active_connections.discard(websocket)
        self.connection_portals.pop(websocket, None)
        logger.info("ğŸ“¡ WebSocket ì—°ê²° í•´ì œ")
    
    async def send_to_client(self, websocket: WebSocket, message: Dict):
        """ê°œë³„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            await websocket.send_json(message)
        except Exception as e:
            logger.debug(f"WebSocket ì „ì†¡ ì‹¤íŒ¨ (ì—°ê²° ëŠê¹€): {e}")
            await self.disconnect_websocket(websocket)
    
    async def broadcast_event(self, event: MonitoringEvent):
        """ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì´ë²¤íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not self.active_connections:
            return
        
        # ì´ë²¤íŠ¸ ê¸°ë¡
        self.latest_events.append(asdict(event))
        if len(self.latest_events) > self.max_events:
            self.latest_events = self.latest_events[-self.max_events:]
        
        message = {
            'type': 'live_event',
            'event': asdict(event)
        }
        
        # ëª¨ë“  í™œì„± ì—°ê²°ì— ì „ì†¡
        disconnected = set()
        for ws in self.active_connections:
            try:
                # í¬í„¸ í•„í„° í™•ì¸
                portal_filter = self.connection_portals.get(ws)
                if portal_filter and event.portal_id and event.portal_id not in portal_filter:
                    continue  # í•„í„°ì— ë§ì§€ ì•Šìœ¼ë©´ ì „ì†¡ ì•ˆí•¨
                
                await ws.send_json(message)
            except Exception as e:
                logger.debug(f"ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                disconnected.add(ws)
        
        # ëŠì–´ì§„ ì—°ê²° ì •ë¦¬
        for ws in disconnected:
            await self.disconnect_websocket(ws)
    
    async def start_background_monitoring(self):
        """ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        logger.info("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        self.is_monitoring = True
        
        while self.is_monitoring:
            try:
                # í†µê³„ ì—…ë°ì´íŠ¸
                await self.update_live_statistics()
                
                # ìƒˆë¡œìš´ ìˆ˜ì§‘ ë°ì´í„° í™•ì¸
                await self.check_new_collections()
                
                await asyncio.sleep(self.stats_update_interval)
                
            except Exception as e:
                logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)  # ì˜¤ë¥˜ ì‹œ ì ì‹œ ëŒ€ê¸°
    
    async def update_live_statistics(self):
        """ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸"""
        try:
            async with self.db_pool.acquire() as conn:
                # ì‹¤ì‹œê°„ í†µê³„ ì¿¼ë¦¬
                stats_query = """
                    SELECT 
                        portal_id,
                        COUNT(*) FILTER (WHERE scraped_at >= NOW() - INTERVAL '1 hour') as recent_hour,
                        COUNT(*) FILTER (WHERE scraped_at >= NOW() - INTERVAL '10 minutes') as recent_10min,
                        AVG(quality_score) FILTER (WHERE scraped_at >= NOW() - INTERVAL '1 hour') as recent_quality,
                        MAX(scraped_at) as last_activity
                    FROM raw_scraped_data
                    WHERE processing_status = 'completed'
                    GROUP BY portal_id
                """
                
                rows = await conn.fetch(stats_query)
                
                current_stats = {}
                for row in rows:
                    current_stats[row['portal_id']] = {
                        'recent_hour': int(row['recent_hour']),
                        'recent_10min': int(row['recent_10min']),
                        'recent_quality': round(float(row['recent_quality'] or 0), 1),
                        'last_activity': row['last_activity'].strftime('%Y-%m-%d %H:%M:%S') if row['last_activity'] else None
                    }
                
                # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ ë¸Œë¡œë“œìºìŠ¤íŠ¸
                if current_stats != self.latest_stats:
                    self.latest_stats = current_stats
                    
                    event = MonitoringEvent(
                        event_type='stats_update',
                        data={'stats': current_stats}
                    )
                    
                    await self.broadcast_event(event)
                
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def check_new_collections(self):
        """ìƒˆë¡œìš´ ìˆ˜ì§‘ ë°ì´í„° í™•ì¸"""
        try:
            async with self.db_pool.acquire() as conn:
                # ìµœê·¼ 5ë¶„ê°„ ìƒˆë¡œìš´ ë°ì´í„° í™•ì¸
                new_items_query = """
                    SELECT 
                        id, portal_id, title, agency, quality_score, scraped_at
                    FROM raw_scraped_data
                    WHERE scraped_at >= NOW() - INTERVAL '5 minutes'
                    AND processing_status = 'completed'
                    ORDER BY scraped_at DESC
                    LIMIT 10
                """
                
                rows = await conn.fetch(new_items_query)
                
                for row in rows:
                    # ê° ìƒˆ í•­ëª©ì— ëŒ€í•´ ì´ë²¤íŠ¸ ìƒì„±
                    event = MonitoringEvent(
                        event_type='new_item',
                        portal_id=row['portal_id'],
                        data={
                            'id': row['id'],
                            'title': row['title'],
                            'agency': row['agency'],
                            'quality_score': float(row['quality_score']),
                            'scraped_at': row['scraped_at'].strftime('%Y-%m-%d %H:%M:%S')
                        }
                    )
                    
                    await self.broadcast_event(event)
                
        except Exception as e:
            logger.error(f"âŒ ìƒˆ ìˆ˜ì§‘ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
    
    async def trigger_collection_event(self, portal_id: str, event_type: str, data: Dict = None):
        """ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” ìˆ˜ì§‘ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°"""
        event = MonitoringEvent(
            event_type=event_type,
            portal_id=portal_id,
            data=data or {}
        )
        
        await self.broadcast_event(event)
        logger.info(f"ğŸ”” ìˆ˜ì§‘ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°: {event_type} - {portal_id}")
    
    async def get_monitoring_summary(self) -> Dict:
        """ëª¨ë‹ˆí„°ë§ í˜„í™© ìš”ì•½"""
        return {
            'active_connections': len(self.active_connections),
            'portal_filters': {str(id(ws))[:8]: portals for ws, portals in self.connection_portals.items()},
            'monitoring_active': self.is_monitoring,
            'latest_stats': self.latest_stats,
            'recent_events_count': len(self.latest_events),
            'update_interval_seconds': self.stats_update_interval
        }


# FastAPI WebSocket ë¼ìš°í„° ì„¤ì •
monitor_router = APIRouter()

# ì „ì—­ ëª¨ë‹ˆí„°ë§ ì¸ìŠ¤í„´ìŠ¤
real_time_monitor: Optional[RealTimeMonitor] = None


async def initialize_monitor(db_connection_string: str):
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global real_time_monitor
    real_time_monitor = RealTimeMonitor(db_connection_string)
    await real_time_monitor.initialize()


@monitor_router.websocket("/ws/live-monitoring")
async def websocket_endpoint(
    websocket: WebSocket,
    portals: str = None  # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ í¬í„¸ í•„í„°
):
    """âš¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    if not real_time_monitor:
        await websocket.close(code=1003, reason="Monitoring system not initialized")
        return
    
    # í¬í„¸ í•„í„° íŒŒì‹±
    portal_filter = None
    if portals:
        portal_filter = [p.strip() for p in portals.split(',') if p.strip()]
    
    # ì—°ê²° ìˆ˜ë½
    await real_time_monitor.connect_websocket(websocket, portal_filter)
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹  (Keep-alive ë“±)
            try:
                message = await websocket.receive_text()
                data = json.loads(message)
                
                # Keep-alive ì‘ë‹µ
                if data.get('type') == 'ping':
                    await real_time_monitor.send_to_client(websocket, {
                        'type': 'pong',
                        'timestamp': datetime.now().isoformat()
                    })
                
                # í¬í„¸ í•„í„° ë³€ê²½
                elif data.get('type') == 'update_filter':
                    new_portals = data.get('portals', [])
                    real_time_monitor.connection_portals[websocket] = new_portals
                    logger.info(f"ğŸ“¡ í¬í„¸ í•„í„° ì—…ë°ì´íŠ¸: {new_portals}")
                    
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.debug(f"WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                break
    
    except WebSocketDisconnect:
        pass
    finally:
        await real_time_monitor.disconnect_websocket(websocket)


@monitor_router.get("/monitoring-summary")
async def get_monitoring_summary():
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í˜„í™© ì¡°íšŒ"""
    if not real_time_monitor:
        return {"error": "Monitoring system not initialized"}
    
    return await real_time_monitor.get_monitoring_summary()


@monitor_router.post("/trigger-event")
async def trigger_monitoring_event(
    event_type: str,
    portal_id: str,
    data: Dict = None
):
    """ì™¸ë¶€ì—ì„œ ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°"""
    if not real_time_monitor:
        return {"error": "Monitoring system not initialized"}
    
    await real_time_monitor.trigger_collection_event(event_type, portal_id, data)
    
    return {
        "success": True,
        "message": f"Event '{event_type}' triggered for portal '{portal_id}'"
    }


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

async def notify_collection_start(portal_id: str, max_pages: int):
    """ìˆ˜ì§‘ ì‹œì‘ ì•Œë¦¼"""
    if real_time_monitor:
        await real_time_monitor.trigger_collection_event(
            portal_id=portal_id,
            event_type='collection_start',
            data={'max_pages': max_pages}
        )


async def notify_collection_complete(portal_id: str, result_data: Dict):
    """ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼"""
    if real_time_monitor:
        await real_time_monitor.trigger_collection_event(
            portal_id=portal_id,
            event_type='collection_complete',
            data=result_data
        )


async def notify_new_item(portal_id: str, item_data: Dict):
    """ìƒˆ í•­ëª© ìˆ˜ì§‘ ì•Œë¦¼"""
    if real_time_monitor:
        await real_time_monitor.trigger_collection_event(
            portal_id=portal_id,
            event_type='new_item',
            data=item_data
        )


# ì˜ˆì œ: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì½”ë“œ
async def setup_real_time_monitoring():
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì˜ˆì œ"""
    db_connection = "postgresql://postgres:@localhost:5432/paperworkdb"
    
    try:
        await initialize_monitor(db_connection)
        logger.info("ğŸ¯ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
        return True
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    # ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    import uvicorn
    from fastapi import FastAPI
    
    app = FastAPI(title="Real-Time Monitoring Test")
    app.include_router(monitor_router, prefix="/monitor", tags=["real-time-monitoring"])
    
    @app.on_event("startup")
    async def startup():
        await setup_real_time_monitoring()
    
    uvicorn.run(app, host="0.0.0.0", port=8007)