# ğŸ§  Paperwork AI í•µì‹¬ ë¡œì§ ëª¨ë“ˆ

> **í”„ë¡œì íŠ¸**: AI ê¸°ë°˜ ë¬¸ì„œ í¸ì§‘ í”Œë«í¼ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§  
> **ë²„ì „**: v2.0.0  
> **ì‘ì„±ì¼**: 2025-08-19  
> **ëª©ì **: ì™„ì „í•œ êµ¬í˜„ì„ ìœ„í•œ ì›ì ë‹¨ìœ„ ëª¨ë“ˆ ì„¤ê³„

---

## ğŸ¯ **1. í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê°œìš”**

### **1.1 ë„ë©”ì¸ ëª¨ë¸ (Domain Model)**

#### **ì£¼ìš” ì—”í‹°í‹° ë° ê´€ê³„**
```mermaid
classDiagram
    class User {
        +UUID id
        +String email
        +String name
        +SubscriptionTier tier
        +int apiUsageCount
        +UserPreferences preferences
        +authenticate()
        +updateUsage()
        +checkLimits()
    }
    
    class Document {
        +UUID id
        +UUID userId
        +String filename
        +FileType type
        +int pageCount
        +ProcessingStatus status
        +validate()
        +updateStatus()
        +checkPageLimit()
    }
    
    class OCRResult {
        +UUID id
        +UUID documentId
        +int pageNumber
        +String extractedText
        +float confidence
        +combinePages()
        +validateQuality()
    }
    
    class AIProcessingJob {
        +UUID id
        +UUID documentId
        +AIModel model
        +JobType type
        +String inputText
        +String outputText
        +execute()
        +retry()
        +cancel()
    }
    
    class AIModel {
        +String name
        +String apiKey
        +ModelConfig config
        +processText()
        +validateInput()
        +handleError()
    }
    
    User ||--o{ Document : owns
    Document ||--o{ OCRResult : contains
    Document ||--o{ AIProcessingJob : processes
    AIProcessingJob }o--|| AIModel : uses
```

### **1.2 í•µì‹¬ ì›Œí¬í”Œë¡œìš° (Core Workflows)**

#### **ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**
```python
"""
Paperwork AI ë¬¸ì„œ ì²˜ë¦¬ í•µì‹¬ ì›Œí¬í”Œë¡œìš°
File: core/workflows/document_processing.py
"""

from typing import List, Optional, Dict, Any
from enum import Enum
import asyncio
from dataclasses import dataclass, field
from datetime import datetime
import uuid

class ProcessingStatus(Enum):
    UPLOADED = "uploaded"
    VALIDATING = "validating"
    CONVERTING = "converting"
    OCR_PROCESSING = "ocr_processing"
    OCR_COMPLETED = "ocr_completed"
    AI_PROCESSING = "ai_processing"
    AI_COMPLETED = "ai_completed"
    COMPLETED = "completed"
    FAILED = "failed"

class JobType(Enum):
    SUMMARIZE = "summarize"
    IMPROVE = "improve"
    EXPAND = "expand"
    TRANSLATE = "translate"

@dataclass
class DocumentMetadata:
    """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ëª¨ë¸"""
    file_size: int
    page_count: int
    file_type: str
    created_at: datetime = field(default_factory=datetime.utcnow)
    
    def validate(self) -> bool:
        """ë©”íƒ€ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        if self.file_size <= 0:
            raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        if self.page_count >= 10:  # 10í˜ì´ì§€ ì´ìƒ ê±°ë¶€
            raise ValueError(f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 10í˜ì´ì§€ ë¯¸ë§Œì˜ ë¬¸ì„œë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {self.page_count}í˜ì´ì§€)")
        
        if self.file_type not in ['pdf', 'doc', 'docx', 'jpg', 'png']:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {self.file_type}")
        
        return True

@dataclass
class DocumentProcessingContext:
    """ë¬¸ì„œ ì²˜ë¦¬ ì»¨í…ìŠ¤íŠ¸"""
    document_id: str
    user_id: str
    metadata: DocumentMetadata
    status: ProcessingStatus = ProcessingStatus.UPLOADED
    progress: float = 0.0
    error_message: Optional[str] = None
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)
    
    def update_status(self, new_status: ProcessingStatus, progress: float = None, error: str = None):
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.status = new_status
        if progress is not None:
            self.progress = progress
        if error:
            self.error_message = error
        self.updated_at = datetime.utcnow()

class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, 
                 file_validator: 'FileValidator',
                 pdf_converter: 'PDFConverter', 
                 ocr_service: 'OCRService',
                 ai_service: 'AIService',
                 storage_service: 'StorageService',
                 notification_service: 'NotificationService'):
        self.file_validator = file_validator
        self.pdf_converter = pdf_converter
        self.ocr_service = ocr_service
        self.ai_service = ai_service
        self.storage_service = storage_service
        self.notification_service = notification_service
    
    async def process_document(self, 
                             file_data: bytes, 
                             filename: str,
                             user_id: str) -> DocumentProcessingContext:
        """ì™„ì „í•œ ë¬¸ì„œ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""
        
        # 1. ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        document_id = str(uuid.uuid4())
        context = DocumentProcessingContext(
            document_id=document_id,
            user_id=user_id,
            metadata=DocumentMetadata(
                file_size=len(file_data),
                page_count=0,  # ì„ì‹œê°’, í›„ì— ì—…ë°ì´íŠ¸
                file_type=filename.split('.')[-1].lower()
            )
        )
        
        try:
            # 2. íŒŒì¼ ê²€ì¦
            await self._validate_file(context, file_data, filename)
            
            # 3. ì €ì¥ì†Œ ì—…ë¡œë“œ
            await self._upload_to_storage(context, file_data, filename)
            
            # 4. PDF ë³€í™˜ (í•„ìš”ì‹œ)
            await self._convert_to_pdf(context)
            
            # 5. ì´ë¯¸ì§€ ë³€í™˜
            await self._convert_to_images(context)
            
            # 6. OCR ì²˜ë¦¬
            await self._process_ocr(context)
            
            # 7. ì™„ë£Œ ì•Œë¦¼
            await self._notify_completion(context)
            
            return context
            
        except Exception as e:
            context.update_status(ProcessingStatus.FAILED, error=str(e))
            await self._notify_error(context, e)
            raise
    
    async def _validate_file(self, context: DocumentProcessingContext, 
                           file_data: bytes, filename: str):
        """1ë‹¨ê³„: íŒŒì¼ ê²€ì¦"""
        context.update_status(ProcessingStatus.VALIDATING, 5.0)
        
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì¦
        validation_result = await self.file_validator.validate(
            file_data, filename, context.metadata.file_type
        )
        
        if not validation_result.is_valid:
            raise ValueError(f"íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {validation_result.error_message}")
        
        # í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ ë° ê²€ì¦
        if context.metadata.file_type == 'pdf':
            page_count = await self.pdf_converter.get_page_count(file_data)
            context.metadata.page_count = page_count
            context.metadata.validate()  # í˜ì´ì§€ ìˆ˜ ì œí•œ ê²€ì¦
    
    async def _upload_to_storage(self, context: DocumentProcessingContext, 
                               file_data: bytes, filename: str):
        """2ë‹¨ê³„: ì €ì¥ì†Œ ì—…ë¡œë“œ"""
        context.update_status(ProcessingStatus.UPLOADING, 15.0)
        
        storage_path = f"documents/{context.user_id}/{context.document_id}/{filename}"
        await self.storage_service.upload(storage_path, file_data)
        
        # ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥ ê²½ë¡œ ì¶”ê°€
        context.storage_path = storage_path
    
    async def _convert_to_pdf(self, context: DocumentProcessingContext):
        """3ë‹¨ê³„: PDF ë³€í™˜ (Word ë¬¸ì„œ ë“±)"""
        if context.metadata.file_type in ['doc', 'docx']:
            context.update_status(ProcessingStatus.CONVERTING, 25.0)
            
            # Word ë¬¸ì„œë¥¼ PDFë¡œ ë³€í™˜
            file_data = await self.storage_service.download(context.storage_path)
            pdf_data = await self.pdf_converter.convert_to_pdf(file_data, context.metadata.file_type)
            
            # ë³€í™˜ëœ PDF ì €ì¥
            pdf_path = context.storage_path.replace('.docx', '.pdf').replace('.doc', '.pdf')
            await self.storage_service.upload(pdf_path, pdf_data)
            context.storage_path = pdf_path
            context.metadata.file_type = 'pdf'
    
    async def _convert_to_images(self, context: DocumentProcessingContext):
        """4ë‹¨ê³„: ì´ë¯¸ì§€ ë³€í™˜"""
        context.update_status(ProcessingStatus.CONVERTING, 40.0)
        
        if context.metadata.file_type == 'pdf':
            # PDFë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            file_data = await self.storage_service.download(context.storage_path)
            images = await self.pdf_converter.convert_to_images(
                file_data, 
                dpi=300,  # ê³ í•´ìƒë„
                format='png'
            )
            
            # ì´ë¯¸ì§€ë“¤ì„ ì €ì¥
            image_paths = []
            for i, image_data in enumerate(images):
                image_path = f"images/{context.document_id}/page_{i+1}.png"
                await self.storage_service.upload(image_path, image_data)
                image_paths.append(image_path)
            
            context.image_paths = image_paths
        elif context.metadata.file_type in ['jpg', 'png']:
            # ì´ë¯¸ ì´ë¯¸ì§€ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            context.image_paths = [context.storage_path]
    
    async def _process_ocr(self, context: DocumentProcessingContext):
        """5ë‹¨ê³„: OCR ì²˜ë¦¬"""
        context.update_status(ProcessingStatus.OCR_PROCESSING, 60.0)
        
        ocr_results = []
        total_images = len(context.image_paths)
        
        for i, image_path in enumerate(context.image_paths):
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 60.0 + (30.0 * (i + 1) / total_images)
            context.update_status(ProcessingStatus.OCR_PROCESSING, progress)
            
            # OCR ì‹¤í–‰
            image_data = await self.storage_service.download(image_path)
            ocr_result = await self.ocr_service.extract_text(
                image_data, 
                page_number=i+1,
                document_id=context.document_id
            )
            ocr_results.append(ocr_result)
        
        context.ocr_results = ocr_results
        context.update_status(ProcessingStatus.OCR_COMPLETED, 90.0)
    
    async def _notify_completion(self, context: DocumentProcessingContext):
        """6ë‹¨ê³„: ì™„ë£Œ ì•Œë¦¼"""
        context.update_status(ProcessingStatus.COMPLETED, 100.0)
        
        await self.notification_service.notify_user(
            user_id=context.user_id,
            message="ë¬¸ì„œ ì—…ë¡œë“œ ë° OCR ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            document_id=context.document_id
        )
    
    async def _notify_error(self, context: DocumentProcessingContext, error: Exception):
        """ì˜¤ë¥˜ ì•Œë¦¼"""
        await self.notification_service.notify_error(
            user_id=context.user_id,
            error_message=str(error),
            document_id=context.document_id
        )
```

---

## ğŸ”§ **2. íŒŒì¼ ì²˜ë¦¬ ëª¨ë“ˆ**

### **2.1 íŒŒì¼ ê²€ì¦ ì„œë¹„ìŠ¤**

```python
"""
íŒŒì¼ ê²€ì¦ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì„œë¹„ìŠ¤
File: core/services/file_validation.py
"""

from typing import Dict, List, Optional, NamedTuple
import magic
import fitz  # PyMuPDF
from PIL import Image
import io
import hashlib

class ValidationResult(NamedTuple):
    is_valid: bool
    error_message: Optional[str] = None
    metadata: Optional[Dict] = None

class FileValidator:
    """íŒŒì¼ ê²€ì¦ ì„œë¹„ìŠ¤"""
    
    # ì§€ì› íŒŒì¼ í˜•ì‹ ë° MIME íƒ€ì…
    SUPPORTED_FORMATS = {
        'pdf': ['application/pdf'],
        'doc': ['application/msword'],
        'docx': ['application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
        'jpg': ['image/jpeg'],
        'png': ['image/png']
    }
    
    # íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
    MAX_FILE_SIZE = 10 * 1024 * 1024
    
    # í˜ì´ì§€ ìˆ˜ ì œí•œ (10í˜ì´ì§€ ë¯¸ë§Œë§Œ í—ˆìš©)
    MAX_PAGES = 9
    
    def __init__(self):
        self.magic_mime = magic.Magic(mime=True)
    
    async def validate(self, file_data: bytes, filename: str, expected_type: str) -> ValidationResult:
        """ì¢…í•©ì ì¸ íŒŒì¼ ê²€ì¦"""
        
        try:
            # 1. ê¸°ë³¸ ê²€ì¦
            basic_validation = self._validate_basic(file_data, filename)
            if not basic_validation.is_valid:
                return basic_validation
            
            # 2. MIME íƒ€ì… ê²€ì¦
            mime_validation = self._validate_mime_type(file_data, expected_type)
            if not mime_validation.is_valid:
                return mime_validation
            
            # 3. í˜•ì‹ë³„ ìƒì„¸ ê²€ì¦
            format_validation = await self._validate_format_specific(file_data, expected_type)
            if not format_validation.is_valid:
                return format_validation
            
            # 4. ë³´ì•ˆ ê²€ì¦
            security_validation = self._validate_security(file_data, expected_type)
            if not security_validation.is_valid:
                return security_validation
            
            # 5. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = await self._extract_metadata(file_data, expected_type)
            
            return ValidationResult(
                is_valid=True,
                metadata=metadata
            )
            
        except Exception as e:
            return ValidationResult(
                is_valid=False,
                error_message=f"íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def _validate_basic(self, file_data: bytes, filename: str) -> ValidationResult:
        """ê¸°ë³¸ ê²€ì¦ (í¬ê¸°, ì´ë¦„ ë“±)"""
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if len(file_data) == 0:
            return ValidationResult(False, "ë¹ˆ íŒŒì¼ì€ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if len(file_data) > self.MAX_FILE_SIZE:
            size_mb = len(file_data) / (1024 * 1024)
            return ValidationResult(
                False, 
                f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 10MBê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. (í˜„ì¬: {size_mb:.1f}MB)"
            )
        
        # íŒŒì¼ëª… ê²€ì¦
        if not filename or len(filename.strip()) == 0:
            return ValidationResult(False, "ìœ íš¨í•œ íŒŒì¼ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if len(filename) > 255:
            return ValidationResult(False, "íŒŒì¼ëª…ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ 255ì)")
        
        # í™•ì¥ì ê²€ì¦
        if '.' not in filename:
            return ValidationResult(False, "íŒŒì¼ í™•ì¥ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        extension = filename.split('.')[-1].lower()
        if extension not in self.SUPPORTED_FORMATS:
            supported = ", ".join(self.SUPPORTED_FORMATS.keys())
            return ValidationResult(
                False, 
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {supported}"
            )
        
        return ValidationResult(True)
    
    def _validate_mime_type(self, file_data: bytes, expected_type: str) -> ValidationResult:
        """MIME íƒ€ì… ê²€ì¦"""
        
        try:
            detected_mime = self.magic_mime.from_buffer(file_data)
            expected_mimes = self.SUPPORTED_FORMATS.get(expected_type, [])
            
            if detected_mime not in expected_mimes:
                return ValidationResult(
                    False,
                    f"íŒŒì¼ í˜•ì‹ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: {expected_type}, ì‹¤ì œ: {detected_mime}"
                )
            
            return ValidationResult(True)
            
        except Exception as e:
            return ValidationResult(
                False,
                f"MIME íƒ€ì… ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            )
    
    async def _validate_format_specific(self, file_data: bytes, file_type: str) -> ValidationResult:
        """í˜•ì‹ë³„ ìƒì„¸ ê²€ì¦"""
        
        try:
            if file_type == 'pdf':
                return await self._validate_pdf(file_data)
            elif file_type in ['jpg', 'png']:
                return await self._validate_image(file_data)
            elif file_type in ['doc', 'docx']:
                return await self._validate_word(file_data)
            else:
                return ValidationResult(True)
                
        except Exception as e:
            return ValidationResult(
                False,
                f"{file_type.upper()} íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            )
    
    async def _validate_pdf(self, file_data: bytes) -> ValidationResult:
        """PDF íŒŒì¼ ê²€ì¦"""
        
        try:
            doc = fitz.open(stream=file_data, filetype="pdf")
            
            # í˜ì´ì§€ ìˆ˜ ê²€ì¦
            page_count = doc.page_count
            if page_count >= 10:  # 10í˜ì´ì§€ ì´ìƒ ê±°ë¶€
                doc.close()
                return ValidationResult(
                    False,
                    f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 10í˜ì´ì§€ ë¯¸ë§Œì˜ ë¬¸ì„œë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í˜„ì¬: {page_count}í˜ì´ì§€)"
                )
            
            # PDF ì†ìƒ ê²€ì¦
            for page_num in range(page_count):
                try:
                    page = doc[page_num]
                    # í˜ì´ì§€ ë Œë”ë§ í…ŒìŠ¤íŠ¸
                    pix = page.get_pixmap(matrix=fitz.Matrix(0.1, 0.1))  # ì‘ì€ í•´ìƒë„ë¡œ í…ŒìŠ¤íŠ¸
                    pix = None  # ë©”ëª¨ë¦¬ í•´ì œ
                except Exception:
                    doc.close()
                    return ValidationResult(
                        False,
                        f"PDF íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. (í˜ì´ì§€ {page_num + 1})"
                    )
            
            # ì•”í˜¸í™” ê²€ì¦
            if doc.needs_pass:
                doc.close()
                return ValidationResult(
                    False,
                    "ì•”í˜¸í™”ëœ PDF íŒŒì¼ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )
            
            doc.close()
            return ValidationResult(True)
            
        except Exception as e:
            return ValidationResult(
                False,
                f"PDF íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def _validate_image(self, file_data: bytes) -> ValidationResult:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦"""
        
        try:
            image = Image.open(io.BytesIO(file_data))
            
            # ì´ë¯¸ì§€ ê¸°ë³¸ ì •ë³´ í™•ì¸
            width, height = image.size
            
            # ìµœì†Œ í¬ê¸° ê²€ì¦
            if width < 100 or height < 100:
                return ValidationResult(
                    False,
                    f"ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. ìµœì†Œ 100x100px ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {width}x{height}px)"
                )
            
            # ìµœëŒ€ í¬ê¸° ê²€ì¦ (OCR ì²˜ë¦¬ ê³ ë ¤)
            if width > 5000 or height > 5000:
                return ValidationResult(
                    False,
                    f"ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 5000x5000pxê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. (í˜„ì¬: {width}x{height}px)"
                )
            
            # ì´ë¯¸ì§€ ì†ìƒ ê²€ì¦
            try:
                image.verify()
            except Exception:
                return ValidationResult(
                    False,
                    "ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤."
                )
            
            return ValidationResult(True)
            
        except Exception as e:
            return ValidationResult(
                False,
                f"ì´ë¯¸ì§€ íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def _validate_word(self, file_data: bytes) -> ValidationResult:
        """Word ë¬¸ì„œ ê²€ì¦"""
        
        try:
            # python-docxë¥¼ ì‚¬ìš©í•œ Word ë¬¸ì„œ ê²€ì¦
            from docx import Document
            
            doc = Document(io.BytesIO(file_data))
            
            # ë¬¸ì„œ êµ¬ì¡° ê¸°ë³¸ ê²€ì¦
            paragraph_count = len(doc.paragraphs)
            if paragraph_count == 0:
                return ValidationResult(
                    False,
                    "ë¹ˆ Word ë¬¸ì„œì…ë‹ˆë‹¤."
                )
            
            # ëŒ€ëµì ì¸ í˜ì´ì§€ ìˆ˜ ì¶”ì • (ë‹¨ë½ ìˆ˜ ê¸°ë°˜)
            estimated_pages = max(1, paragraph_count // 10)  # ë‹¨ë½ 10ê°œë‹¹ 1í˜ì´ì§€ë¡œ ì¶”ì •
            if estimated_pages >= 10:
                return ValidationResult(
                    False,
                    f"ë¬¸ì„œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì˜ˆìƒ í˜ì´ì§€ ìˆ˜: {estimated_pages}í˜ì´ì§€ (10í˜ì´ì§€ ë¯¸ë§Œë§Œ í—ˆìš©)"
                )
            
            return ValidationResult(True)
            
        except Exception as e:
            return ValidationResult(
                False,
                f"Word ë¬¸ì„œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    def _validate_security(self, file_data: bytes, file_type: str) -> ValidationResult:
        """ë³´ì•ˆ ê²€ì¦ (ë°”ì´ëŸ¬ìŠ¤, ì•…ì„±ì½”ë“œ ë“±)"""
        
        try:
            # íŒŒì¼ í•´ì‹œ ìƒì„±
            file_hash = hashlib.sha256(file_data).hexdigest()
            
            # ì•…ì„± íŒŒì¼ íŒ¨í„´ ê²€ì‚¬ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            suspicious_patterns = [
                b'<script',
                b'javascript:',
                b'vbscript:',
                b'onload=',
                b'onerror='
            ]
            
            for pattern in suspicious_patterns:
                if pattern in file_data.lower():
                    return ValidationResult(
                        False,
                        "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì½˜í…ì¸ ê°€ í¬í•¨ëœ íŒŒì¼ì…ë‹ˆë‹¤."
                    )
            
            # TODO: ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” VirusTotal API ë“±ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì¦
            
            return ValidationResult(True)
            
        except Exception as e:
            return ValidationResult(
                False,
                f"ë³´ì•ˆ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            )
    
    async def _extract_metadata(self, file_data: bytes, file_type: str) -> Dict:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        metadata = {
            'file_size': len(file_data),
            'file_type': file_type,
            'file_hash': hashlib.sha256(file_data).hexdigest()
        }
        
        try:
            if file_type == 'pdf':
                doc = fitz.open(stream=file_data, filetype="pdf")
                metadata.update({
                    'page_count': doc.page_count,
                    'title': doc.metadata.get('title', ''),
                    'author': doc.metadata.get('author', ''),
                    'subject': doc.metadata.get('subject', ''),
                    'creator': doc.metadata.get('creator', ''),
                    'producer': doc.metadata.get('producer', ''),
                    'creation_date': doc.metadata.get('creationDate', ''),
                    'modification_date': doc.metadata.get('modDate', '')
                })
                doc.close()
                
            elif file_type in ['jpg', 'png']:
                image = Image.open(io.BytesIO(file_data))
                metadata.update({
                    'width': image.size[0],
                    'height': image.size[1],
                    'mode': image.mode,
                    'format': image.format
                })
                
                # EXIF ë°ì´í„° ì¶”ì¶œ (JPEGë§Œ)
                if hasattr(image, '_getexif') and image._getexif():
                    exif = image._getexif()
                    metadata['exif'] = {k: str(v) for k, v in exif.items() if isinstance(v, (str, int, float))}
                
            elif file_type in ['doc', 'docx']:
                from docx import Document
                doc = Document(io.BytesIO(file_data))
                
                metadata.update({
                    'paragraph_count': len(doc.paragraphs),
                    'estimated_pages': max(1, len(doc.paragraphs) // 10)
                })
                
                # ë¬¸ì„œ ì†ì„± ì¶”ì¶œ
                props = doc.core_properties
                if props:
                    metadata.update({
                        'title': props.title or '',
                        'author': props.author or '',
                        'subject': props.subject or '',
                        'created': props.created.isoformat() if props.created else '',
                        'modified': props.modified.isoformat() if props.modified else ''
                    })
            
        except Exception as e:
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
            metadata['metadata_extraction_error'] = str(e)
        
        return metadata
```

### **2.2 PDF ë³€í™˜ ì„œë¹„ìŠ¤**

```python
"""
PDF ë³€í™˜ ë° ì´ë¯¸ì§€ ì¶”ì¶œ ì„œë¹„ìŠ¤
File: core/services/pdf_conversion.py
"""

from typing import List, Tuple, Optional
import fitz  # PyMuPDF
from PIL import Image
import io
import tempfile
import os
from pathlib import Path

class PDFConverter:
    """PDF ë³€í™˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.temp_dir = tempfile.gettempdir()
    
    async def get_page_count(self, pdf_data: bytes) -> int:
        """PDF í˜ì´ì§€ ìˆ˜ ë°˜í™˜"""
        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
            page_count = doc.page_count
            doc.close()
            return page_count
        except Exception as e:
            raise ValueError(f"PDF í˜ì´ì§€ ìˆ˜ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
    
    async def convert_to_images(self, 
                              pdf_data: bytes, 
                              dpi: int = 300,
                              format: str = 'PNG') -> List[bytes]:
        """PDFë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        
        images = []
        doc = None
        
        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
            
            # ìŠ¤ì¼€ì¼ë§ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚° (DPI ê¸°ë°˜)
            zoom = dpi / 72.0  # 72 DPIê°€ ê¸°ë³¸ê°’
            matrix = fitz.Matrix(zoom, zoom)
            
            for page_num in range(doc.page_count):
                page = doc[page_num]
                
                # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë Œë”ë§
                pix = page.get_pixmap(matrix=matrix, alpha=False)
                
                # PIL Imageë¡œ ë³€í™˜
                img_data = pix.tobytes(format.lower())
                pil_image = Image.frombytes("RGB", [pix.width, pix.height], img_data)
                
                # ì´ë¯¸ì§€ í›„ì²˜ë¦¬ (OCR ìµœì í™”)
                processed_image = await self._optimize_for_ocr(pil_image)
                
                # ë°”ì´íŠ¸ë¡œ ë³€í™˜
                img_buffer = io.BytesIO()
                processed_image.save(img_buffer, format=format, quality=95, optimize=True)
                images.append(img_buffer.getvalue())
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                pix = None
                img_buffer.close()
            
            return images
            
        except Exception as e:
            raise ValueError(f"PDF ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        finally:
            if doc:
                doc.close()
    
    async def _optimize_for_ocr(self, image: Image.Image) -> Image.Image:
        """OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ìµœì í™”"""
        
        try:
            # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.mode != 'L':
                image = image.convert('L')
            
            # 2. ëŒ€ë¹„ í–¥ìƒ
            from PIL import ImageEnhance
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.2)  # ëŒ€ë¹„ 20% í–¥ìƒ
            
            # 3. ì„ ëª…ë„ í–¥ìƒ
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.1)  # ì„ ëª…ë„ 10% í–¥ìƒ
            
            # 4. ë…¸ì´ì¦ˆ ì œê±° (ê°„ë‹¨í•œ ë¯¸ë””ì•ˆ í•„í„°)
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” OpenCV ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë” ì •êµí•œ ì²˜ë¦¬
            
            return image
            
        except Exception as e:
            # ìµœì í™” ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return image
    
    async def convert_to_pdf(self, file_data: bytes, source_format: str) -> bytes:
        """ë‹¤ë¥¸ í˜•ì‹ì„ PDFë¡œ ë³€í™˜"""
        
        try:
            if source_format in ['doc', 'docx']:
                return await self._convert_word_to_pdf(file_data)
            elif source_format in ['jpg', 'png']:
                return await self._convert_image_to_pdf(file_data)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë³€í™˜ í˜•ì‹: {source_format}")
                
        except Exception as e:
            raise ValueError(f"PDF ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    async def _convert_word_to_pdf(self, word_data: bytes) -> bytes:
        """Word ë¬¸ì„œë¥¼ PDFë¡œ ë³€í™˜"""
        
        try:
            # python-docxì™€ reportlabì„ ì‚¬ìš©í•œ ë³€í™˜
            from docx import Document
            from reportlab.pdfgen import canvas
            from reportlab.lib.pagesizes import letter
            from reportlab.lib.styles import getSampleStyleSheet
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
            
            # Word ë¬¸ì„œ ì½ê¸°
            doc = Document(io.BytesIO(word_data))
            
            # PDF ìƒì„±
            pdf_buffer = io.BytesIO()
            pdf_doc = SimpleDocTemplate(pdf_buffer, pagesize=letter)
            story = []
            styles = getSampleStyleSheet()
            
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    para = Paragraph(paragraph.text, styles['Normal'])
                    story.append(para)
                    story.append(Spacer(1, 12))
            
            pdf_doc.build(story)
            return pdf_buffer.getvalue()
            
        except Exception as e:
            raise ValueError(f"Word to PDF ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    async def _convert_image_to_pdf(self, image_data: bytes) -> bytes:
        """ì´ë¯¸ì§€ë¥¼ PDFë¡œ ë³€í™˜"""
        
        try:
            image = Image.open(io.BytesIO(image_data))
            
            # PDF ìƒì„±
            pdf_buffer = io.BytesIO()
            
            # RGB ëª¨ë“œë¡œ ë³€í™˜ (PDF í˜¸í™˜ì„±)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # PDFë¡œ ì €ì¥
            image.save(pdf_buffer, format='PDF', quality=95, optimize=True)
            
            return pdf_buffer.getvalue()
            
        except Exception as e:
            raise ValueError(f"Image to PDF ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    async def extract_text_direct(self, pdf_data: bytes) -> List[str]:
        """PDFì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR ë³´ì™„ìš©)"""
        
        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
            texts = []
            
            for page_num in range(doc.page_count):
                page = doc[page_num]
                text = page.get_text()
                texts.append(text.strip())
            
            doc.close()
            return texts
            
        except Exception as e:
            raise ValueError(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    async def get_pdf_info(self, pdf_data: bytes) -> dict:
        """PDF ì •ë³´ ì¶”ì¶œ"""
        
        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
            
            info = {
                'page_count': doc.page_count,
                'metadata': doc.metadata,
                'is_encrypted': doc.needs_pass,
                'is_pdf_a': doc.is_pdf,
                'pages_info': []
            }
            
            # ê° í˜ì´ì§€ ì •ë³´
            for page_num in range(doc.page_count):
                page = doc[page_num]
                page_info = {
                    'page_number': page_num + 1,
                    'width': page.rect.width,
                    'height': page.rect.height,
                    'rotation': page.rotation,
                    'has_images': len(page.get_images()) > 0,
                    'text_length': len(page.get_text())
                }
                info['pages_info'].append(page_info)
            
            doc.close()
            return info
            
        except Exception as e:
            raise ValueError(f"PDF ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
```

---

## ğŸ‘ï¸ **3. OCR ì²˜ë¦¬ ëª¨ë“ˆ**

### **3.1 í†µí•© OCR ì„œë¹„ìŠ¤**

```python
"""
í†µí•© OCR ì²˜ë¦¬ ì„œë¹„ìŠ¤
File: core/services/ocr_service.py
"""

from typing import List, Optional, Dict, Any, NamedTuple
from enum import Enum
import asyncio
import base64
import json
import time
from dataclasses import dataclass
from abc import ABC, abstractmethod

class OCREngine(Enum):
    TESSERACT = "tesseract"
    GOOGLE_VISION = "google_vision"
    AZURE_COGNITIVE = "azure_cognitive"
    AWS_TEXTRACT = "aws_textract"

class OCRQuality(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    ULTRA = "ultra"

@dataclass
class OCRResult:
    """OCR ê²°ê³¼ ëª¨ë¸"""
    document_id: str
    page_number: int
    extracted_text: str
    confidence_score: float
    processing_time_ms: int
    engine_used: OCREngine
    bounding_boxes: Optional[List[Dict]] = None
    language_detected: Optional[str] = None
    error_message: Optional[str] = None

class BaseOCREngine(ABC):
    """OCR ì—”ì§„ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def extract_text(self, 
                          image_data: bytes, 
                          language: str = 'kor+eng',
                          quality: OCRQuality = OCRQuality.HIGH) -> OCRResult:
        pass
    
    @abstractmethod
    def get_engine_name(self) -> OCREngine:
        pass

class TesseractEngine(BaseOCREngine):
    """Tesseract OCR ì—”ì§„"""
    
    def __init__(self):
        import pytesseract
        from PIL import Image
        self.pytesseract = pytesseract
        self.Image = Image
    
    def get_engine_name(self) -> OCREngine:
        return OCREngine.TESSERACT
    
    async def extract_text(self, 
                          image_data: bytes, 
                          language: str = 'kor+eng',
                          quality: OCRQuality = OCRQuality.HIGH) -> OCRResult:
        
        start_time = time.time()
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image = self.Image.open(io.BytesIO(image_data))
            processed_image = await self._preprocess_image(image, quality)
            
            # OCR ì„¤ì •
            config = self._get_tesseract_config(quality)
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = self.pytesseract.image_to_string(
                processed_image, 
                lang=language,
                config=config
            )
            
            # ì‹ ë¢°ë„ ì¶”ì¶œ
            confidence_data = self.pytesseract.image_to_data(
                processed_image, 
                lang=language,
                config=config,
                output_type=self.pytesseract.Output.DICT
            )
            
            # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
            confidences = [int(conf) for conf in confidence_data['conf'] if int(conf) > 0]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´
            bounding_boxes = self._extract_bounding_boxes(confidence_data)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return OCRResult(
                document_id="",  # í˜¸ì¶œìì—ì„œ ì„¤ì •
                page_number=0,   # í˜¸ì¶œìì—ì„œ ì„¤ì •
                extracted_text=extracted_text.strip(),
                confidence_score=avg_confidence / 100.0,  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
                processing_time_ms=processing_time,
                engine_used=self.get_engine_name(),
                bounding_boxes=bounding_boxes
            )
            
        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            return OCRResult(
                document_id="",
                page_number=0,
                extracted_text="",
                confidence_score=0.0,
                processing_time_ms=processing_time,
                engine_used=self.get_engine_name(),
                error_message=f"Tesseract OCR ì‹¤íŒ¨: {str(e)}"
            )
    
    async def _preprocess_image(self, image: 'Image.Image', quality: OCRQuality) -> 'Image.Image':
        """OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if image.mode != 'L':
                image = image.convert('L')
            
            if quality in [OCRQuality.HIGH, OCRQuality.ULTRA]:
                # ê³ í’ˆì§ˆ ì „ì²˜ë¦¬
                from PIL import ImageEnhance, ImageFilter
                
                # ëŒ€ë¹„ í–¥ìƒ
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(1.5)
                
                # ì„ ëª…ë„ í–¥ìƒ
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(1.2)
                
                if quality == OCRQuality.ULTRA:
                    # ë…¸ì´ì¦ˆ ì œê±°
                    image = image.filter(ImageFilter.MedianFilter(size=3))
            
            return image
            
        except Exception:
            # ì „ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return image
    
    def _get_tesseract_config(self, quality: OCRQuality) -> str:
        """í’ˆì§ˆë³„ Tesseract ì„¤ì •"""
        
        base_config = '--oem 3 --psm 6'  # LSTM + ë‹¨ì¼ ë¸”ë¡ í…ìŠ¤íŠ¸
        
        if quality == OCRQuality.LOW:
            return f"{base_config} -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZê°€-í£"
        elif quality == OCRQuality.MEDIUM:
            return f"{base_config} -c preserve_interword_spaces=1"
        elif quality == OCRQuality.HIGH:
            return f"{base_config} -c preserve_interword_spaces=1 -c tessedit_do_invert=0"
        else:  # ULTRA
            return f"{base_config} -c preserve_interword_spaces=1 -c tessedit_do_invert=0 -c classify_bln_numeric_mode=0"
    
    def _extract_bounding_boxes(self, data: Dict) -> List[Dict]:
        """ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        
        boxes = []
        n_boxes = len(data['level'])
        
        for i in range(n_boxes):
            if int(data['conf'][i]) > 0:  # ì‹ ë¢°ë„ê°€ ìˆëŠ” í•­ëª©ë§Œ
                box = {
                    'text': data['text'][i],
                    'confidence': int(data['conf'][i]),
                    'left': int(data['left'][i]),
                    'top': int(data['top'][i]),
                    'width': int(data['width'][i]),
                    'height': int(data['height'][i])
                }
                boxes.append(box)
        
        return boxes

class GoogleVisionEngine(BaseOCREngine):
    """Google Cloud Vision OCR ì—”ì§„"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """Google Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            from google.cloud import vision
            import os
            
            # API í‚¤ ì„¤ì •
            if self.api_key:
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = self.api_key
            
            self.client = vision.ImageAnnotatorClient()
        except Exception as e:
            raise ValueError(f"Google Vision API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def get_engine_name(self) -> OCREngine:
        return OCREngine.GOOGLE_VISION
    
    async def extract_text(self, 
                          image_data: bytes, 
                          language: str = 'ko+en',
                          quality: OCRQuality = OCRQuality.HIGH) -> OCRResult:
        
        start_time = time.time()
        
        try:
            from google.cloud import vision
            
            # ì´ë¯¸ì§€ ê°ì²´ ìƒì„±
            image = vision.Image(content=image_data)
            
            # ì–¸ì–´ íŒíŠ¸ ì„¤ì •
            language_hints = ['ko', 'en'] if language == 'ko+en' else [language]
            image_context = vision.ImageContext(language_hints=language_hints)
            
            # í…ìŠ¤íŠ¸ ê°ì§€ ì‹¤í–‰
            response = self.client.text_detection(
                image=image,
                image_context=image_context
            )
            
            if response.error.message:
                raise Exception(response.error.message)
            
            # ê²°ê³¼ ì²˜ë¦¬
            texts = response.text_annotations
            
            if not texts:
                extracted_text = ""
                confidence = 0.0
                bounding_boxes = []
            else:
                # ì²« ë²ˆì§¸ annotationì´ ì „ì²´ í…ìŠ¤íŠ¸
                extracted_text = texts[0].description
                
                # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° (Google Visionì€ confidenceë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ)
                # ëŒ€ì‹  detectionì˜ ê°œìˆ˜ì™€ í’ˆì§ˆë¡œ ì¶”ì •
                confidence = min(0.95, 0.5 + (len(texts) * 0.05))
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                bounding_boxes = []
                for text in texts[1:]:  # ì²« ë²ˆì§¸ ì œì™¸ (ì „ì²´ í…ìŠ¤íŠ¸)
                    vertices = text.bounding_poly.vertices
                    box = {
                        'text': text.description,
                        'confidence': int(confidence * 100),
                        'left': min(v.x for v in vertices),
                        'top': min(v.y for v in vertices),
                        'width': max(v.x for v in vertices) - min(v.x for v in vertices),
                        'height': max(v.y for v in vertices) - min(v.y for v in vertices)
                    }
                    bounding_boxes.append(box)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return OCRResult(
                document_id="",
                page_number=0,
                extracted_text=extracted_text.strip(),
                confidence_score=confidence,
                processing_time_ms=processing_time,
                engine_used=self.get_engine_name(),
                bounding_boxes=bounding_boxes,
                language_detected=language
            )
            
        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            return OCRResult(
                document_id="",
                page_number=0,
                extracted_text="",
                confidence_score=0.0,
                processing_time_ms=processing_time,
                engine_used=self.get_engine_name(),
                error_message=f"Google Vision OCR ì‹¤íŒ¨: {str(e)}"
            )

class OCRService:
    """í†µí•© OCR ì„œë¹„ìŠ¤"""
    
    def __init__(self, 
                 primary_engine: BaseOCREngine,
                 fallback_engines: List[BaseOCREngine] = None):
        self.primary_engine = primary_engine
        self.fallback_engines = fallback_engines or []
        self.min_confidence_threshold = 0.7
    
    async def extract_text(self, 
                          image_data: bytes,
                          page_number: int,
                          document_id: str,
                          language: str = 'kor+eng',
                          quality: OCRQuality = OCRQuality.HIGH) -> OCRResult:
        """ë©”ì¸ OCR ì²˜ë¦¬ ë©”ì„œë“œ"""
        
        # 1ì°¨: ê¸°ë³¸ ì—”ì§„ ì‹œë„
        result = await self.primary_engine.extract_text(image_data, language, quality)
        result.document_id = document_id
        result.page_number = page_number
        
        # ê²°ê³¼ê°€ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šìœ¼ë©´ í´ë°± ì—”ì§„ë“¤ ì‹œë„
        if (result.confidence_score < self.min_confidence_threshold or 
            result.error_message or 
            len(result.extracted_text.strip()) < 10):
            
            for fallback_engine in self.fallback_engines:
                try:
                    fallback_result = await fallback_engine.extract_text(image_data, language, quality)
                    fallback_result.document_id = document_id
                    fallback_result.page_number = page_number
                    
                    # ë” ì¢‹ì€ ê²°ê³¼ì¸ì§€ í™•ì¸
                    if (fallback_result.confidence_score > result.confidence_score and
                        not fallback_result.error_message):
                        result = fallback_result
                        break
                        
                except Exception:
                    continue
        
        # í›„ì²˜ë¦¬
        result.extracted_text = await self._post_process_text(result.extracted_text)
        
        return result
    
    async def _post_process_text(self, text: str) -> str:
        """OCR ê²°ê³¼ í›„ì²˜ë¦¬"""
        
        if not text:
            return text
        
        # 1. ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        
        # 2. ì—°ì†ëœ ê³µë°± ì •ë¦¬
        import re
        text = re.sub(r'\s+', ' ', text)
        
        # 3. í•œê¸€-ì˜ì–´ ì‚¬ì´ ê³µë°± ì •ë¦¬
        text = re.sub(r'([ê°€-í£])\s+([a-zA-Z])', r'\1 \2', text)
        text = re.sub(r'([a-zA-Z])\s+([ê°€-í£])', r'\1 \2', text)
        
        # 4. ìˆ«ì ì£¼ë³€ ê³µë°± ì •ë¦¬
        text = re.sub(r'(\d)\s+([ê°€-í£a-zA-Z])', r'\1 \2', text)
        text = re.sub(r'([ê°€-í£a-zA-Z])\s+(\d)', r'\1 \2', text)
        
        # 5. ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ ìˆ˜ì •
        corrections = {
            'O': '0',  # ìˆ«ì ì»¨í…ìŠ¤íŠ¸ì—ì„œ
            'l': '1',  # ìˆ«ì ì»¨í…ìŠ¤íŠ¸ì—ì„œ
            'ï½œ': '|',
            'ï¼': '.',
            'ï¼Œ': ',',
            'ï¼Ÿ': '?',
            'ï¼': '!',
        }
        
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
        
        return text
    
    async def batch_extract_text(self, 
                                images_data: List[bytes],
                                document_id: str,
                                language: str = 'kor+eng',
                                quality: OCRQuality = OCRQuality.HIGH) -> List[OCRResult]:
        """ë°°ì¹˜ OCR ì²˜ë¦¬"""
        
        tasks = []
        for i, image_data in enumerate(images_data):
            task = self.extract_text(
                image_data=image_data,
                page_number=i + 1,
                document_id=document_id,
                language=language,
                quality=quality
            )
            tasks.append(task)
        
        # ë³‘ë ¬ ì²˜ë¦¬
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_result = OCRResult(
                    document_id=document_id,
                    page_number=i + 1,
                    extracted_text="",
                    confidence_score=0.0,
                    processing_time_ms=0,
                    engine_used=self.primary_engine.get_engine_name(),
                    error_message=f"OCR ì²˜ë¦¬ ì‹¤íŒ¨: {str(result)}"
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        return processed_results
    
    def combine_ocr_results(self, results: List[OCRResult]) -> str:
        """ì—¬ëŸ¬ í˜ì´ì§€ OCR ê²°ê³¼ ê²°í•©"""
        
        valid_results = [r for r in results if r.extracted_text and not r.error_message]
        
        if not valid_results:
            return ""
        
        # í˜ì´ì§€ ìˆœì„œë¡œ ì •ë ¬
        valid_results.sort(key=lambda x: x.page_number)
        
        # í…ìŠ¤íŠ¸ ê²°í•©
        combined_text = ""
        for result in valid_results:
            combined_text += f"\n--- í˜ì´ì§€ {result.page_number} ---\n"
            combined_text += result.extracted_text
            combined_text += "\n"
        
        return combined_text.strip()
    
    def get_ocr_statistics(self, results: List[OCRResult]) -> Dict[str, Any]:
        """OCR ì²˜ë¦¬ í†µê³„"""
        
        total_pages = len(results)
        successful_pages = len([r for r in results if not r.error_message])
        failed_pages = total_pages - successful_pages
        
        if successful_pages > 0:
            avg_confidence = sum(r.confidence_score for r in results if not r.error_message) / successful_pages
            avg_processing_time = sum(r.processing_time_ms for r in results if not r.error_message) / successful_pages
            total_text_length = sum(len(r.extracted_text) for r in results if not r.error_message)
        else:
            avg_confidence = 0.0
            avg_processing_time = 0.0
            total_text_length = 0
        
        return {
            'total_pages': total_pages,
            'successful_pages': successful_pages,
            'failed_pages': failed_pages,
            'success_rate': successful_pages / total_pages if total_pages > 0 else 0,
            'average_confidence': avg_confidence,
            'average_processing_time_ms': avg_processing_time,
            'total_text_length': total_text_length,
            'engines_used': list(set(r.engine_used.value for r in results))
        }
```

---

## ğŸ¤– **4. AI ì²˜ë¦¬ ëª¨ë“ˆ**

### **4.1 AI ì„œë¹„ìŠ¤ ì¶”ìƒí™”**

```python
"""
AI ì²˜ë¦¬ ì„œë¹„ìŠ¤ í†µí•© ëª¨ë“ˆ
File: core/services/ai_service.py
"""

from typing import Dict, List, Optional, Any, Union
from abc import ABC, abstractmethod
from enum import Enum
from dataclasses import dataclass, field
import asyncio
import time
import json
from datetime import datetime

class AIModel(Enum):
    GEMINI = "gemini"
    GPT4 = "gpt4"
    CLAUDE = "claude"
    PERPLEXITY = "perplexity"
    CLOVA = "clova"

class JobType(Enum):
    SUMMARIZE = "summarize"
    IMPROVE = "improve"
    EXPAND = "expand"
    TRANSLATE = "translate"

@dataclass
class AIRequest:
    """AI ìš”ì²­ ëª¨ë¸"""
    job_type: JobType
    input_text: str
    reference_text: Optional[str] = None
    target_language: Optional[str] = None
    custom_prompt: Optional[str] = None
    parameters: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AIResponse:
    """AI ì‘ë‹µ ëª¨ë¸"""
    processed_text: str
    model_used: AIModel
    processing_time_ms: int
    token_usage: Dict[str, int] = field(default_factory=dict)
    confidence_score: Optional[float] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class BaseAIProvider(ABC):
    """AI í”„ë¡œë°”ì´ë” ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def process_text(self, request: AIRequest) -> AIResponse:
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        pass
    
    @abstractmethod
    def get_model_name(self) -> AIModel:
        """ëª¨ë¸ ì´ë¦„ ë°˜í™˜"""
        pass
    
    @abstractmethod
    def get_max_tokens(self) -> int:
        """ìµœëŒ€ í† í° ìˆ˜ ë°˜í™˜"""
        pass
    
    @abstractmethod
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """ë¹„ìš© ì¶”ì •"""
        pass

class OpenAIProvider(BaseAIProvider):
    """OpenAI GPT-4 í”„ë¡œë°”ì´ë”"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        self.api_key = api_key
        self.model = model
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            import openai
            self.client = openai.AsyncOpenAI(api_key=self.api_key)
        except Exception as e:
            raise ValueError(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def get_model_name(self) -> AIModel:
        return AIModel.GPT4
    
    def get_max_tokens(self) -> int:
        return 4096
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        # GPT-4 ê°€ê²© (2024ë…„ ê¸°ì¤€, ì‹¤ì œ ê°€ê²©ì€ ë³€ë™ë  ìˆ˜ ìˆìŒ)
        input_cost = input_tokens * 0.00003  # $0.03 per 1K tokens
        output_cost = output_tokens * 0.00006  # $0.06 per 1K tokens
        return input_cost + output_cost
    
    async def process_text(self, request: AIRequest) -> AIResponse:
        """OpenAIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            messages = self._build_messages(request)
            
            # API í˜¸ì¶œ
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.get_max_tokens(),
                temperature=self._get_temperature(request.job_type),
                top_p=0.9,
                frequency_penalty=0.0,
                presence_penalty=0.0
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            processed_text = response.choices[0].message.content
            
            # í† í° ì‚¬ìš©ëŸ‰
            token_usage = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return AIResponse(
                processed_text=processed_text,
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                token_usage=token_usage,
                confidence_score=0.9,  # OpenAIëŠ” confidenceë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                metadata={
                    'model_version': self.model,
                    'finish_reason': response.choices[0].finish_reason
                }
            )
            
        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            return AIResponse(
                processed_text="",
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                error_message=f"OpenAI ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _build_messages(self, request: AIRequest) -> List[Dict[str, str]]:
        """ë©”ì‹œì§€ êµ¬ì„±"""
        
        system_message = self._get_system_message(request.job_type)
        user_message = self._get_user_message(request)
        
        return [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
    
    def _get_system_message(self, job_type: JobType) -> str:
        """ì‘ì—… ìœ í˜•ë³„ ì‹œìŠ¤í…œ ë©”ì‹œì§€"""
        
        messages = {
            JobType.SUMMARIZE: "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            JobType.IMPROVE: "ë‹¹ì‹ ì€ ë¬¸ì„œ í¸ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë¬¸ì²´, êµ¬ì¡°, ê°€ë…ì„±ì„ ê°œì„ í•´ì£¼ì„¸ìš”.",
            JobType.EXPAND: "ë‹¹ì‹ ì€ ì½˜í…ì¸  ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë” ìƒì„¸í•˜ê³  í’ë¶€í•˜ê²Œ í™•ì¥í•´ì£¼ì„¸ìš”.",
            JobType.TRANSLATE: "ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ë¬¸ë§¥ê³¼ ë‰˜ì•™ìŠ¤ë¥¼ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”."
        }
        
        return messages.get(job_type, "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
    
    def _get_user_message(self, request: AIRequest) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±"""
        
        if request.custom_prompt:
            return request.custom_prompt
        
        prompts = {
            JobType.SUMMARIZE: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{request.input_text}

ìš”ì•½:""",
            JobType.IMPROVE: f"""
ë‹¤ìŒ ë¬¸ì„œì˜ ë¬¸ì²´ì™€ êµ¬ì¡°ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”:

{request.input_text}

ê°œì„ ëœ ë¬¸ì„œ:""",
            JobType.EXPAND: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë” ìƒì„¸í•˜ê³  í’ë¶€í•˜ê²Œ í™•ì¥í•´ì£¼ì„¸ìš”:
{f"ì°¸ê³ ìë£Œ: {request.reference_text}" if request.reference_text else ""}

ì›ë³¸ ë¬¸ì„œ:
{request.input_text}

í™•ì¥ëœ ë¬¸ì„œ:""",
            JobType.TRANSLATE: f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {request.target_language or 'ì˜ì–´'}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”:

{request.input_text}

ë²ˆì—­:"""
        }
        
        return prompts.get(request.job_type, request.input_text)
    
    def _get_temperature(self, job_type: JobType) -> float:
        """ì‘ì—… ìœ í˜•ë³„ temperature ì„¤ì •"""
        
        temperatures = {
            JobType.SUMMARIZE: 0.3,    # ì •í™•ì„± ì¤‘ì‹œ
            JobType.IMPROVE: 0.4,      # ì•½ê°„ì˜ ì°½ì˜ì„±
            JobType.EXPAND: 0.6,       # ì°½ì˜ì„± í•„ìš”
            JobType.TRANSLATE: 0.2     # ì •í™•ì„± ìµœìš°ì„ 
        }
        
        return temperatures.get(job_type, 0.5)

class GoogleGeminiProvider(BaseAIProvider):
    """Google Gemini í”„ë¡œë°”ì´ë”"""
    
    def __init__(self, api_key: str, model: str = "gemini-pro"):
        self.api_key = api_key
        self.model = model
        self.client = None
        self._init_client()
    
    def _init_client(self):
        """Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)
        except Exception as e:
            raise ValueError(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def get_model_name(self) -> AIModel:
        return AIModel.GEMINI
    
    def get_max_tokens(self) -> int:
        return 4096
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        # Gemini ê°€ê²© (ë¬´ë£Œ tierë„ ìˆìŒ)
        return 0.0  # ë¬´ë£Œ ì‚¬ìš©ëŸ‰ ë‚´ì—ì„œëŠ” ë¹„ìš© ì—†ìŒ
    
    async def process_text(self, request: AIRequest) -> AIResponse:
        """Geminië¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(request)
            
            # API í˜¸ì¶œ
            response = await self.client.generate_content_async(
                prompt,
                generation_config={
                    'temperature': self._get_temperature(request.job_type),
                    'top_p': 0.9,
                    'top_k': 40,
                    'max_output_tokens': self.get_max_tokens(),
                }
            )
            
            processed_text = response.text
            processing_time = int((time.time() - start_time) * 1000)
            
            return AIResponse(
                processed_text=processed_text,
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                confidence_score=0.85,
                metadata={
                    'model_version': self.model,
                    'safety_ratings': response.prompt_feedback.safety_ratings if hasattr(response, 'prompt_feedback') else []
                }
            )
            
        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            return AIResponse(
                processed_text="",
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                error_message=f"Gemini ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _build_prompt(self, request: AIRequest) -> str:
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        if request.custom_prompt:
            return request.custom_prompt
        
        system_context = self._get_system_context(request.job_type)
        user_message = self._get_user_message(request)
        
        return f"{system_context}\n\n{user_message}"
    
    def _get_system_context(self, job_type: JobType) -> str:
        """ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸"""
        
        contexts = {
            JobType.SUMMARIZE: "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ê²ƒì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤.",
            JobType.IMPROVE: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ í¸ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì²´ ê°œì„ , êµ¬ì¡° ìµœì í™”, ê°€ë…ì„± í–¥ìƒì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤.",
            JobType.EXPAND: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì½˜í…ì¸  ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í’ë¶€í•˜ê³  ìƒì„¸í•œ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤.",
            JobType.TRANSLATE: "ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ì™€ ì™¸êµ­ì–´ ê°„ì˜ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ì´ ì „ë¬¸ ë¶„ì•¼ì…ë‹ˆë‹¤."
        }
        
        return contexts.get(job_type, "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
    
    def _get_user_message(self, request: AIRequest) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ (OpenAIì™€ ë™ì¼í•œ ë¡œì§ ì¬ì‚¬ìš©)"""
        
        prompts = {
            JobType.SUMMARIZE: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”:

{request.input_text}

ìš”ì•½:""",
            JobType.IMPROVE: f"""
ë‹¤ìŒ ë¬¸ì„œì˜ ë¬¸ì²´ì™€ êµ¬ì¡°ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”. ê°€ë…ì„±ì„ ë†’ì´ê³  ë…¼ë¦¬ì  íë¦„ì„ ê°œì„ í•´ì£¼ì„¸ìš”:

{request.input_text}

ê°œì„ ëœ ë¬¸ì„œ:""",
            JobType.EXPAND: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë” ìƒì„¸í•˜ê³  í’ë¶€í•˜ê²Œ í™•ì¥í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ ë¬¸ë§¥ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”:
{f"ì°¸ê³ ìë£Œ: {request.reference_text}" if request.reference_text else ""}

ì›ë³¸ ë¬¸ì„œ:
{request.input_text}

í™•ì¥ëœ ë¬¸ì„œ:""",
            JobType.TRANSLATE: f"""
ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ {request.target_language or 'ì˜ì–´'}ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”:

{request.input_text}

ë²ˆì—­:"""
        }
        
        return prompts.get(request.job_type, request.input_text)
    
    def _get_temperature(self, job_type: JobType) -> float:
        """ì‘ì—… ìœ í˜•ë³„ temperature (OpenAIì™€ ë™ì¼)"""
        
        temperatures = {
            JobType.SUMMARIZE: 0.3,
            JobType.IMPROVE: 0.4,
            JobType.EXPAND: 0.6,
            JobType.TRANSLATE: 0.2
        }
        
        return temperatures.get(job_type, 0.5)

class ClovaXProvider(BaseAIProvider):
    """ë„¤ì´ë²„ ClovaX í”„ë¡œë°”ì´ë”"""
    
    def __init__(self, api_key: str, request_id: str):
        self.api_key = api_key
        self.request_id = request_id
        self.model = "HCX-005"
        self.host = "https://clovastudio.stream.ntruss.com"
    
    def get_model_name(self) -> AIModel:
        return AIModel.CLOVA
    
    def get_max_tokens(self) -> int:
        return 4096
    
    def estimate_cost(self, input_tokens: int, output_tokens: int) -> float:
        # ClovaX ê°€ê²© ì •ë³´ê°€ í•„ìš”
        return 0.0  # ì„ì‹œ
    
    async def process_text(self, request: AIRequest) -> AIResponse:
        """ClovaXë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        
        start_time = time.time()
        
        try:
            import aiohttp
            
            # ìš”ì²­ ë°ì´í„° êµ¬ì„±
            request_data = {
                "messages": [
                    {
                        "role": "system",
                        "content": self._get_system_message(request.job_type)
                    },
                    {
                        "role": "user",
                        "content": self._get_user_message(request)
                    }
                ],
                "topP": 0.8,
                "topK": 0,
                "maxTokens": self.get_max_tokens(),
                "temperature": self._get_temperature(request.job_type),
                "repeatPenalty": 1.1,
                "stopBefore": [],
                "includeAiFilters": True,
                "seed": 0
            }
            
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'X-NCP-CLOVASTUDIO-REQUEST-ID': self.request_id,
                'Content-Type': 'application/json; charset=utf-8',
                'Accept': 'application/json'
            }
            
            # API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.host}/v3/chat-completions/{self.model}",
                    headers=headers,
                    json=request_data
                ) as response:
                    
                    if response.status != 200:
                        raise Exception(f"ClovaX API ì˜¤ë¥˜: {response.status}")
                    
                    result = await response.json()
            
            # ì‘ë‹µ ì²˜ë¦¬
            if result.get('choices') and len(result['choices']) > 0:
                processed_text = result['choices'][0]['message']['content']
            else:
                raise Exception("ClovaX API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return AIResponse(
                processed_text=processed_text,
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                confidence_score=0.88,  # ClovaX í•œêµ­ì–´ íŠ¹í™”
                metadata={
                    'model_version': self.model,
                    'request_id': self.request_id
                }
            )
            
        except Exception as e:
            processing_time = int((time.time() - start_time) * 1000)
            return AIResponse(
                processed_text="",
                model_used=self.get_model_name(),
                processing_time_ms=processing_time,
                error_message=f"ClovaX ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _get_system_message(self, job_type: JobType) -> str:
        """ClovaX í•œêµ­ì–´ íŠ¹í™” ì‹œìŠ¤í…œ ë©”ì‹œì§€"""
        
        messages = {
            JobType.SUMMARIZE: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            JobType.IMPROVE: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì²´ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ í‘œí˜„ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰½ê²Œ ê°œì„ í•´ì£¼ì„¸ìš”.",
            JobType.EXPAND: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì½˜í…ì¸  í™•ì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë¬¸ë§¥ì— ë§ëŠ” ì ì ˆí•œ í‘œí˜„ìœ¼ë¡œ ë‚´ìš©ì„ í’ë¶€í•˜ê²Œ í™•ì¥í•´ì£¼ì„¸ìš”.",
            JobType.TRANSLATE: "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸í™”ì  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”."
        }
        
        return messages.get(job_type, "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
    
    def _get_user_message(self, request: AIRequest) -> str:
        """ClovaXìš© ì‚¬ìš©ì ë©”ì‹œì§€"""
        
        if request.custom_prompt:
            return request.custom_prompt
        
        prompts = {
            JobType.SUMMARIZE: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ ë¬¸ë§¥ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”:

{request.input_text}

ìš”ì•½:""",
            JobType.IMPROVE: f"""
ë‹¤ìŒ ë¬¸ì„œì˜ ë¬¸ì²´ì™€ êµ¬ì¡°ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ í‘œí˜„ì„ ë” ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{request.input_text}

ê°œì„ ëœ ë¬¸ì„œ:""",
            JobType.EXPAND: f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë” ìƒì„¸í•˜ê³  í’ë¶€í•˜ê²Œ í™•ì¥í•´ì£¼ì„¸ìš”. í•œêµ­ì–´ ë¬¸ë§¥ì— ë§ëŠ” ì ì ˆí•œ í‘œí˜„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”:
{f"ì°¸ê³ ìë£Œ: {request.reference_text}" if request.reference_text else ""}

ì›ë³¸ ë¬¸ì„œ:
{request.input_text}

í™•ì¥ëœ ë¬¸ì„œ:""",
            JobType.TRANSLATE: f"""
ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì„œë¥¼ {request.target_language or 'English'}ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë¬¸í™”ì  ë§¥ë½ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”:

{request.input_text}

ë²ˆì—­:"""
        }
        
        return prompts.get(request.job_type, request.input_text)
    
    def _get_temperature(self, job_type: JobType) -> float:
        """ì‘ì—… ìœ í˜•ë³„ temperature"""
        
        temperatures = {
            JobType.SUMMARIZE: 0.3,
            JobType.IMPROVE: 0.4,
            JobType.EXPAND: 0.6,
            JobType.TRANSLATE: 0.2
        }
        
        return temperatures.get(job_type, 0.5)

class AIService:
    """í†µí•© AI ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.providers: Dict[AIModel, BaseAIProvider] = {}
        self.default_model = AIModel.GEMINI
    
    def register_provider(self, provider: BaseAIProvider):
        """AI í”„ë¡œë°”ì´ë” ë“±ë¡"""
        self.providers[provider.get_model_name()] = provider
    
    def set_default_model(self, model: AIModel):
        """ê¸°ë³¸ ëª¨ë¸ ì„¤ì •"""
        if model in self.providers:
            self.default_model = model
        else:
            raise ValueError(f"ë“±ë¡ë˜ì§€ ì•Šì€ ëª¨ë¸: {model}")
    
    async def process_document(self,
                             document_id: str,
                             job_type: JobType,
                             input_text: str,
                             ai_model: AIModel = None,
                             reference_text: str = None,
                             target_language: str = None,
                             custom_prompt: str = None) -> AIResponse:
        """ë¬¸ì„œ ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        
        # ëª¨ë¸ ì„ íƒ
        model = ai_model or self.default_model
        provider = self.providers.get(model)
        
        if not provider:
            raise ValueError(f"ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” AI ëª¨ë¸: {model}")
        
        # ìš”ì²­ êµ¬ì„±
        request = AIRequest(
            job_type=job_type,
            input_text=input_text,
            reference_text=reference_text,
            target_language=target_language,
            custom_prompt=custom_prompt
        )
        
        # AI ì²˜ë¦¬ ì‹¤í–‰
        response = await provider.process_text(request)
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        response.metadata.update({
            'document_id': document_id,
            'job_type': job_type.value,
            'input_length': len(input_text),
            'output_length': len(response.processed_text),
            'timestamp': datetime.utcnow().isoformat()
        })
        
        return response
    
    async def compare_models(self,
                           input_text: str,
                           job_type: JobType,
                           models: List[AIModel] = None) -> Dict[AIModel, AIResponse]:
        """ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ"""
        
        if not models:
            models = list(self.providers.keys())
        
        tasks = []
        for model in models:
            if model in self.providers:
                request = AIRequest(job_type=job_type, input_text=input_text)
                task = self.providers[model].process_text(request)
                tasks.append((model, task))
        
        results = {}
        completed_tasks = await asyncio.gather(*[task for _, task in tasks], return_exceptions=True)
        
        for (model, _), result in zip(tasks, completed_tasks):
            if isinstance(result, Exception):
                results[model] = AIResponse(
                    processed_text="",
                    model_used=model,
                    processing_time_ms=0,
                    error_message=str(result)
                )
            else:
                results[model] = result
        
        return results
    
    def get_available_models(self) -> List[AIModel]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
        return list(self.providers.keys())
    
    def get_model_info(self, model: AIModel) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        
        provider = self.providers.get(model)
        if not provider:
            return {}
        
        return {
            'model_name': model.value,
            'max_tokens': provider.get_max_tokens(),
            'estimated_cost_per_1k_tokens': provider.estimate_cost(1000, 1000),
            'supported_languages': ['ko', 'en'],  # ëª¨ë“  ëª¨ë¸ì´ í•œì˜ ì§€ì›
            'specialties': self._get_model_specialties(model)
        }
    
    def _get_model_specialties(self, model: AIModel) -> List[str]:
        """ëª¨ë¸ë³„ íŠ¹í™” ë¶„ì•¼"""
        
        specialties = {
            AIModel.GEMINI: ['ì¼ë°˜ ë¬¸ì„œ', 'ë¹ ë¥¸ ì²˜ë¦¬', 'ë¬´ë£Œ ì‚¬ìš©'],
            AIModel.GPT4: ['ì°½ì˜ì  í¸ì§‘', 'ë³µì¡í•œ êµ¬ì¡°', 'ë†’ì€ í’ˆì§ˆ'],
            AIModel.CLAUDE: ['ì •í™•í•œ ë¶„ì„', 'ê¸´ ë¬¸ì„œ', 'ì•ˆì „í•œ ì²˜ë¦¬'],
            AIModel.PERPLEXITY: ['ì‹¤ì‹œê°„ ì •ë³´', 'íŒ©íŠ¸ì²´í¬', 'ìµœì‹  ë°ì´í„°'],
            AIModel.CLOVA: ['í•œêµ­ì–´ íŠ¹í™”', 'ë¡œì»¬ ì»¨í…ìŠ¤íŠ¸', 'ë¬¸í™”ì  ì´í•´']
        }
        
        return specialties.get(model, ['ë²”ìš© ì²˜ë¦¬'])
```

---

ì´ì œ ë§ˆì§€ë§‰ìœ¼ë¡œ ì™„ì „ êµ¬í˜„ ê°€ëŠ¥í•œ ì½”ë“œ ìƒ˜í”Œì„ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "\uc0ac\uc6a9\uc790/\uace0\uac1d \uad00\uc810 \uae30\ub2a5 \uba85\uc138\uc11c \uc791\uc131", "status": "completed", "id": "1"}, {"content": "\uac1c\ubc1c\uc790 \uad00\uc810 \uc544\ud0a4\ud14d\ucc98 \uc124\uacc4\uc548 \uc791\uc131", "status": "completed", "id": "2"}, {"content": "\ub514\uc790\uc774\ub108 \uad00\uc810 UI/UX/AX \uac00\uc774\ub4dc \uc791\uc131", "status": "completed", "id": "3"}, {"content": "\ud575\uc2ec \ub85c\uc9c1 \ubc0f \ubaa8\ub4c8 \uad6c\uc870 \ubb38\uc11c\ud654", "status": "completed", "id": "4"}, {"content": "\uc644\uc804 \uad6c\ud604 \uac00\ub2a5\ud55c \ucf54\ub4dc \uc0d8\ud50c \uc815\ub9ac", "status": "in_progress", "id": "5"}]