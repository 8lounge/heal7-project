#!/usr/bin/env python3
"""
HEAL7 ë§ˆì¼€íŒ… í¬ë¡¤ëŸ¬ AI ì„œë¹„ìŠ¤
Gemini AIë¥¼ í™œìš©í•œ API ë³€í™˜, ë°ì´í„° ì²˜ë¦¬, ìµœì í™” ì„œë¹„ìŠ¤
"""

import logging
import json
import asyncio
import httpx
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from pydantic import BaseModel

logger = logging.getLogger(__name__)

class AIServiceClient:
    """AI ì„œë¹„ìŠ¤ ë°±ì—”ë“œ í´ë¼ì´ì–¸íŠ¸ (ìƒˆë¡œìš´ í†µí•© AI ë§¤ë‹ˆì € í˜¸ì¶œ)"""
    
    def __init__(self, ai_service_url: str = None):
        """AI ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.ai_service_url = None  # AI ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”ë¨ - ë¡œì»¬ ì²˜ë¦¬ë¡œ ì „í™˜
        self.client = httpx.AsyncClient(timeout=60.0)
        
        # ìƒˆë¡œìš´ AI ì‹œìŠ¤í…œì˜ ì„œë¹„ìŠ¤ë³„ í´ë°± ìˆœì„œ
        self.service_types = {
            "marketing": "marketing",    # ë§ˆì¼€íŒ… íŠ¹í™” í´ë°±
            "research": "research",      # ë¦¬ì„œì¹˜ íŠ¹í™” (Perplexity ìš°ì„ )
            "general": "default",        # ê¸°ë³¸ í´ë°±
            "api_validation": "marketing",
            "job_optimization": "marketing", 
            "data_conversion": "general",
            "data_analysis": "research",
            "worker_validation": "general"
        }
    
    async def process_with_fallback(self, prompt: str, task_type: str = "general") -> Dict[str, Any]:
        """ìƒˆë¡œìš´ AI ì„œë¹„ìŠ¤ ë°±ì—”ë“œë¥¼ í†µí•œ í†µí•© ì²˜ë¦¬"""
        
        # ì‘ì—… íƒ€ì…ì„ ì„œë¹„ìŠ¤ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
        service_type = self.service_types.get(task_type, "default")
        
        logger.info(f"ğŸ¤– AI ì²˜ë¦¬ ìš”ì²­: {task_type} â†’ {service_type} ì„œë¹„ìŠ¤")
        
        try:
            # ìƒˆë¡œìš´ AI ì„œë¹„ìŠ¤ ë°±ì—”ë“œì˜ í†µí•© API í˜¸ì¶œ
            response = await self.client.post(
                f"{self.ai_service_url}/ai/process",
                json={
                    "prompt": prompt,
                    "service": service_type,
                    "temperature": 0.7,
                    "max_tokens": 2048
                },
                timeout=60.0
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"âœ… AI ì²˜ë¦¬ ì„±ê³µ: {result.get('model_used', 'unknown')}")
                
                return {
                    "success": True,
                    "result": self._parse_ai_response(result.get("response", "")),
                    "model_used": result.get("model_used", "unknown"),
                    "task_type": task_type,
                    "service_type": service_type,
                    "processing_time": result.get("response_time", 0),
                    "cost_estimate": result.get("cost_estimate", 0)
                }
            else:
                error_msg = f"AI ì„œë¹„ìŠ¤ HTTP ì—ëŸ¬ {response.status_code}: {response.text}"
                logger.error(f"âŒ {error_msg}")
                return {
                    "success": False,
                    "error": error_msg,
                    "task_type": task_type,
                    "service_type": service_type
                }
                
        except asyncio.TimeoutError:
            error_msg = f"AI ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ (60ì´ˆ)"
            logger.error(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "task_type": task_type,
                "service_type": service_type
            }
            
        except Exception as e:
            error_msg = f"AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "task_type": task_type,
                "service_type": service_type
            }
    
    async def research_with_perplexity(self, query: str, context: str = "") -> Dict[str, Any]:
        """Perplexityë¥¼ ì´ìš©í•œ ì „ë¬¸ ë¦¬ì„œì¹˜ ì¡°ì‚¬"""
        
        research_prompt = f"""
        ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¦¬ì„œì¹˜ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        
        ì¡°ì‚¬ ì£¼ì œ: {query}
        ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {context}
        
        ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•´ì„œ ì¡°ì‚¬í•´ì£¼ì„¸ìš”:
        1. ìµœì‹  ë™í–¥ ë° íŠ¸ë Œë“œ
        2. ì‹œì¥ ë¶„ì„ ë° ì „ë§
        3. ì£¼ìš” í”Œë ˆì´ì–´ ë° ê²½ìŸì‚¬ ë¶„ì„
        4. ê¸°ìˆ ì  ë°œì „ ì‚¬í•­
        5. ê·œì œ ë° ì •ì±… ë³€í™”
        6. ì†Œë¹„ì í–‰ë™ íŒ¨í„´
        7. í–¥í›„ ì˜ˆì¸¡ ë° ê¸°íšŒ
        
        ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        return await self.process_with_fallback(research_prompt, "research")

class CrawlerService:
    def __init__(self, ai_service_url: str = None):
        """AI ì„œë¹„ìŠ¤ ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.ai_client = AIServiceClient(ai_service_url)
        
    async def validate_api_configuration(self, api_config: Dict[str, Any]) -> Dict[str, Any]:
        """API ì„¤ì •ì„ AI í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ê²€ì¦í•˜ê³  ìµœì í™”"""
        
        prompt = f"""
        ë‹¤ìŒ API ì„¤ì •ì„ ë¶„ì„í•˜ê³  ê²€ì¦í•´ì£¼ì„¸ìš”:
        
        API ì •ë³´:
        - ì´ë¦„: {api_config.get('name')}
        - ì œê³µì—…ì²´: {api_config.get('provider')}
        - ê¸°ë³¸ URL: {api_config.get('base_url')}
        - API í‚¤: {api_config.get('api_key', '***')}
        - ì¶”ê°€ íŒŒë¼ë¯¸í„°: {api_config.get('additional_params', {})}
        
        ë‹¤ìŒ ì‚¬í•­ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. URL í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦
        2. ì¸ì¦ ë°©ì‹ ì¶”ì • (API Key, Bearer Token, OAuth ë“±)
        3. ì˜ˆìƒë˜ëŠ” ì‘ë‹µ í˜•ì‹ (JSON, XML, RSS ë“±)
        4. ê¶Œì¥ í˜¸ì¶œ ë¹ˆë„ ë° ì œí•œì‚¬í•­
        5. í•„ìš”í•œ í—¤ë”ë‚˜ íŒŒë¼ë¯¸í„° ì¶”ì²œ
        6. ì—ëŸ¬ ì²˜ë¦¬ ë°©ë²• ì¶”ì²œ
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # AI í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
        ai_result = await self.ai_client.process_with_fallback(prompt, "api_validation")
        
        if not ai_result["success"]:
            logger.error(f"AI API ê²€ì¦ ì‹¤íŒ¨: {ai_result.get('errors', [])}")
            return {
                "valid": False,
                "error": "AI ì²˜ë¦¬ ì‹¤íŒ¨",
                "fallback_errors": ai_result.get("errors", []),
                "analysis": None,
                "confidence": 0.0
            }
        
        result = ai_result["result"]
        
        # AI ì‘ë‹µì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
        return {
            "valid": result.get("valid", True),
            "analysis": {
                "api_type": result.get("api_type", "REST API"),
                "authentication": result.get("authentication", "API Key"),
                "response_format": result.get("response_format", "JSON"),
                "rate_limits": result.get("rate_limits", "Unknown"),
                "recommended_settings": result.get("recommended_settings", {}),
                "required_headers": result.get("required_headers", {}),
                "error_handling": result.get("error_handling", [])
            },
            "confidence": result.get("confidence", 0.8),
            "ai_model_used": ai_result["model_used"],
            "processing_attempt": ai_result["attempt"]
        }
    
    async def optimize_crawling_job(self, job_config: Dict[str, Any]) -> Dict[str, Any]:
        """í¬ë¡¤ë§ ì‘ì—… ì„¤ì •ì„ AI í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ìµœì í™”"""
        
        prompt = f"""
        ë‹¤ìŒ í¬ë¡¤ë§ ì‘ì—…ì„ ìµœì í™”í•´ì£¼ì„¸ìš”:
        
        ì‘ì—… ì •ë³´:
        - ì´ë¦„: {job_config.get('name')}
        - ì¹´í…Œê³ ë¦¬: {job_config.get('category')}
        - ì†ŒìŠ¤ íƒ€ì…: {job_config.get('source_type')}
        - ëŒ€ìƒ URL: {job_config.get('target_url')}
        - ê²€ìƒ‰ í‚¤ì›Œë“œ: {job_config.get('search_keywords', [])}
        - í˜„ì¬ ì£¼ê¸°: {job_config.get('crawl_frequency')}
        - ì ‘ê·¼ íŒ¨í„´: {job_config.get('access_pattern')}
        - ì§€ì—° ì‹œê°„: {job_config.get('random_delay_min')}-{job_config.get('random_delay_max')}ì´ˆ
        
        ë‹¤ìŒ ì‚¬í•­ì„ ìµœì í™”í•´ì£¼ì„¸ìš”:
        1. ìµœì  í¬ë¡¤ë§ ì£¼ê¸° (ì„œë²„ ë¶€í•˜, ì°¨ë‹¨ ìœ„í—˜ ê³ ë ¤)
        2. íš¨ìœ¨ì ì¸ ì ‘ê·¼ íŒ¨í„´
        3. ì ì ˆí•œ ì§€ì—° ì‹œê°„ ì„¤ì •
        4. í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ë° ì¶”ê°€ í‚¤ì›Œë“œ ì œì•ˆ
        5. ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ë°©ë²•
        6. ì—ëŸ¬ ë³µêµ¬ ì „ëµ
        7. ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ìµœì í™”
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # AI í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
        ai_result = await self.ai_client.process_with_fallback(prompt, "job_optimization")
        
        if not ai_result["success"]:
            logger.error(f"AI ì‘ì—… ìµœì í™” ì‹¤íŒ¨: {ai_result.get('errors', [])}")
            return {
                "optimized": False,
                "error": "AI ì²˜ë¦¬ ì‹¤íŒ¨",
                "fallback_errors": ai_result.get("errors", []),
                "confidence": 0.0
            }
        
        result = ai_result["result"]
        
        return {
            "optimized": True,
            "recommendations": {
                "crawl_frequency": result.get("optimal_frequency", job_config.get('crawl_frequency')),
                "access_pattern": result.get("optimal_pattern", job_config.get('access_pattern')),
                "delay_range": result.get("optimal_delays", [5, 30]),
                "additional_keywords": result.get("suggested_keywords", []),
                "priority_keywords": result.get("priority_keywords", []),
                "batch_size": result.get("optimal_batch_size", 50),
                "retry_strategy": result.get("retry_strategy", "exponential_backoff"),
                "quality_filters": result.get("quality_filters", [])
            },
            "performance_improvements": result.get("performance_tips", []),
            "risk_mitigation": result.get("risk_mitigation", []),
            "confidence": result.get("confidence", 0.8),
            "ai_model_used": ai_result["model_used"],
            "processing_attempt": ai_result["attempt"]
        }
    
    async def convert_api_response(self, raw_data: Dict[str, Any], target_schema: str) -> Dict[str, Any]:
        """ë‹¤ì–‘í•œ API ì‘ë‹µì„ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜"""
        
        prompt = f"""
        ë‹¤ìŒ API ì‘ë‹µ ë°ì´í„°ë¥¼ HEAL7 ë§ˆì¼€íŒ… ì‹œìŠ¤í…œì˜ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:
        
        ì›ë³¸ ë°ì´í„°:
        {json.dumps(raw_data, ensure_ascii=False, indent=2)}
        
        ëª©í‘œ ìŠ¤í‚¤ë§ˆ: {target_schema}
        
        ë³€í™˜ ìš”êµ¬ì‚¬í•­:
        1. ë°ì´í„° êµ¬ì¡° ì •ê·œí™”
        2. í•œê¸€/ì˜ë¬¸ í•„ë“œëª… í†µì¼
        3. ë‚ ì§œ/ì‹œê°„ í˜•ì‹ í‘œì¤€í™” (ISO 8601)
        4. ëˆ„ë½ í•„ë“œ ì²˜ë¦¬
        5. ë°ì´í„° íƒ€ì… ì •ê·œí™”
        6. ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
        7. ë©”íƒ€ë°ì´í„° ì¶”ê°€
        
        JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # AI í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
        ai_result = await self.ai_client.process_with_fallback(prompt, "data_conversion")
        
        if not ai_result["success"]:
            logger.error(f"AI ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {ai_result.get('errors', [])}")
            return {
                "success": False,
                "error": "AI ì²˜ë¦¬ ì‹¤íŒ¨",
                "fallback_errors": ai_result.get("errors", []),
                "original_data": raw_data
            }
        
        result = ai_result["result"]
        converted_data = result.get("converted_data", raw_data)
        
        return {
            "success": True,
            "converted_data": converted_data,
            "metadata": {
                "conversion_timestamp": datetime.now().isoformat(),
                "original_fields": len(raw_data),
                "converted_fields": len(converted_data),
                "schema_version": target_schema
            },
            "quality_score": self._calculate_data_quality(converted_data),
            "ai_model_used": ai_result["model_used"],
            "processing_attempt": ai_result["attempt"]
        }
    
    async def analyze_collected_data(self, data_batch: List[Dict[str, Any]], category: str) -> Dict[str, Any]:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ AIë¡œ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        prompt = f"""
        ë‹¤ìŒ {category} ì¹´í…Œê³ ë¦¬ì˜ ìˆ˜ì§‘ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ë°ì´í„° ìƒ˜í”Œ ({len(data_batch)}ê°œ):
        {json.dumps(data_batch[:5], ensure_ascii=False, indent=2)}
        
        ë¶„ì„ ìš”ì²­ì‚¬í•­:
        1. ì£¼ìš” íŠ¸ë Œë“œ ë° íŒ¨í„´ ì‹ë³„
        2. í‚¤ì›Œë“œ ë¹ˆë„ ë° ì¤‘ìš”ë„ ë¶„ì„
        3. ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
        4. ë°ì´í„° í’ˆì§ˆ í‰ê°€
        5. ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ë¶„ì„
        6. ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        7. í™œìš© ê¶Œì¥ì‚¬í•­
        
        ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # AI í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
        ai_result = await self.ai_client.process_with_fallback(prompt, "data_analysis")
        
        if not ai_result["success"]:
            logger.error(f"AI ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {ai_result.get('errors', [])}")
            return {
                "analysis_success": False,
                "error": "AI ì²˜ë¦¬ ì‹¤íŒ¨",
                "fallback_errors": ai_result.get("errors", []),
                "category": category,
                "data_count": len(data_batch)
            }
        
        result = ai_result["result"]
        
        return {
            "analysis_success": True,
            "category": category,
            "data_count": len(data_batch),
            "insights": {
                "key_trends": result.get("trends", []),
                "keyword_analysis": result.get("keywords", {}),
                "sentiment_score": result.get("sentiment", 0.0),
                "quality_metrics": result.get("quality", {}),
                "predictions": result.get("predictions", []),
                "recommendations": result.get("recommendations", [])
            },
            "confidence": result.get("confidence", 0.8),
            "analysis_timestamp": datetime.now().isoformat(),
            "ai_model_used": ai_result["model_used"],
            "processing_attempt": ai_result["attempt"]
        }
    
    async def validate_worker_configuration(self, worker_config: Dict[str, Any]) -> Dict[str, Any]:
        """ì›Œì»¤ ì„¤ì •ì„ AIë¡œ ê²€ì¦í•˜ê³  ìµœì í™”"""
        
        prompt = f"""
        ë‹¤ìŒ í¬ë¡¤ë§ ì›Œì»¤ ì„¤ì •ì„ ê²€ì¦í•˜ê³  ìµœì í™”í•´ì£¼ì„¸ìš”:
        
        ì›Œì»¤ ì„¤ì •:
        - íƒ€ì…: {worker_config.get('type')}
        - ìœ„ì¹˜: {worker_config.get('location')}
        - ìµœëŒ€ ì›Œì»¤ ìˆ˜: {worker_config.get('max_workers')}
        - ì„¤ì •: {worker_config.get('config', {})}
        
        ê²€ì¦ í•­ëª©:
        1. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì ì •ì„±
        2. ì„±ëŠ¥ ìµœì í™” ê°€ëŠ¥ì„±
        3. ì•ˆì •ì„± ë° ì—ëŸ¬ ì²˜ë¦¬
        4. ë³´ì•ˆ ìœ„í—˜ ìš”ì†Œ
        5. í™•ì¥ì„± ê³ ë ¤ì‚¬í•­
        
        JSON í˜•ì‹ìœ¼ë¡œ ê²€ì¦ ê²°ê³¼ì™€ ìµœì í™” ê¶Œì¥ì‚¬í•­ì„ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        # AI í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©
        ai_result = await self.ai_client.process_with_fallback(prompt, "worker_validation")
        
        if not ai_result["success"]:
            logger.warning(f"AI ì›Œì»¤ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {ai_result.get('errors', [])}")
            return {
                "valid": True,  # ê¸°ë³¸ê°’ìœ¼ë¡œ í—ˆìš©
                "error": "AI ì²˜ë¦¬ ì‹¤íŒ¨",
                "fallback_errors": ai_result.get("errors", []),
                "confidence": 0.0
            }
        
        result = ai_result["result"]
        
        return {
            "valid": result.get("valid", True),
            "optimization_score": result.get("score", 7.5),
            "recommendations": result.get("recommendations", []),
            "risk_assessment": result.get("risks", []),
            "resource_optimization": result.get("resource_tips", []),
            "confidence": result.get("confidence", 0.8),
            "ai_model_used": ai_result["model_used"],
            "processing_attempt": ai_result["attempt"]
        }
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """AI ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±"""
        try:
            # JSON ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
            if "```json" in response_text:
                start = response_text.find("```json") + 7
                end = response_text.find("```", start)
                json_text = response_text[start:end].strip()
            elif "{" in response_text and "}" in response_text:
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                json_text = response_text[start:end]
            else:
                # JSONì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ ìƒì„±
                return {"valid": True, "analysis": response_text}
            
            return json.loads(json_text)
            
        except json.JSONDecodeError:
            logger.warning(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {response_text[:200]}...")
            return {"valid": True, "raw_response": response_text}
    
    def _calculate_data_quality(self, data: Dict[str, Any]) -> float:
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 1.0
        
        # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€
        required_fields = ["title", "content", "timestamp", "source"]
        existing_fields = sum(1 for field in required_fields if field in data)
        score *= (existing_fields / len(required_fields))
        
        # ë°ì´í„° ì™„ì „ì„±
        empty_values = sum(1 for value in data.values() if not value)
        if len(data) > 0:
            score *= (1 - empty_values / len(data))
        
        return round(score, 2)

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
crawler_service = CrawlerService()

# í¸ì˜ í•¨ìˆ˜ë“¤
async def validate_api_with_ai(api_config: Dict[str, Any]) -> Dict[str, Any]:
    """API ì„¤ì • AI ê²€ì¦"""
    return await crawler_service.validate_api_configuration(api_config)

async def optimize_job_with_ai(job_config: Dict[str, Any]) -> Dict[str, Any]:
    """í¬ë¡¤ë§ ì‘ì—… AI ìµœì í™”"""
    return await crawler_service.optimize_crawling_job(job_config)

async def convert_data_with_ai(raw_data: Dict[str, Any], schema: str) -> Dict[str, Any]:
    """ë°ì´í„° AI ë³€í™˜"""
    return await crawler_service.convert_api_response(raw_data, schema)

async def analyze_data_with_ai(data: List[Dict[str, Any]], category: str) -> Dict[str, Any]:
    """ë°ì´í„° AI ë¶„ì„"""
    return await crawler_service.analyze_collected_data(data, category)

async def validate_worker_config_with_ai(worker_config: Dict[str, Any]) -> Dict[str, Any]:
    """ì›Œì»¤ ì„¤ì • AI ê²€ì¦"""
    return await crawler_service.validate_worker_configuration(worker_config)